{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8353"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Here we extract the words that have more impact on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only considering the 20000 most common words\n",
    "## We convert all other words to N0O0N, which indicate unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpora, Get DataLoader Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:44<00:00, 1159.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:25<00:00, 1166.63it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor\n",
    "# Here, one hot embedding is used\n",
    "## A score for each words is a trainable vector. Higher means positive word, lower means negative word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(len(corpora.word_index), 5)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "        emb = self.embedding(src)\n",
    "        z = torch.sum(emb,dim=1)\n",
    "        d = torch.softmax(z, dim=-1)\n",
    "\n",
    "\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Weights Initialization Goes Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_DIM = len(corpora.word_index)\n",
    "\n",
    "# initialize the model\n",
    "featureExtractor = FeatureExtractor(INPUT_DIM).cuda(3)\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "featureExtractor.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(featureExtractor.parameters())\n",
    "\n",
    "\n",
    "tmp = optimizer.state_dict()\n",
    "tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "optimizer.load_state_dict(tmp)\n",
    "print(optimizer)\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 30\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "training_losses = []\n",
    "test_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    \n",
    "#     if num_epochs_train == 1:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "#     if num_epochs_train == 2:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 3:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.000125\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 15:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 15:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.000025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 749.70it/s]\n",
      "1562it [00:06, 259.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 14s\tTrain Loss: 1.563 | Test Loss: 1.550\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 774.48it/s]\n",
      "1562it [00:06, 259.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 14s\tTrain Loss: 1.546 | Test Loss: 1.544\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 779.20it/s]\n",
      "1562it [00:05, 262.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 13s\tTrain Loss: 1.541 | Test Loss: 1.541\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 782.40it/s]\n",
      "1562it [00:05, 265.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 13s\tTrain Loss: 1.536 | Test Loss: 1.537\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 1028.34it/s]\n",
      "1562it [00:05, 262.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 12s\tTrain Loss: 1.532 | Test Loss: 1.535\n",
      "epoch start:  5\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 1002.72it/s]\n",
      "1562it [00:05, 264.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 12s\tTrain Loss: 1.529 | Test Loss: 1.534\n",
      "epoch start:  6\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 758.66it/s]\n",
      "1562it [00:05, 262.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 14s\tTrain Loss: 1.527 | Test Loss: 1.533\n",
      "epoch start:  7\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 802.49it/s] \n",
      "1562it [00:05, 260.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 13s\tTrain Loss: 1.526 | Test Loss: 1.532\n",
      "epoch start:  8\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 801.21it/s]\n",
      "1562it [00:05, 260.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 13s\tTrain Loss: 1.524 | Test Loss: 1.532\n",
      "epoch start:  9\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 794.78it/s]\n",
      "1562it [00:05, 263.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 13s\tTrain Loss: 1.523 | Test Loss: 1.531\n",
      "epoch start:  10\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 796.98it/s]\n",
      "1562it [00:05, 262.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 13s\tTrain Loss: 1.522 | Test Loss: 1.531\n",
      "epoch start:  11\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 767.42it/s]\n",
      "1562it [00:06, 259.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 14s\tTrain Loss: 1.521 | Test Loss: 1.531\n",
      "epoch start:  12\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 783.57it/s]\n",
      "1562it [00:05, 263.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 13s\tTrain Loss: 1.520 | Test Loss: 1.531\n",
      "epoch start:  13\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 784.13it/s]\n",
      "1562it [00:05, 265.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 13s\tTrain Loss: 1.519 | Test Loss: 1.530\n",
      "epoch start:  14\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 786.82it/s]\n",
      "1562it [00:06, 256.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 14s\tTrain Loss: 1.518 | Test Loss: 1.530\n",
      "epoch start:  15\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 780.34it/s]\n",
      "1562it [00:06, 253.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  16\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 766.01it/s]\n",
      "1562it [00:05, 261.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  17\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 774.25it/s]\n",
      "1562it [00:06, 256.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  18\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 798.50it/s]\n",
      "1562it [00:05, 267.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 13s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  19\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 782.76it/s]\n",
      "1562it [00:05, 262.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 13s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  20\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 794.53it/s]\n",
      "1562it [00:05, 263.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 0m 13s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  21\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 833.26it/s] \n",
      "1562it [00:05, 262.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 0m 13s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  22\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 770.12it/s]\n",
      "1562it [00:05, 262.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  23\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 801.72it/s]\n",
      "1562it [00:06, 255.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 0m 13s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  24\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 741.28it/s]\n",
      "1562it [00:06, 256.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  25\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 771.68it/s]\n",
      "1562it [00:06, 247.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  26\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 762.59it/s]\n",
      "1562it [00:06, 254.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  27\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 775.53it/s]\n",
      "1562it [00:06, 256.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 0m 14s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  28\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 790.58it/s]\n",
      "1562it [00:05, 264.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Time: 0m 13s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  29\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 805.11it/s] \n",
      "1562it [00:06, 254.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 0m 13s\tTrain Loss: 1.517 | Test Loss: 1.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(featureExtractor, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(featureExtractor, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efda5d61dd0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[0.1600, 0.1794, 0.1676, 0.1718, 0.3212]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[0.1682, 0.1791, 0.2008, 0.2643, 0.1876]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[0.1505, 0.1541, 0.3948, 0.1504, 0.1503]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[0.3420, 0.1766, 0.1622, 0.1594, 0.1597]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[0.1524, 0.1585, 0.1523, 0.1571, 0.3797]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[0.3249, 0.1736, 0.1743, 0.1643, 0.1629]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = featureExtractor.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12695.,  3270.,  2201.,   867.,   921.],\n",
      "        [ 5947.,  6783.,  4460.,  1347.,  1335.],\n",
      "        [ 2436.,  3331.,  9022.,  3800.,  1318.],\n",
      "        [  702.,   674.,  2909., 10226.,  5658.],\n",
      "        [  495.,   452.,   565.,  2264., 16290.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(64453.)\n",
      "diag:  tensor(55016.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep =30\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
