{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20164"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Here we extract the words that have more impact on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only considering the 20000 most common words\n",
    "## We convert all other words to N0O0N, which indicate unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpora, Get DataLoader Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:44<00:00, 1161.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:26<00:00, 1159.81it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor\n",
    "# Here, one hot embedding is used\n",
    "## A score for each words is a trainable vector. Higher means positive word, lower means negative word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.embedding = nn.functional.one_hot(torch.arange(input_dim).cuda(3))\n",
    "        \n",
    "        # The Initialization below does not work. Initial in the next cell's next cell!\n",
    "        vector_weights = [30000.0]*input_dim\n",
    "        self.vector_weights = nn.Parameter(torch.tensor(vector_weights, requires_grad=True).cuda(3))\n",
    "\n",
    "        \n",
    "\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = torch.sum(self.embedding[src],dim=2)\n",
    "        emb = torch.tensor(emb, dtype=torch.float)\n",
    "        w = self.vector_weights[src]\n",
    "        # A Vector of Batch_size * 1\n",
    "        z = torch.sum(w*emb,dim=1)\n",
    "\n",
    "\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Weights Initialization Goes Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "\n",
    "# initialize the model\n",
    "featureExtractor = FeatureExtractor(INPUT_DIM).cuda(3)\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "featureExtractor.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(featureExtractor.parameters())\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    global num_epochs_train\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "\n",
    "        num_batchs += 1\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        # absolution distance loss\n",
    "        # About 0.8 after 1st ephoch (regression loss)\n",
    "        loss= sum(abs(z - torch.tensor(batch[1]-3).cuda(3)))/BATCH_SIZE\n",
    "\n",
    "        # loss= torch.sqrt(sum(pow(z - torch.tensor(batch[1]).cuda(3),2)))/BATCH_SIZE\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))       \n",
    "        # absolution distance loss\n",
    "        loss= sum(abs(z - (torch.tensor(batch[1]-3).cuda(3))))/BATCH_SIZE      \n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "6250it [00:26, 235.55it/s]\n",
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "1562it [00:04, 360.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 30s\tTrain Loss: 0.823 | Test Loss: 0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(featureExtractor, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(featureExtractor, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe7388f5510>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watered',\n",
       " '\"save',\n",
       " 'fake!',\n",
       " 'horrible.',\n",
       " '\"worst',\n",
       " 'case!',\n",
       " 'disgusting.',\n",
       " '\"broke',\n",
       " 'disappointing!',\n",
       " 'worst.',\n",
       " 'unhappy',\n",
       " 'fake.',\n",
       " 'disappointed!\"',\n",
       " 'dissapointing.',\n",
       " 'awful.',\n",
       " 'ridiculous!',\n",
       " 'worst',\n",
       " 'smut',\n",
       " 'fake.\"',\n",
       " 'instead,',\n",
       " 'worthless.\"',\n",
       " 'disappointed\"',\n",
       " 'scam.',\n",
       " 'disappointing.\"',\n",
       " 'fake,',\n",
       " 'gross.',\n",
       " 'ridiculous',\n",
       " 'trash.\"',\n",
       " 'weighs',\n",
       " 'dre',\n",
       " 'salinger',\n",
       " 'worthless',\n",
       " 'erotica.',\n",
       " 'rubbish.',\n",
       " 'disappointment.',\n",
       " 'phone!!',\n",
       " '0',\n",
       " 'drivel',\n",
       " 'garbage!',\n",
       " 'muslim',\n",
       " 'embarrassed',\n",
       " 'gross.\"',\n",
       " 'that?\"',\n",
       " 'hated',\n",
       " 'upset.',\n",
       " 'chips',\n",
       " 'owns',\n",
       " 'refund',\n",
       " 'useless.\"',\n",
       " 'stinks!']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.argsort(featureExtractor.vector_weights)[0:50]\n",
    "top50_words = []\n",
    "for i in top50:\n",
    "    top50_words.append(corpora.index_word[i])\n",
    "            \n",
    "top50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['razor,',\n",
       " 'good.i',\n",
       " 'facial.',\n",
       " 'calms',\n",
       " '\"heats',\n",
       " 'cleared',\n",
       " 'habit.',\n",
       " 'bleeding',\n",
       " 'tan!',\n",
       " 'qtips',\n",
       " 'sooner.',\n",
       " '\"helps',\n",
       " 'diva',\n",
       " 'squatty',\n",
       " 'tanners',\n",
       " 'similar,',\n",
       " 'delighted',\n",
       " 'salon!',\n",
       " 'amazing!\"',\n",
       " 'stamping',\n",
       " 'quickly!',\n",
       " 'haha',\n",
       " 'favorite!',\n",
       " 'biggie',\n",
       " 'stamping.',\n",
       " 'trick!',\n",
       " 'yrs.',\n",
       " 'odor,',\n",
       " 'curlers.',\n",
       " 'subscribe',\n",
       " 'since!',\n",
       " 'norelco.',\n",
       " 'q-tips.',\n",
       " 'diaper',\n",
       " 'flu',\n",
       " 'great-',\n",
       " 'excelente',\n",
       " 'compliments',\n",
       " '\"best',\n",
       " 'compliments.',\n",
       " 'gallon',\n",
       " 'disappoint!',\n",
       " 'healed',\n",
       " 'pampers',\n",
       " 'aspiring',\n",
       " 'fitbit',\n",
       " '\"tastes',\n",
       " 'sucking',\n",
       " 'works!']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot50 = torch.argsort(featureExtractor.vector_weights)[-50:-1]\n",
    "bot50_words = []\n",
    "for i in bot50:\n",
    "    bot50_words.append(corpora.index_word[i])\n",
    "            \n",
    "bot50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-0.9500, -0.8548, -0.7669,  ...,  0.7251,  0.7679,  0.8315],\n",
       "       device='cuda:3', grad_fn=<SortBackward0>),\n",
       "indices=tensor([ 3601, 10945,  9690,  ...,  6590,   569, 16209], device='cuda:3'))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.sort(featureExtractor.vector_weights)\n",
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0070, -0.2668,  0.0170,  0.1314, -0.1022, -0.0377,  0.2260, -0.0100,\n",
       "        -0.0050,  0.0049], device='cuda:3', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureExtractor.vector_weights[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N0O0N', '\"not', '', 'once', 'touch', 'water,', 'gone!', 'light', 'on', 'to']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpora.word_index.keys())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that the forward function we do not consider the sentence length, so all values are arround zero, because the training minimized the impact of sentence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# Below is a Classifier using the extracted features\n",
    "1. use the same corporous\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
