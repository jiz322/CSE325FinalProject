{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32592"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Here we extract the words that have more impact on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only considering the 20000 most common words\n",
    "## We convert all other words to N0O0N, which indicate unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpora, Get DataLoader Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:55<00:00, 1126.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:28<00:00, 1126.13it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor\n",
    "# Here, one hot embedding is used\n",
    "## A score for each words is a trainable vector. Higher means positive word, lower means negative word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.embedding = nn.functional.one_hot(torch.arange(input_dim).cuda(3))\n",
    "        \n",
    "        # The Initialization below does not work. Initial in the next cell's next cell!\n",
    "        vector_weights = [30000.0]*input_dim\n",
    "        self.vector_weights = nn.Parameter(torch.tensor(vector_weights, requires_grad=True).cuda(3))\n",
    "\n",
    "        \n",
    "\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = torch.sum(self.embedding[src],dim=2)\n",
    "        emb = torch.tensor(emb, dtype=torch.float)\n",
    "        w = self.vector_weights[src]\n",
    "        # A Vector of Batch_size * 1\n",
    "        z = torch.sum(w*emb,dim=1)\n",
    "\n",
    "\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Weights Initialization Goes Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "\n",
    "# initialize the model\n",
    "featureExtractor = FeatureExtractor(INPUT_DIM).cuda(3)\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "featureExtractor.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(featureExtractor.parameters())\n",
    "\n",
    "\n",
    "tmp = optimizer.state_dict()\n",
    "tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "optimizer.load_state_dict(tmp)\n",
    "print(optimizer)\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer,  clip, num_epochs=0):\n",
    "    \n",
    "    global num_epochs_train\n",
    "    if num_epochs_train == 2:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 5:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0001\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 7:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00006\n",
    "        optimizer.load_state_dict(tmp)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "\n",
    "    \n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        \n",
    "          # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        num_batchs += 1\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        # absolution distance loss\n",
    "        # About 0.8 after 1st ephoch (regression loss)\n",
    "        loss= sum(abs(z - torch.tensor(batch[1]-3).cuda(3)))/BATCH_SIZE\n",
    "\n",
    "        # loss= torch.sqrt(sum(pow(z - torch.tensor(batch[1]).cuda(3),2)))/BATCH_SIZE\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))       \n",
    "        # absolution distance loss\n",
    "        loss= sum(abs(z - (torch.tensor(batch[1]-3).cuda(3))))/BATCH_SIZE      \n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "6250it [00:25, 243.06it/s]\n",
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "1562it [00:03, 397.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 29s\tTrain Loss: 0.856 | Test Loss: 0.800\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 241.29it/s]\n",
      "1562it [00:03, 398.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 29s\tTrain Loss: 0.783 | Test Loss: 0.790\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 241.14it/s]\n",
      "1562it [00:03, 397.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 29s\tTrain Loss: 0.768 | Test Loss: 0.788\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 240.83it/s]\n",
      "1562it [00:03, 399.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 29s\tTrain Loss: 0.763 | Test Loss: 0.787\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:26, 239.80it/s]\n",
      "1562it [00:03, 399.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 29s\tTrain Loss: 0.760 | Test Loss: 0.787\n",
      "epoch start:  5\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 219.99it/s]\n",
      "1562it [00:04, 359.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 32s\tTrain Loss: 0.755 | Test Loss: 0.787\n",
      "epoch start:  6\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 217.98it/s]\n",
      "1562it [00:04, 359.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 33s\tTrain Loss: 0.754 | Test Loss: 0.787\n",
      "epoch start:  7\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 218.37it/s]\n",
      "1562it [00:04, 359.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 32s\tTrain Loss: 0.753 | Test Loss: 0.787\n",
      "epoch start:  8\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 219.28it/s]\n",
      "1562it [00:04, 360.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 32s\tTrain Loss: 0.752 | Test Loss: 0.787\n",
      "epoch start:  9\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 219.04it/s]\n",
      "1562it [00:04, 360.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 32s\tTrain Loss: 0.752 | Test Loss: 0.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(featureExtractor, training_iterator, optimizer, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(featureExtractor, test_iterator)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc1b2990310>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watered',\n",
       " 'worst',\n",
       " '\"save',\n",
       " 'disgusting.',\n",
       " '\"broke',\n",
       " 'horrible.',\n",
       " '\"terrible',\n",
       " 'hated',\n",
       " '\"worst',\n",
       " 'worst.',\n",
       " 'awful.',\n",
       " 'scam.',\n",
       " 'case!',\n",
       " 'poorly',\n",
       " 'worse',\n",
       " 'embarrassed',\n",
       " 'gross.',\n",
       " 'disappointment.',\n",
       " 'ruined',\n",
       " 'throwing',\n",
       " 'dissatisfied',\n",
       " 'terrible.',\n",
       " 'garbage.\"',\n",
       " 'disappointed\"',\n",
       " 'threw',\n",
       " 'zero',\n",
       " 'waste',\n",
       " 'juicer',\n",
       " 'salinger',\n",
       " 'smut',\n",
       " 'fake.',\n",
       " 'sucks!\"',\n",
       " 'horribly.',\n",
       " 'unhappy',\n",
       " 'dissatisfied.',\n",
       " 'whatsoever.',\n",
       " 'terrible',\n",
       " 'fake!',\n",
       " 'ridiculous',\n",
       " 'yuck.',\n",
       " 'worse.',\n",
       " 'weighs',\n",
       " 'pretentious',\n",
       " 'garbage!',\n",
       " 'ridiculous!',\n",
       " 'beware!',\n",
       " 'trash.\"',\n",
       " 'fake,',\n",
       " 'trash.',\n",
       " 'horrible!']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.argsort(featureExtractor.vector_weights)[0:50]\n",
    "top50_words = []\n",
    "for i in top50:\n",
    "    top50_words.append(corpora.index_word[i])\n",
    "            \n",
    "top50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perfect!',\n",
       " 'amazing!\"',\n",
       " 'gifts.',\n",
       " 'biting',\n",
       " 'haha',\n",
       " 'diapers.',\n",
       " 'shaver,',\n",
       " 'great!!!',\n",
       " \"annie's\",\n",
       " 'maldon',\n",
       " 'tweezers.',\n",
       " 'stamping.',\n",
       " 'fabulous',\n",
       " 'amazing.\"',\n",
       " 'gorgeous!',\n",
       " 'awesome!',\n",
       " '\"heats',\n",
       " 'daddy',\n",
       " 'best!',\n",
       " 'add-on',\n",
       " 'trick!',\n",
       " 'dermatologist,',\n",
       " 'diaper',\n",
       " 'amazing.',\n",
       " 'sooner.',\n",
       " 'subscribe',\n",
       " 'tweezer',\n",
       " '\"tastes',\n",
       " 'disappoint.',\n",
       " 'compliments',\n",
       " 'pampers',\n",
       " 'gallon',\n",
       " 'works!!',\n",
       " 'cabello',\n",
       " 'curlers.',\n",
       " 'amazing!',\n",
       " 'norelco.',\n",
       " 'works!!!',\n",
       " 'diva',\n",
       " '\"love',\n",
       " 'cleared',\n",
       " 'compliments.',\n",
       " 'excelente',\n",
       " 'healed',\n",
       " '\"best',\n",
       " 'swabs',\n",
       " 'works!',\n",
       " 'sucking',\n",
       " 'fitbit']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot50 = torch.argsort(featureExtractor.vector_weights)[-50:-1]\n",
    "bot50_words = []\n",
    "for i in bot50:\n",
    "    bot50_words.append(corpora.index_word[i])\n",
    "            \n",
    "bot50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-0.8095, -0.7767, -0.6749,  ...,  0.6942,  0.7051,  0.7353],\n",
       "       device='cuda:3', grad_fn=<SortBackward0>),\n",
       "indices=tensor([ 3601,  2218, 10945,  ...,  6590, 11934, 16209], device='cuda:3'))"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.sort(featureExtractor.vector_weights)\n",
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0211, -0.2614,  0.0035,  0.0702, -0.0514,  0.0104,  0.3373, -0.0008,\n",
       "         0.0053, -0.0119], device='cuda:3', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureExtractor.vector_weights[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N0O0N', '\"not', '', 'once', 'touch', 'water,', 'gone!', 'light', 'on', 'to']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpora.word_index.keys())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that the forward function we do not consider the sentence length, so all values are arround zero, because the training minimized the impact of sentence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# Below is a Classifier using the extracted features\n",
    "1. use the same corporous\n",
    "2. Draw 4 lines that classiy the sum of features into 5 possible classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import embedding, nn\n",
    "\n",
    "# Draw 4 lines that classiy the sum of features into 5 possible classes\n",
    "# Use device 2!\n",
    "\n",
    "feature_4_classify = featureExtractor.vector_weights.clone().detach().cuda(3)\n",
    "\n",
    "\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        \n",
    "        # The Initialization \n",
    "        \n",
    "        lines = [[-2.0, -1.0, 0.0, 1.0, 2.0]]\n",
    "        self.register_parameter(name='lines', param=torch.nn.Parameter(torch.tensor(lines, requires_grad=True)))\n",
    "        #self.lines = nn.Parameter(torch.tensor(lines, requires_grad=True).cuda(3))\n",
    "        \n",
    "                                  \n",
    "\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "                                  \n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        z = torch.sum(featureExtractor.vector_weights[src],dim=1)\n",
    "        #print(self.lines.data[0][0])\n",
    "        l = torch.tensor(0.0).cuda(3)\n",
    "        for i in range(len(z)):\n",
    "            if i < self.lines.data[0][0]:\n",
    "                z[i] = 1.0\n",
    "                l += abs(self.lines.data[0][0])\n",
    "            elif i < self.lines.data[0][1]:\n",
    "                z[i] = 2.0\n",
    "                l += abs(self.lines.data[0][1])\n",
    "            elif i < self.lines.data[0][2]:\n",
    "                z[i] = 3.0\n",
    "                l += abs(self.lines.data[0][2])\n",
    "            elif i < self.lines.data[0][3]:\n",
    "                z[i] = 4.0\n",
    "                l += abs(self.lines.data[0][3])\n",
    "            else:\n",
    "                z[i] = 5.0\n",
    "                l += abs(self.lines.data[0][4])\n",
    "            \n",
    "        return z, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-2., -1.,  0.,  1.,  2.]], device='cuda:3', requires_grad=True)]\n",
      "{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0]}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize the model\n",
    "lc = LinearClassifier().cuda(3)\n",
    "print(list(lc.parameters()))\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(lc.parameters())\n",
    "#optimizer.add_param_group(lc.parameters())\n",
    "print(optimizer.state_dict())\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7fc1b2ca0d50>\n"
     ]
    }
   ],
   "source": [
    "print(lc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, clip, num_epochs=0):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    global num_epochs_train\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "\n",
    "        num_batchs += 1\n",
    "        z, l = lc.forward(batch[0])\n",
    "        #batch[1].cuda(3)\n",
    "        # absolution distance loss\n",
    "        # About 0.8 after 1st ephoch (regression loss)\n",
    "        loss= (sum(abs(z.cuda(3) - batch[1].cuda(3))) +  0.5*l)/BATCH_SIZE\n",
    "\n",
    "        # loss= torch.sqrt(sum(pow(z - torch.tensor(batch[1]).cuda(3),2)))/BATCH_SIZE\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z, l = lc.forward(batch[0].cuda(3))       \n",
    "        # absolution distance loss\n",
    "        loss= (sum(abs(z.cuda(3) - batch[1].cuda(3))) + 0.5*l)/BATCH_SIZE   \n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [02:01, 51.52it/s]\n",
      "1562it [00:15, 100.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 16s\tTrain Loss: 2.012 | Test Loss: 2.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(lc, training_iterator, optimizer, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(lc, test_iterator)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0201,  0.0136, -0.0395,  0.0689,  0.0404]], device='cuda:3',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0091, -0.2918, -0.0111,  ...,  0.0263, -0.2554, -0.0166],\n",
       "       device='cuda:3', requires_grad=True)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureExtractor.vector_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5.], device='cuda:3',\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.forward(list(training_iterator.batch_sampler)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   20,    21,     0,  ...,  6248,   131,     0],\n",
       "        [   40,  2163,   120,  ...,   110,  2512,  8327],\n",
       "        [   99,    21,   131,  ...,    37,  2308,  2085],\n",
       "        ...,\n",
       "        [  206,   124,    30,  ...,   131,    27,  1808],\n",
       "        [ 2455,  3505,   374,  ...,   419,     9,  5266],\n",
       "        [   30,   283,   374,  ...,   101, 17065,  9018]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(training_iterator.batch_sampler)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
