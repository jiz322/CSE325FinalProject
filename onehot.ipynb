{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20692"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class LSTMScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.embedding = nn.functional.one_hot(torch.arange(input_dim).cuda(3))\n",
    "        vector_weights = [3.0]*input_dim\n",
    "        self.vector_weights = nn.Parameter(torch.tensor(vector_weights, requires_grad=True).cuda(3))\n",
    "\n",
    "        \n",
    "\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = torch.sum(self.embedding[src],dim=2)\n",
    "        emb = torch.tensor(emb, dtype=torch.float)\n",
    "        w = self.vector_weights[src]\n",
    "        z = torch.sum(w*emb,dim=1)\n",
    "        \n",
    "        # A Vector of Batch_size * 1\n",
    "        return z/src.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:52<00:00, 1133.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:25<00:00, 1167.58it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "\n",
    "# initialize the model\n",
    "ScoreAssigner = LSTMScoreAssigner(INPUT_DIM).cuda(3)\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "# criterion = nn.CrossEntropyLoss(reduction = 'sum', ignore_index = PAD_INDEX)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    global num_epochs_train\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "\n",
    "        num_batchs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3))\n",
    "\n",
    "        # absolution distance loss\n",
    "        loss= sum(abs(z - torch.tensor(batch[1]).cuda(3)))/BATCH_SIZE\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3))\n",
    "        \n",
    "         # absolution distance loss\n",
    "        loss= sum(abs(z - torch.tensor(batch[1]).cuda(3)))/BATCH_SIZE\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        z = z+0.5\n",
    "        z = torch.tensor(z, dtype=torch.int)\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(z)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(z[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "6250it [00:26, 240.06it/s]\n",
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "1562it [00:08, 180.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 34s\tTrain Loss: 1.373 | Test Loss: 0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f769aca0ed0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([1.], device='cuda:3', grad_fn=<SoftmaxBackward0>) z:  tensor([7.9042], device='cuda:3', grad_fn=<DivBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([1.], device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([1.], device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([1.], device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([1.], device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([1.], device='cuda:3', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d, \"z: \", z)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19954.,     0.,     0.,     0.,     0.],\n",
      "        [19872.,     0.,     0.,     0.,     0.],\n",
      "        [19907.,     0.,     0.,     0.,     0.],\n",
      "        [20169.,     0.,     0.,     0.,     0.],\n",
      "        [20066.,     0.,     0.,     0.,     0.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(200457.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[0][i][j]*abs(i-j)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'waste',\n",
       " 'refund',\n",
       " 'wasted',\n",
       " 'trash.',\n",
       " 'horrible.',\n",
       " 'threw',\n",
       " 'poorly',\n",
       " 'throwing',\n",
       " 'terrible.',\n",
       " 'nothing.',\n",
       " 'horrible',\n",
       " 'junk.',\n",
       " 'garbage',\n",
       " 'refund.',\n",
       " '\"terrible',\n",
       " 'terrible',\n",
       " 'garbage.',\n",
       " 'return',\n",
       " 'money',\n",
       " 'fake.',\n",
       " 'hated',\n",
       " 'returning',\n",
       " 'wast',\n",
       " 'unhappy',\n",
       " 'awful.',\n",
       " 'scam.',\n",
       " 'rip',\n",
       " '\"do',\n",
       " 'defective.',\n",
       " 'worse',\n",
       " 'trash',\n",
       " 'money.',\n",
       " 'money!\"',\n",
       " 'crap',\n",
       " 'useless',\n",
       " 'drivel.',\n",
       " '\"worst',\n",
       " 'worthless',\n",
       " 'counterfeit',\n",
       " 'poor',\n",
       " 'zero',\n",
       " 'junk',\n",
       " 'returned',\n",
       " 'attempted',\n",
       " 'money.\"',\n",
       " 'broke',\n",
       " 'deleted',\n",
       " 'junk!',\n",
       " 'worse.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.argsort(ScoreAssigner.vector_weights)[0:50]\n",
    "top50_words = []\n",
    "for i in top50:\n",
    "    top50_words.append(corpora.index_word[i])\n",
    "            \n",
    "top50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tanning',\n",
       " 'smooth',\n",
       " 'glad',\n",
       " 'beauty',\n",
       " 'moisturizer',\n",
       " 'beautiful',\n",
       " 'gives',\n",
       " 'winter',\n",
       " 'iron.',\n",
       " 'recommended',\n",
       " 'curls',\n",
       " 'straightener',\n",
       " 'great',\n",
       " 'razor',\n",
       " 'awesome',\n",
       " 'excellent',\n",
       " 'skin',\n",
       " 'product!',\n",
       " 'dotting',\n",
       " 'pleased',\n",
       " '\"great',\n",
       " 'favorite',\n",
       " 'brushes',\n",
       " 'compliments',\n",
       " ':)',\n",
       " 'wonders',\n",
       " 'iron',\n",
       " 'gentle',\n",
       " ':)\"',\n",
       " 'foundation',\n",
       " 'heats',\n",
       " 'dermatologist',\n",
       " 'highly',\n",
       " 'nails.',\n",
       " 'perfect',\n",
       " 'amazing.',\n",
       " 'years.',\n",
       " 'nail',\n",
       " 'lasts',\n",
       " 'exactly',\n",
       " '\"love',\n",
       " 'wonderful',\n",
       " 'helps',\n",
       " 'years',\n",
       " 'best',\n",
       " 'makeup',\n",
       " 'salon',\n",
       " 'nails',\n",
       " 'love']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot50 = torch.argsort(ScoreAssigner.vector_weights)[-50:-1]\n",
    "bot50_words = []\n",
    "for i in bot50:\n",
    "    bot50_words.append(corpora.index_word[i])\n",
    "            \n",
    "bot50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(99968.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(confusion_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-6.0568, -6.0236, -5.6498,  ...,  7.9353,  8.0811,  8.0910],\n",
       "       device='cuda:3', grad_fn=<SortBackward0>),\n",
       "indices=tensor([2218,  729, 6528,  ...,  799,   20, 2360], device='cuda:3'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.sort(ScoreAssigner.vector_weights)\n",
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
