{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30103"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('5', 'skin friendly product.i strongly recommend this product for dry skin treatment.no side effect.no burning after application.light smell with moisture.like it')\n",
      "['1', '5', '3', '4', '2']\n",
      "{'1': 8210, '5': 61842, '4': 16420, '3': 8199, '2': 5324}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_500000_not_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"i\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.25'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "        # NB: COMMENT OUT the line below will do less data-preprocess,\n",
    "        # but a little bit lower performance\n",
    "        \n",
    "        \n",
    "            \n",
    "            input = convert(input)           \n",
    "            \n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [11:39<00:00, 572.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:53<00:00, 576.35it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 3945\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 3945\n",
      "Training second batch max length = 1258\n",
      "Training last batch max length = 13\n",
      "Training second last batch max length = 14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class LSTMScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        # before output, there is a dropout (except the last layer)\n",
    "        \n",
    "        if bidirectional == 0:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, batch_first=True)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 1\n",
    "        elif bidirectional == 1:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 2\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # -- COMMENT\n",
    "    # -- The src means sourse, which is a 2d array batch_size by sentence_len, it is a big 2d tensor\n",
    "    def forward(self, src, ep=500):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = self.embedding(src)\n",
    "        output = self.rnn(emb)[1][0]\n",
    "        logit = self.fc(output)\n",
    "\n",
    "        return logit.squeeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jiz322/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "OUTPUT_DIM = 5\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 64\n",
    "N_LAYERS = 1 # number of LSTM layers.\n",
    "BIDIRECT = 0 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "# initialize the model\n",
    "ScoreAssigner = LSTMScoreAssigner(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECT).cuda(1)\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded words\n",
    "# and the loss function should also take padded value into consideration.\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    \n",
    "\n",
    "    if num_epochs_train == 2:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 3:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.000125\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 5:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00002\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(1),ep=num_epochs_train)\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(1))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(1))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(1))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:41, 151.22it/s]\n",
      "1562it [00:07, 212.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 48s\tTrain Loss: 1.287 | Test Loss: 1.286\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:37, 166.61it/s]\n",
      "1562it [00:07, 213.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 44s\tTrain Loss: 1.286 | Test Loss: 1.286\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:37, 166.62it/s]\n",
      "1562it [00:07, 213.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 44s\tTrain Loss: 1.286 | Test Loss: 1.286\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:37, 166.79it/s]\n",
      "1562it [00:07, 212.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 44s\tTrain Loss: 1.286 | Test Loss: 1.286\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:37, 168.04it/s]\n",
      "1562it [00:07, 213.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 44s\tTrain Loss: 1.286 | Test Loss: 1.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'may5th_lst_hid_rnn_not_balanced.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f61f086e790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'peice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ccf1afe6911f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mseq5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mseq6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'peice'"
     ]
    }
   ],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(1)\n",
    "seq2 = torch.tensor([seq2]).cuda(1)\n",
    "seq3 = torch.tensor([seq3]).cuda(1)\n",
    "seq4 = torch.tensor([seq4]).cuda(1)\n",
    "seq5 = torch.tensor([seq5]).cuda(1)\n",
    "seq6 = torch.tensor([seq6]).cuda(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2faaaee1d391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScoreAssigner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Example: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nprediction: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScoreAssigner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-78db2a7a0031>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, ep)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \"\"\"\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.,     0.,     0.,     0.,  8209.],\n",
      "        [    0.,     0.,     0.,     0.,  5325.],\n",
      "        [    0.,     0.,     0.,     0.,  8199.],\n",
      "        [    0.,     0.,     0.,     0., 16414.],\n",
      "        [    0.,     0.,     0.,     0., 61821.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(81623.)\n",
      "diag:  tensor(61821.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep = 5\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499840.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(confusion_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
