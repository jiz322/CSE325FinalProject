{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13963"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Here we extract the words that have more impact on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only considering the 20000 most common words\n",
    "## We convert all other words to N0O0N, which indicate unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpora, Get DataLoader Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:52<00:00, 1135.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:27<00:00, 1139.29it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor\n",
    "# Here, one hot embedding is used\n",
    "## A score for each words is a trainable vector. Higher means positive word, lower means negative word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
       "        [ 0.5099,  0.4205,  1.0448, -1.4512, -1.7122],\n",
       "        [-0.0107,  0.1870, -0.0271, -0.0311,  0.1257],\n",
       "        ...,\n",
       "        [ 0.3331, -0.1641, -0.0194, -0.6917, -0.2053],\n",
       "        [-0.2155,  0.2724,  0.4009, -0.5545, -0.8262],\n",
       "        [-0.1014, -0.1260, -0.2298, -0.1653,  0.1523]], device='cuda:3')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('results/5_embs.pkl', 'rb') as f:\n",
    "    weight = pickle.load(f)\n",
    "weight = weight.clone().detach().requires_grad_(False)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0278,  0.0184, -0.0036,  0.0028,  0.0030],\n",
      "        [-0.0835, -0.0403,  0.0187, -0.0716, -0.0894],\n",
      "        [ 0.0062,  0.0201, -0.0240, -0.0098,  0.0135],\n",
      "        ...,\n",
      "        [ 0.0598, -0.0433, -0.0243,  0.0710,  0.0373],\n",
      "        [-0.0661,  0.0212,  0.0146, -0.0423, -0.0408],\n",
      "        [ 0.0097, -0.0323,  0.0269, -0.0234,  0.0162]], device='cuda:3',\n",
      "       requires_grad=True)\n",
      "tensor([[   0,   58,    9,  ...,    0,    2, 8740],\n",
      "        [ 433,   20,   21,  ...,    0,    0,    0],\n",
      "        [ 433,  122,   17,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 121,  764,  872,  ...,    0,    0,    0],\n",
      "        [  30,  122,   88,  ...,    0,    0,    0],\n",
      "        [ 181, 2277, 1463,  ...,    0,    0,    0]])\n",
      "torch.Size([64, 78, 5])\n",
      "torch.Size([64, 78, 5])\n",
      "tensor([[[ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [-0.0779,  0.0259,  0.1976,  0.1068,  0.1283],\n",
      "         [-0.0427,  0.2994,  0.1648,  0.1368, -0.1537],\n",
      "         ...,\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [-0.0107,  0.1870, -0.0271, -0.0311,  0.1257],\n",
      "         [ 0.3315, -0.7387,  0.1098, -0.5437, -0.1625]],\n",
      "\n",
      "        [[-0.2574,  0.0804, -0.0577,  0.0507,  0.1756],\n",
      "         [-3.0133, -0.3478, -1.1178, -0.2130,  2.2009],\n",
      "         [ 0.4676,  0.1433, -0.9236, -0.2774,  0.4659],\n",
      "         ...,\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622]],\n",
      "\n",
      "        [[-0.2574,  0.0804, -0.0577,  0.0507,  0.1756],\n",
      "         [ 0.2146,  0.0908,  0.1520, -0.2968, -0.2514],\n",
      "         [ 1.1031,  0.3379,  0.1246, -1.5291, -1.5381],\n",
      "         ...,\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0478, -0.3881,  0.3849, -0.0347, -0.5657],\n",
      "         [ 0.7610,  0.3858,  0.1071, -0.4581, -1.0541],\n",
      "         [-1.0882,  0.0738,  0.8402,  0.4023, -1.0200],\n",
      "         ...,\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622]],\n",
      "\n",
      "        [[-0.2107, -0.0775, -0.0692,  0.0378,  0.1064],\n",
      "         [ 0.2146,  0.0908,  0.1520, -0.2968, -0.2514],\n",
      "         [-0.8745,  0.1764, -0.0729,  0.1402,  0.4095],\n",
      "         ...,\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622]],\n",
      "\n",
      "        [[-0.0309,  0.3665,  0.4558, -0.3274, -1.1151],\n",
      "         [-0.5700, -1.1441, -1.0153,  0.5067,  0.7252],\n",
      "         [-0.4407, -0.1072,  0.3580, -0.2914,  0.3974],\n",
      "         ...,\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622],\n",
      "         [ 0.1999,  0.1449, -0.1665, -0.0792,  0.0622]]], device='cuda:3')\n"
     ]
    }
   ],
   "source": [
    "print(featureExtractor.embedding.weight)\n",
    "print(list(test_iterator.batch_sampler)[0][0])\n",
    "print(featureExtractor.embedding(list(test_iterator.batch_sampler)[0][0].cuda(3)).shape)\n",
    "print(featureExtractor.embedding.weight[list(test_iterator.batch_sampler)[0][0].cuda(3)].shape)\n",
    "print(weight[list(test_iterator.batch_sampler)[0][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \n",
    "    # emb_dim = 5, rnn_output_dim = 1, input_dim = len(corpora.word_index)\n",
    "    \n",
    "    def __init__(self, hid_dim, n_layers, bidirectional, dropout):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        emb_dim = 5\n",
    "        # rnn_output_dim = 1\n",
    "        rnn_output_dim = 5\n",
    "        input_dim = len(corpora.word_index)\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        \n",
    "        # Emdeding borrow from 5_embs, which is rigid (does not require grad)\n",
    "        with open('results/5_embs.pkl', 'rb') as f:\n",
    "            weight = pickle.load(f)\n",
    "        self.weight = weight.cuda(3)\n",
    "        \n",
    "        if bidirectional == 0:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout)\n",
    "            self.fc = nn.Linear(hid_dim, 1)\n",
    "            self.num_directions = 1\n",
    "        elif bidirectional == 1:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, bidirectional=True)\n",
    "            self.fc = nn.Linear(hid_dim * 2, rnn_output_dim)\n",
    "            self.num_directions = 2\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "        emb = self.weight[src]\n",
    "        rnn_output = self.fc(self.rnn(emb)[0])\n",
    "        output = emb * rnn_output    # Unsqueeze rnn_output, maybe\n",
    "        z = torch.sum(output,dim=1)\n",
    "        d = torch.softmax(z, dim=-1)\n",
    "\n",
    "\n",
    "        # either z or d should work!\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Weights Initialization Goes Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jiz322/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "HID_DIM = 128\n",
    "N_LAYERS = 1 # number of LSTM layers.\n",
    "BIDIRECT = 1 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# initialize the model\n",
    "featureExtractor = FeatureExtractor(HID_DIM, N_LAYERS, BIDIRECT, DROPOUT).cuda(3)\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "featureExtractor.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(featureExtractor.parameters())\n",
    "\n",
    "\n",
    "tmp = optimizer.state_dict()\n",
    "tmp[\"param_groups\"][0][\"lr\"] = 0.001\n",
    "optimizer.load_state_dict(tmp)\n",
    "print(optimizer)\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "training_losses = []\n",
    "test_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    global num_epochs_train\n",
    "    tmp = optimizer.state_dict()\n",
    "    tmp[\"param_groups\"][0][\"lr\"] = 0.0005/(num_epochs_train + 1)\n",
    "    optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 1:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.0003\n",
    "#     if num_epochs_train == 2:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.0001\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 3:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00005\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00002\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00001\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "    \n",
    "    \n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:54, 114.22it/s]\n",
      "1562it [00:07, 197.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 2s\tTrain Loss: 1.286 | Test Loss: 1.347\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:57, 108.69it/s]\n",
      "1562it [00:07, 196.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 1m 5s\tTrain Loss: 1.284 | Test Loss: 1.346\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:54, 114.94it/s]\n",
      "1562it [00:07, 196.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 1m 2s\tTrain Loss: 1.284 | Test Loss: 1.346\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:54, 114.85it/s]\n",
      "1562it [00:07, 197.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 1m 2s\tTrain Loss: 1.284 | Test Loss: 1.346\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:54, 114.84it/s]\n",
      "1562it [00:07, 197.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 1m 2s\tTrain Loss: 1.283 | Test Loss: 1.347\n",
      "epoch start:  5\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:55, 112.72it/s]\n",
      "1562it [00:07, 195.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 1m 3s\tTrain Loss: 1.283 | Test Loss: 1.346\n",
      "epoch start:  6\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [01:00, 104.05it/s]\n",
      "1562it [00:08, 194.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 1m 8s\tTrain Loss: 1.283 | Test Loss: 1.345\n",
      "epoch start:  7\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [01:01, 101.57it/s]\n",
      "1562it [00:08, 193.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 1m 9s\tTrain Loss: 1.283 | Test Loss: 1.346\n",
      "epoch start:  8\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:59, 105.57it/s]\n",
      "1562it [00:07, 197.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 1m 7s\tTrain Loss: 1.283 | Test Loss: 1.346\n",
      "epoch start:  9\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:53, 116.10it/s]\n",
      "1562it [00:07, 198.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 1m 1s\tTrain Loss: 1.283 | Test Loss: 1.345\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(featureExtractor, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(featureExtractor, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdfc52cbfd0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[0.0369, 0.1991, 0.1043, 0.1285, 0.5312]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[0.0650, 0.1193, 0.2167, 0.4274, 0.1715]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[0.0156, 0.0587, 0.9032, 0.0082, 0.0143]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[0.6853, 0.1619, 0.0533, 0.0383, 0.0611]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[0.0136, 0.0733, 0.0080, 0.0771, 0.8279]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[0.7949, 0.0679, 0.0508, 0.0349, 0.0516]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = featureExtractor.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12734.,  3344.,  2230.,   833.,   813.],\n",
      "        [ 5945.,  6936.,  4522.,  1315.,  1154.],\n",
      "        [ 2424.,  3420.,  9139.,  3775.,  1149.],\n",
      "        [  731.,   745.,  2969., 10311.,  5413.],\n",
      "        [  511.,   504.,   603.,  2452., 15996.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(63734.)\n",
      "diag:  tensor(55116.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep =10\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
