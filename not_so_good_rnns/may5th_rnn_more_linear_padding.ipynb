{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21056"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "        # NB: COMMENT OUT the line below will do less data-preprocess,\n",
    "        # but a little bit lower performance\n",
    "        \n",
    "        \n",
    "            \n",
    "            input = convert(input)\n",
    "            # disabled convertion, \n",
    "                # d = 64152 for using weights \n",
    "                # d = 66405 for pure RNN \n",
    "            # Convert all frequence rank less than 60000:\n",
    "                # d = 63634 for using weight\n",
    "                # d = 65335 for pure RNN\n",
    "            # Convert all frequence rank less than 30000: (better)\n",
    "                # d = 63308 for using weight\n",
    "                # d = - for pure RNN\n",
    "            # Convert all frequence rank less than 20000: \n",
    "                # d = - for using weight\n",
    "                # d = - for pure RNN\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:44<00:00, 1162.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:25<00:00, 1163.88it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class LSTMScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        vector_weights = [0.0]*input_dim\n",
    "        self.vector_weights = nn.Parameter(torch.tensor(vector_weights, requires_grad=True))\n",
    "\n",
    "        # before output, there is a dropout (except the last layer)\n",
    "        \n",
    "        if bidirectional == 0:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 1\n",
    "        elif bidirectional == 1:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, bidirectional=True)\n",
    "            self.fc_pad_1 = nn.Linear(hid_dim * 2, hid_dim * 2)\n",
    "            self.fc_pad_2 = nn.Linear(hid_dim * 2, hid_dim * 2)\n",
    "            self.fc_pad_3 = nn.Linear(hid_dim * 2, hid_dim * 2)\n",
    "            self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
    "            self.num_directions = 2\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.8)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    # -- COMMENT\n",
    "    # -- The src means sourse, which is a 2d array batch_size by sentence_len, it is a big 2d tensor\n",
    "    def forward(self, src, ep=500):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = self.embedding(src)\n",
    "        output = self.rnn(emb)[0]\n",
    "        l1 = self.dropout1(nn.ReLU().forward((self.fc_pad_1(output))))\n",
    "        l2 = self.dropout2(nn.ReLU().forward((self.fc_pad_2(l1))))\n",
    "        l3 = self.dropout(nn.ReLU().forward((self.fc_pad_3(l2))))\n",
    "        logit = self.fc(l3)\n",
    "        logit = torch.swapaxes(logit, 1, 2)\n",
    "        # Limit the range of weight_vector, so rnn gain more weight.\n",
    "        weight_vector = self.vector_weights[src]\n",
    "        \n",
    "        # Pure RNN (without using weight vector)\n",
    "        # Distance: 65335 Loss: 1.355\n",
    "#         rate = 0\n",
    "#         weight_vector[weight_vector>rate] = rate\n",
    "#         weight_vector[weight_vector<-rate] = -rate\n",
    "        \n",
    "        # Distance: 63940 Loss: 1.350\n",
    "#         rate = ep*0.5\n",
    "#         weight_vector[weight_vector>rate] = rate\n",
    "#         weight_vector[weight_vector<-rate] = -rate\n",
    "        \n",
    "\n",
    "        # Without previous tuning\n",
    "        # Distance: 63634 Loss: 1.348\n",
    "        weight_vector = torch.softmax(weight_vector.unsqueeze(dim=2),dim=1)\n",
    "        \n",
    "        return torch.bmm(logit,weight_vector).squeeze(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "OUTPUT_DIM = 5\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 64\n",
    "N_LAYERS = 1 # number of LSTM layers.\n",
    "BIDIRECT = 1 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "# initialize the model\n",
    "ScoreAssigner = LSTMScoreAssigner(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECT).cuda(3)\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded words\n",
    "# and the loss function should also take padded value into consideration.\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "N_EPOCHS = 4\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    if num_epochs_train == 0:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0020\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 1:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0020\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 0:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0015\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 1:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0010\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3),ep=num_epochs_train)\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [01:06, 94.57it/s] \n",
      "1562it [00:08, 175.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 15s\tTrain Loss: 1.450 | Test Loss: 1.404\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [01:11, 86.93it/s]\n",
      "1562it [00:09, 171.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 1m 21s\tTrain Loss: 1.397 | Test Loss: 1.388\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [01:11, 87.77it/s]\n",
      "1562it [00:08, 173.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 1m 20s\tTrain Loss: 1.375 | Test Loss: 1.373\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [01:11, 87.62it/s]\n",
      "1562it [00:08, 175.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 1m 20s\tTrain Loss: 1.362 | Test Loss: 1.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'may5th_rnn_padded.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa795fd39d0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.002 0.002 \n",
    "#1.385\n",
    "\n",
    "# 0.002 0.0025\n",
    "#1.389\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[0.0000e+00, 0.0000e+00, 3.6956e-41, 1.9653e-16, 1.0000e+00]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[1.5338e-29, 7.4614e-15, 6.0975e-06, 9.9999e-01, 5.2655e-10]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[0.0000e+00, 1.5499e-30, 1.0000e+00, 2.5911e-36, 0.0000e+00]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[1., 0., 0., 0., 0.]], device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[2.3927e-13, 1.0182e-07, 3.6274e-06, 1.0685e-01, 8.9315e-01]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[1.0000e+00, 1.9185e-12, 1.2787e-21, 9.7504e-32, 4.4611e-26]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12263.,  3327.,  2821.,   940.,   603.],\n",
      "        [ 7696.,  4373.,  5095.,  1687.,  1021.],\n",
      "        [ 3174.,  3291.,  7826.,  4487.,  1129.],\n",
      "        [  357.,   978.,  3992.,  9927.,  4915.],\n",
      "        [  257.,   968.,  1094.,  4236., 13511.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(68321.)\n",
      "diag:  tensor(51656.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep = 4\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is a list of words that have lowest weight (we see many stop words here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " '',\n",
       " 'i',\n",
       " 'for',\n",
       " 'was',\n",
       " 'take',\n",
       " '\"i',\n",
       " 'it',\n",
       " 'knots',\n",
       " 'time',\n",
       " 'in',\n",
       " 'just',\n",
       " 'of',\n",
       " 'better',\n",
       " 'wavy',\n",
       " 'more',\n",
       " '1st',\n",
       " 'the',\n",
       " 'on',\n",
       " 'convinced',\n",
       " 'been',\n",
       " 'cheek',\n",
       " 'girl',\n",
       " 'fixed',\n",
       " 'up',\n",
       " 'different',\n",
       " 'gone,',\n",
       " 'difference',\n",
       " 'already',\n",
       " 'its',\n",
       " \"i'll\",\n",
       " 'than',\n",
       " 'brown',\n",
       " 'getting',\n",
       " 'tell',\n",
       " 'is',\n",
       " 'redness',\n",
       " 'free.',\n",
       " 'price,',\n",
       " 'else',\n",
       " 'which',\n",
       " 'his',\n",
       " 'less',\n",
       " 'or',\n",
       " 'feel',\n",
       " 'guys',\n",
       " 'enormous',\n",
       " 'belt',\n",
       " 'sized',\n",
       " 'strong']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.argsort(ScoreAssigner.vector_weights)[0:50]\n",
    "top50_words = []\n",
    "for i in top50:\n",
    "    top50_words.append(corpora.index_word[i])\n",
    "            \n",
    "top50_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is a list of words that have highest weight (we see emotional words and name of product and so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['junk.\"',\n",
       " 'joke.',\n",
       " 'return',\n",
       " 'amazing!\"',\n",
       " 'q-tips',\n",
       " 'wast',\n",
       " '\"horrible',\n",
       " 'upset.',\n",
       " 'ok,',\n",
       " 'worthless.',\n",
       " 'fitbit',\n",
       " '\"waste',\n",
       " 'junk!',\n",
       " 'disgusting.',\n",
       " 'scam.',\n",
       " 'poorly',\n",
       " 'junk',\n",
       " 'horrible.',\n",
       " 'drivel',\n",
       " 'horribly.',\n",
       " 'fake.',\n",
       " 'sucking',\n",
       " 'amazing!',\n",
       " 'deleted',\n",
       " 'trash',\n",
       " 'wasted',\n",
       " 'junk.',\n",
       " 'garbage',\n",
       " '\"worst',\n",
       " '\"terrible',\n",
       " 'garbage.\"',\n",
       " 'okay,',\n",
       " 'trash.',\n",
       " 'refund.',\n",
       " 'garbage!',\n",
       " 'ok',\n",
       " 'nothing.',\n",
       " 'worthless',\n",
       " 'okay',\n",
       " '\"do',\n",
       " 'awful.',\n",
       " 'horrible',\n",
       " 'garbage.',\n",
       " 'threw',\n",
       " 'refund',\n",
       " 'terrible.',\n",
       " 'okay.',\n",
       " 'ok.',\n",
       " 'waste']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot50 = torch.argsort(ScoreAssigner.vector_weights)[-50:-1]\n",
    "bot50_words = []\n",
    "for i in bot50:\n",
    "    bot50_words.append(corpora.index_word[i])\n",
    "            \n",
    "bot50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499840.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(confusion_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-0.6710, -0.6438, -0.5750,  ...,  1.0349,  1.3094,  1.3142],\n",
       "       device='cuda:3', grad_fn=<SortBackward0>),\n",
       "indices=tensor([ 101,    2,   30,  ...,  953,  729, 2218], device='cuda:3'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.sort(ScoreAssigner.vector_weights)\n",
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
