{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13223"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class LSTMScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        vector_weights = [1.0/input_dim]*input_dim\n",
    "        self.vector_weights = nn.Parameter(torch.tensor(vector_weights, requires_grad=True))\n",
    "\n",
    "        # before output, there is a dropout (except the last layer)\n",
    "        \n",
    "        # -- Comment: this is a part of the analysis (last part of this hw)\n",
    "        # -- It feels like I have no control on this bidirectional since it is part of nn library.\n",
    "        if bidirectional == 0:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 1\n",
    "        elif bidirectional == 1:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, bidirectional=True)\n",
    "            self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
    "            self.num_directions = 2\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # -- COMMENT\n",
    "    # -- The src means sourse, which is a 2d array batch_size by sentence_len, it is a big 2d tensor\n",
    "    # -- NBBBBB: How to turn the POSTaggedDataset into a big 2d tensor see test_p2 line 4-7\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = self.embedding(src)\n",
    "        output = self.rnn(emb)[0]\n",
    "        logit = self.fc(output)\n",
    "        logit = torch.swapaxes(logit, 1, 2)\n",
    "        weight_vector = self.vector_weights[src]\n",
    "        weight_vector = torch.softmax(weight_vector.unsqueeze(dim=2),dim=1)\n",
    "        \n",
    "        return torch.bmm(logit,weight_vector).squeeze(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:05<00:00, 70402.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:01<00:00, 67068.68it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 340059\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 69\n",
      "Training last batch max length = 8\n",
      "Training second last batch max length = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jiz322/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "INPUT_DIM = len(corpora.word_index)\n",
    "OUTPUT_DIM = 5\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 64\n",
    "N_LAYERS = 1 # number of LSTM layers.\n",
    "BIDIRECT = 1 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "# initialize the model\n",
    "ScoreAssigner = LSTMScoreAssigner(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECT).cuda(3)\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "# criterion = nn.CrossEntropyLoss(reduction = 'sum', ignore_index = PAD_INDEX)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "\n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3))\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = torch.zeros(5,5)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    num_epochs = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        num_epochs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[row][col] += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12500it [02:04, 100.74it/s]\n",
      "3125it [00:08, 360.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 12s\tTrain Loss: 1.402 | Test Loss: 1.391\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa05d17fd10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[9.3191e-27, 1.2549e-18, 1.7037e-19, 1.3128e-10, 1.0000e+00]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[1.1478e-09, 1.8551e-06, 1.5434e-04, 9.9845e-01, 1.3961e-03]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[9.7061e-10, 5.8380e-06, 9.9999e-01, 8.5174e-10, 1.1236e-21]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[1.0000e+00, 7.2335e-08, 2.1581e-14, 2.8666e-19, 8.4362e-16]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[1.3560e-09, 6.8925e-08, 5.1337e-09, 3.5799e-05, 9.9996e-01]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[9.9922e-01, 5.9344e-04, 1.2507e-04, 5.4604e-05, 2.4811e-06]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11084.,  4362.,  1958.,  1077.,  1483.],\n",
      "        [ 5762.,  7071.,  3566.,  1475.,  2004.],\n",
      "        [ 2461.,  4558.,  7163.,  3728.,  2001.],\n",
      "        [  664.,  1065.,  3093.,  8321.,  7034.],\n",
      "        [  540.,   930.,   592.,  1707., 16301.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writer',\n",
       " 'arrived',\n",
       " 'gentle,',\n",
       " \"haven't\",\n",
       " 'they',\n",
       " 'broken.',\n",
       " 'def',\n",
       " 'stuff!\"',\n",
       " 'while',\n",
       " 'got',\n",
       " 'timely',\n",
       " 'mia',\n",
       " 'mid',\n",
       " 'maps.',\n",
       " 'it..',\n",
       " 'surprisingly',\n",
       " 'damaged',\n",
       " 'repetitive.',\n",
       " 'shampoo',\n",
       " 'market,',\n",
       " \"couldn't\",\n",
       " 'very',\n",
       " 'traveling',\n",
       " ',i',\n",
       " 'kept',\n",
       " 'diets',\n",
       " 'feeling',\n",
       " '45',\n",
       " 'plan',\n",
       " 'do',\n",
       " 'sending',\n",
       " 'certainly',\n",
       " 'flow.',\n",
       " 'sad,',\n",
       " 'say',\n",
       " 'cool.\"',\n",
       " 'ipad!',\n",
       " 'uv',\n",
       " 'muy',\n",
       " 'about',\n",
       " 'disappointed!\"',\n",
       " 'reinforced',\n",
       " 'it,it',\n",
       " 'y',\n",
       " 'title',\n",
       " 'with.',\n",
       " 'knock',\n",
       " '\"she',\n",
       " 'customer.',\n",
       " 'green']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.argsort(ScoreAssigner.vector_weights)[0:50]\n",
    "top50_words = []\n",
    "for i in top50:\n",
    "    for j in corpora.word_index.keys():\n",
    "        if corpora.word_index[j] == i:\n",
    "            top50_words.append(j)\n",
    "            continue\n",
    "            \n",
    "top50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75031.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[i][j]*abs(i-j)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
