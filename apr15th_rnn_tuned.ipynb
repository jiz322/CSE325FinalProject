{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12119"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sanitize'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(30000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "        # NB: COMMENT OUT the line below will do less data-preprocess,\n",
    "        # but a little bit lower performance\n",
    "        \n",
    "        \n",
    "            \n",
    "            input = convert(input)\n",
    "            # disabled convertion, \n",
    "                # d = 64152 for using weights \n",
    "                # d = 66405 for pure RNN \n",
    "            # Convert all frequence rank less than 60000:\n",
    "                # d = 63634 for using weight\n",
    "                # d = 65335 for pure RNN\n",
    "            # Convert all frequence rank less than 30000: (better)\n",
    "                # d = 63308 for using weight\n",
    "                # d = - for pure RNN\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [07:18<00:00, 912.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:49<00:00, 917.04it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 30001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class LSTMScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        vector_weights = [0.0]*input_dim\n",
    "        self.vector_weights = nn.Parameter(torch.tensor(vector_weights, requires_grad=True))\n",
    "\n",
    "        # before output, there is a dropout (except the last layer)\n",
    "        \n",
    "        if bidirectional == 0:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 1\n",
    "        elif bidirectional == 1:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, bidirectional=True)\n",
    "            self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
    "            self.num_directions = 2\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # -- COMMENT\n",
    "    # -- The src means sourse, which is a 2d array batch_size by sentence_len, it is a big 2d tensor\n",
    "    def forward(self, src, ep=500):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = self.embedding(src)\n",
    "        output = self.rnn(emb)[0]\n",
    "        logit = self.fc(output)\n",
    "        logit = torch.swapaxes(logit, 1, 2)\n",
    "        # Limit the range of weight_vector, so rnn gain more weight.\n",
    "        weight_vector = self.vector_weights[src]\n",
    "        \n",
    "        # Pure RNN (without using weight vector)\n",
    "        # Distance: 65335 Loss: 1.355\n",
    "#         rate = 0\n",
    "#         weight_vector[weight_vector>rate] = rate\n",
    "#         weight_vector[weight_vector<-rate] = -rate\n",
    "        \n",
    "        # Distance: 63940 Loss: 1.350\n",
    "#         rate = ep*0.5\n",
    "#         weight_vector[weight_vector>rate] = rate\n",
    "#         weight_vector[weight_vector<-rate] = -rate\n",
    "        \n",
    "\n",
    "        # Without previous tuning\n",
    "        # Distance: 63634 Loss: 1.348\n",
    "        weight_vector = torch.softmax(weight_vector.unsqueeze(dim=2),dim=1)\n",
    "        \n",
    "        return torch.bmm(logit,weight_vector).squeeze(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jiz322/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "OUTPUT_DIM = 5\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 64\n",
    "N_LAYERS = 1 # number of LSTM layers.\n",
    "BIDIRECT = 1 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "# initialize the model\n",
    "ScoreAssigner = LSTMScoreAssigner(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECT).cuda(3)\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded words\n",
    "# and the loss function should also take padded value into consideration.\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    \n",
    "    if num_epochs_train == 1:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "    if num_epochs_train == 2:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 3:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.000125\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3),ep=num_epochs_train)\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:59, 104.71it/s]\n",
      "1562it [00:08, 190.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 7s\tTrain Loss: 1.390 | Test Loss: 1.359\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [01:00, 103.06it/s]\n",
      "1562it [00:08, 192.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 1m 8s\tTrain Loss: 1.333 | Test Loss: 1.349\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:59, 105.55it/s]\n",
      "1562it [00:08, 192.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 1m 7s\tTrain Loss: 1.295 | Test Loss: 1.346\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:59, 105.54it/s]\n",
      "1562it [00:08, 192.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 1m 7s\tTrain Loss: 1.282 | Test Loss: 1.346\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:59, 105.22it/s]\n",
      "1562it [00:08, 191.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 1m 7s\tTrain Loss: 1.275 | Test Loss: 1.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7f6de38f10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[1.3435e-30, 8.5743e-21, 1.4174e-18, 4.5723e-12, 1.0000e+00]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[3.8711e-26, 1.5049e-17, 2.0965e-09, 1.0000e+00, 3.3080e-11]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[1.3764e-17, 9.1517e-09, 1.0000e+00, 5.3621e-13, 3.1082e-23]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[1.0000e+00, 9.2076e-13, 2.1429e-22, 6.1281e-31, 5.5617e-24]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[1.2201e-08, 4.8295e-06, 1.0789e-06, 3.0171e-04, 9.9969e-01]],\n",
      "       device='cuda:3', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[0.7983, 0.0912, 0.0891, 0.0158, 0.0056]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11813.,  4840.,  1595.,   811.,   895.],\n",
      "        [ 5610.,  7887.,  3690.,  1422.,  1263.],\n",
      "        [ 1894.,  5274.,  7755.,  3818.,  1166.],\n",
      "        [  473.,  1087.,  2976., 10216.,  5417.],\n",
      "        [  600.,   628.,   381.,  2926., 15531.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(63308.)\n",
      "diag:  tensor(54591.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep = 4\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is a list of words that have lowest weight (we see many stop words here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " '',\n",
       " 'of',\n",
       " 'is',\n",
       " 'a',\n",
       " 'i',\n",
       " 'on',\n",
       " 'in',\n",
       " 'N0O0N',\n",
       " 'my',\n",
       " 'are',\n",
       " 'to',\n",
       " 'what',\n",
       " 'or',\n",
       " '\"i',\n",
       " 'the',\n",
       " 'one',\n",
       " 'be',\n",
       " 'am',\n",
       " 'time',\n",
       " 'and',\n",
       " 'they',\n",
       " 'for',\n",
       " 'have',\n",
       " 'was',\n",
       " 'me',\n",
       " 'come',\n",
       " 'so',\n",
       " 'from',\n",
       " 'up',\n",
       " 'with',\n",
       " 'when',\n",
       " 'do',\n",
       " 'give',\n",
       " 'will',\n",
       " 'get',\n",
       " 'you',\n",
       " 'them',\n",
       " 'just',\n",
       " 'were',\n",
       " 'way',\n",
       " 'at',\n",
       " \"i'm\",\n",
       " 'that',\n",
       " 'different',\n",
       " 'make',\n",
       " 'than',\n",
       " 'go',\n",
       " '-',\n",
       " 'out']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.argsort(ScoreAssigner.vector_weights)[0:50]\n",
    "top50_words = []\n",
    "for i in top50:\n",
    "    top50_words.append(corpora.index_word[i])\n",
    "            \n",
    "top50_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is a list of words that have highest weight (we see emotional words and name of product and so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dan',\n",
       " 'printer',\n",
       " 'netflix',\n",
       " 'special.',\n",
       " 'music',\n",
       " 'keyboard.',\n",
       " 'fitbit',\n",
       " 'worse',\n",
       " 'otterbox',\n",
       " 'ruined',\n",
       " 'keurig',\n",
       " 'cable',\n",
       " 'camera',\n",
       " 'disappointed',\n",
       " 'junk.',\n",
       " 'however',\n",
       " 'stylus',\n",
       " 'zero',\n",
       " 'headset',\n",
       " 'alright.',\n",
       " 'terrible.',\n",
       " 'gps',\n",
       " 'screen',\n",
       " 'sound',\n",
       " 'horrible',\n",
       " 'return',\n",
       " 'hated',\n",
       " 'however,',\n",
       " 'headphones',\n",
       " 'ipad',\n",
       " 'phone.',\n",
       " 'grill',\n",
       " 'complaint',\n",
       " 'horrible.',\n",
       " 'poorly',\n",
       " 'mattress',\n",
       " 'vacuum',\n",
       " 'ok',\n",
       " 'mouse',\n",
       " 'phone',\n",
       " 'okay,',\n",
       " 'ok,',\n",
       " 'keyboard',\n",
       " 'okay',\n",
       " 'iphone',\n",
       " 'worst',\n",
       " 'waste',\n",
       " 'coffee',\n",
       " 'ok.']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot50 = torch.argsort(ScoreAssigner.vector_weights)[-50:-1]\n",
    "bot50_words = []\n",
    "for i in bot50:\n",
    "    bot50_words.append(corpora.index_word[i])\n",
    "            \n",
    "bot50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499840.)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(confusion_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-1.8541, -1.8103, -1.7442,  ...,  1.5508,  1.5598,  1.7333],\n",
       "       device='cuda:3', grad_fn=<SortBackward0>),\n",
       "indices=tensor([  47,    2,  111,  ..., 2440,  971, 5206], device='cuda:3'))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.sort(ScoreAssigner.vector_weights)\n",
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
