{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24253"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "        # NB: COMMENT OUT the line below will do less data-preprocess,\n",
    "        # but a little bit lower performance\n",
    "        \n",
    "        \n",
    "            \n",
    "            input = convert(input)           \n",
    "            \n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:52<00:00, 1134.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:28<00:00, 1135.94it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class LSTMScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        # before output, there is a dropout (except the last layer)\n",
    "        \n",
    "        if bidirectional == 0:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, batch_first=True)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 1\n",
    "        elif bidirectional == 1:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 2\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # -- COMMENT\n",
    "    # -- The src means sourse, which is a 2d array batch_size by sentence_len, it is a big 2d tensor\n",
    "    def forward(self, src, ep=500):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = self.embedding(src)\n",
    "        output = self.rnn(emb)[1][0]\n",
    "        logit = self.fc(output)\n",
    "\n",
    "        return logit.squeeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "OUTPUT_DIM = 5\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 64\n",
    "N_LAYERS = 1 # number of LSTM layers.\n",
    "BIDIRECT = 0 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "# initialize the model\n",
    "ScoreAssigner = LSTMScoreAssigner(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECT).cuda(1)\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded words\n",
    "# and the loss function should also take padded value into consideration.\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    \n",
    "\n",
    "    if num_epochs_train == 2:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 3:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.000125\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 5:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00002\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(1),ep=num_epochs_train)\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(1))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(1))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(1))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 216.63it/s]\n",
      "1562it [00:07, 220.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 35s\tTrain Loss: 1.399 | Test Loss: 1.359\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:29, 209.41it/s]\n",
      "1562it [00:07, 214.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 37s\tTrain Loss: 1.341 | Test Loss: 1.346\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 218.23it/s]\n",
      "1562it [00:07, 220.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 35s\tTrain Loss: 1.301 | Test Loss: 1.340\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 217.53it/s]\n",
      "1562it [00:07, 218.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 35s\tTrain Loss: 1.282 | Test Loss: 1.340\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:29, 211.01it/s]\n",
      "1562it [00:07, 220.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 36s\tTrain Loss: 1.271 | Test Loss: 1.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'apr15th_rnn_tuned.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6c98110850>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD7CAYAAACCEpQdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7vUlEQVR4nO3deVyU5f7/8dc9M+z7zrAoooIL4EZWimZiaipipm1uWdq3Mu30s/Vkdkpb7JzTKS1tNy0rKtPcl/R4DMs1FdwVF5RFZRPZBGbu3x8giqICzjCDfJ6Phw+Zmeu+5z03w+eeua77vm5FVVUVIYQQTYrG0gGEEEI0PCn+QgjRBEnxF0KIJkiKvxBCNEFS/IUQogmS4i+EEE2QFH8hhGiCdJYOUFu5uYUYjXU/JcHLy5ns7AIzJLo5kqtuJFfdWWs2yVU39c2l0Sh4eDhd8/FGU/yNRrVexf/istZIctWN5Ko7a80muerGHLmk20cIIZogKf5CCNEE1arbZ8aMGaxevZq0tDSWLl1KWFjYNdsePXqU++67j0ceeYSXXnoJgOLiYl555RX27t2LVqvlpZde4u677zbNKxBCmIWqquTmnqW0tAQwXbfDmTMajEajydZnKo0zl4KtrT0eHj4oilKn9daq+MfGxjJ69GhGjBhx3XYGg4HXX3+dPn36VLv/yy+/xNnZmbVr13L8+HFGjBjBmjVrcHK69mCEEMKyCgrOoSgKfn5BKIrpOgl0Og3l5dZXZBtjLlU1kpeXRUHBOVxc3Ou03lr9RqOjo9Hr9Tds99lnn9GrVy9CQkKq3b9y5UoefPBBAEJCQoiIiGDjxo11CiqEaFjFxQW4uLibtPAL01IUDS4uHhQX1/1oIJMd7XPgwAESExOZP38+s2fPrvZYeno6gYGBVbf1ej2ZmZl1Wr+Xl3O9s/n4uNR7WXOSXHUjueruZrKdOaNiZ2db5+6E2tDprHOH0hhzabW2gFrn37VJin9ZWRmvvfYa77zzDlqt1hSrvEp2dkGdD3fadzyH7347zMShkfh5OpolV335+Lhw9ux5S8e4iuSqG2vNBTefzWg0YjComLK/Hxpn94ol1SaX0Wi86net0SjX/dBskt3c2bNnSU1N5YknnqB3797MmzePH3/8kddeew2AgIAA0tLSqtpnZGTg7+9viqe+Lj8PRwqKy/jgp90UFJeZ/fmEEObz5ZefUlZWv7/jAwf28cYbU27YLivrLBMn/l+9nuNavvzyUz766AOTrtMUTFL8AwIC2LJlC+vXr2f9+vWMGTOGBx54gGnTpgHQv39/EhISADh+/DjJycn06NHDFE99XV5u9rw6tivZ+SV8/Esy5Qbr26sLIWpn7tzPr1n8y8vLr7tsmzbteP316Td8Dm9vH2bN+rRe+RqbWnX7TJ8+nTVr1pCVlcXYsWNxd3dn+fLljB8/nkmTJhEZGXnd5R9//HFefvll7rnnHjQaDW+++SbOzvXvw6+Ldi28GDugLZ8v3ce8VQd4bEBbs/RhCiHM59//ngHAU089hqJomDXrU2bO/DdarZbU1BMUFRXx9dff8cYbU0hNPUFZWSmBgcG88spUXF1d+euv7Xz88Yd8+eU3ZGSkM27cKAYPHsrmzZsoKSnh5Zen0qVL56rHli9fB0BMTDRPPPE0Gzdu4Ny5c0yYMIlevWIB2LBhHZ99Nhs7OzvuvrsPn302mzVrNuLoeO0uZoPBwJw5s9iy5Q8Abr+9G089NRGtVsuvv/7Cjz9+h42NLapq5M033yU4uBnvvTeD7du3YmNji6OjA3PmfGWSbVqr4j9lyhSmTLn6K9Pnn39eY/uJEydWu+3o6MjMmTPrEc807mzvz+mcIpZsOo6/pyMD7wyxWBYhGqNNyRkkJmWYZF2KApdfOTwmSk/3yOsfTTh58kssWvQTc+Z8Va24Hj58iI8++gwHBwcAnn32edzd3QH47LPZLFgwj6eemnjV+s6dO0dERBT/938TWLNmJZ98MpPPP/+6xud2cnLiiy/mk5S0i6lTX6FXr1hycrJ57723+fTTuQQHNyMhYUGtXvuSJYs4fPgQX31V0f755yexZMki7rtvGLNnf8iCBQvx9vamtLQUo9HIkSOH2LFjG99++xMajYb8/PxaPU9tWOfQthnEx7Tg9nZ+LPzfUbYfOGPpOEIIE+jVK7aq8AOsWrWMxx4byejRD7J27WoOHz5U43IODo50717R9dy+fWS1Mckrxcb2q2qXlXWWCxcusG/fHsLCwgkObgbAwIHxtcq7ffsWBgwYhI2NDTY2NgwYEMf27VsA6Nz5Nt5663V+/vkHzp49g729PQEBQRgM5bz77jRWrVpeq+eorUYzsdvNUhSFxwa0IftcCZ8v24enqz2hAa6WjiVEo9A98safzmvLlEfVODpeKvy7d+9k8eKFzJnzFR4eHqxZs4olS36pcTlbW5uqnzUaDQbDtccMbG1tAaqOZDQYDKaIfpW33/4n+/fvZceO7Uya9CTPP/8Kd97Zne+++5lt27axfftW5syZxVdffYuXl/dNP1+T+eQPYKPT8sz9kbg52TJzYRLZ50osHUkIUUuOjk4UFl77ZKbz58/j5OSMm5sbpaWlLF++xGxZ2rWL4NChg6SlnQJg5cpltVouOvp2Vq5cRnl5OeXl5axcuYzbbrud8vJy0tPTaNcuglGjHqVr1zs4fPggubm5lJSUcPvtd/Lkk8/g7OxMevq1v6XURZP55H+Rq6Mtzw7vwNvf7ODDn3fzysguONg1uc0gRKPz0EMjmDTpSezs7Gs8IueOO7qxZs1KHn54KG5u7nTs2Il9+/aaJYunpxfPP/8Kzz8/CXt7e7p164FOp8Pe3v66yw0efB+nTp1k7NhHAOja9U7i4u7DYDDw1lv/oKDgPIqiwc/PjyeffIbMzEzee2865eUGDAYDd9zRjfbtr3+ATW0pqqpa5wTWV6jPSV5w7RNd9h7P4T8Ju2nfwpNJwyLRahr2S5C1nhwkuerGWnPBzWfLzDyBv39zEyaq0JhPprpcUVEhjo4V85MtX76EZct+Zc6cLy2Sq6bf1Y1O8mqyH3nbh3gysl8Y81cd5Id1Rxhxz7VnKhVCiCv99NMP/Pe/6zAYynF1deOll258Epk1abLFH6BXx0BO5xSxeutJ/Dwc6BMdbOlIQohGYsyYxxkz5nFLx6i3Jl38AYb3asWZ3GK+X3cYXw8Holre/Ci6EEJYuyZ1tE9NNBqFJ+LaE+zrzJxf93LyjPVdwFkIIUytyRd/ADtbLc8O64CDrZYPf97NuYILlo4khBBmJcW/koeLHc8O60BBcRkzFyZxocw8J3IIIYQ1kOJ/meb+Lvzf4PYczzjPF8v2YWwcR8EKIUSdSfG/QqfWPjzQuxU7Dp5l0cajlo4jhKh0M/P512Yd6enpDBwYe1Prb0yk+Neg723B9OoYwPI/T/B7Urql4wghuP58/g25jltFkz/UsyaKovDIPWGczStm/qqDeLs50La5h6VjCWExZYc2UXZwo0nWpSgKl08sYBPeE5uw7tddpqb5/DUahVmz/kNKymFKS0vp1CmaiROfQ6vV8tVXn/Hbb6uxtbVDUWDmzE/57LPZV63DxeXa173dvPkPPv30I4xGI+7uHrzwwt8JCgomNfU4b731BiUlJRiNBu69N45HHhnF779v4PPP56DRaDEYynnuuRfp3Dn6preXuUjxvwadVsNTQyJ465sdzF6UzKujo/G3susAC9FU1DSf/7vvTqNjx868/PJrGI1G3nhjCsuXL6FXr978+ON3/PrrKuzs7CkqKsTW1u6a1wSoSW5uDtOnT2XWrM9o0SKUZcsW88YbU/j883n88svPxMT0ZNSosQBVc+x/8cWnvPjiq0RERGEwGCgpKTbvRrlJUvyvw9Hehr8N78D0+dv54KfdTBkdjbODzY0XFOIWYxPW/YafzmvLVHP7JCZuZP/+vfzwQ8WFUUpKSvD19cPJyZnAwGCmTXudrl3voFu3HlVz8NTW3r17aNkyjBYtQgEYMGAw//73DIqKCunYsROzZ8+kpKSEzp2jqz7dd+kSzcyZ79OrV2/uuKMboaGtbvo1mpMU/xvwcXdg4tAo3vt+Jx8tTGLyQ52w0clQiRCWp/L22/8iMDDoqkc+/XQuycm7+euv7Tz++Ej+/e9ZtGrV2iTP2qtXLBERUWzduplvv/2a5cuXMHXqNCZNmkxKyhF27NjGa6+9zIMPjmDw4PtM8pzmIFWsFloFufHYwDYcOnWOeasO0EgmQhXilnLlfP7du/fk22/nVV1cJS8vj/T0NIqKCsnLy6NTpy48/vj/ERrakqNHU2pcx7W0bx9JSsohTpw4DlTM19+6dTiOjk6cOnUST08vBgyIY+zY8VXTRqemHqdly1Y88MDD9O17L/v37zPxFjAt+eRfS3e08+dMTjGLE4/h7+nIoG4hlo4kRJNy5Xz+zz47mdmzZ/Loow+jKAo2NrZMmjQZnU7Hq6++SGnpBYxGI2FhbbjrrrtrXMe1Bnw9PDyYMuVN3njjVQwGA+7uHkydOg2A9evXsmbNKmxsdCiKwrPPTgZgzpyPOHUqFa1Wh7OzM6+8MrVhNkw9Ndn5/OtDVVW+WLaPP/ee5sn49nRt61fvdVnrPPCSq26sNRfIfP511Zhz1Wc+f+n2qQNFUXj03ra0DnLji2X7SUk7Z+lIQghRLzcs/jNmzKB3796Eh4dz6NChGtssXLiQuLg44uPjiYuLY/78+VWPZWdn88QTTxAXF8e9997LP/7xD8rLr32xZGtno9PwzNBIPFxsmbUwiaw86z6cSwghanLD4h8bG8uCBQsIDAy8Zpt+/fqxZMkSfv31V77//nvmzp3LgQMHAPjkk09o2bIlS5cuZcmSJezdu5c1a9aY7hVYgIujLX8b3oEyg8qHPydRVNJ4d2ZCXE8j6RVu0ur7O7ph8Y+Ojkav11+3jbOzM4qiABXH2paVlVXdVhSFwsJCjEYjpaWllJWV4edX/75ya6H3cmLCfRFk5hTxya97MBitr69QiJtx8UxVYd0MhnI0Gm2dlzPZ0T7r1q3j/fffJzU1lcmTJxMeHg7A008/zcSJE4mJiaG4uJgRI0bQpUuXOq//egMXN+Ljc+1TuG/GXT4ulBjgo592sSjxOE8Ojara6Vky182SXHVjrbng5rKpqhfnz5/Dw8MbRTHt8KDOSs+VaWy5VNXIuXPn8PHxqvPv2mTFPzY2ltjYWNLT05kwYQI9e/YkNDSUVatWER4ezrx58ygsLGT8+PGsWrWK/v3712n91nC0T006t/Sk/+3NWPHHcdwcbbinltcBttajRCRX3VhrLjBFNnvKy8+TlpYKmK77R6PRYLTCb8qNM5eCra09YH/V7/pGR/uY/Dj/gIAAIiMj2bBhA6GhoXz77be8/fbbaDQaXFxc6N27N1u2bKlz8bdmw3q15HROET+sO4yPuwMdW8l1gEXjpygKnp6+Jl+vte4wm1ouk3zHSUlJqfo5JyeHLVu2EBYWBkBQUBAbN1bMBlhaWsqff/5J69amOc3aWmiUiusAN/N14dNf95J62vreQEIIcbkbFv/p06fTs2dPMjMzGTt2LAMHDgRg/PjxJCcnA5CQkMDAgQOJj4/n0UcfZeTIkcTExADw97//nR07dhAXF8eQIUMICQnhgQceMONLsgw7Wy2ThkXhaK/jw5+TyJPrAAshrJic4WtiqafP8863f+Hv5cjLj3TGzrbmUfim9hXzZkmuurPWbJKrbuqbS87wbWDN/Fz4v/j2pJ4+z+dyHWAhhJWS4m8GHVt582Dv1vx16CwLN6TceAEhhGhgMqunmdwTHcTpnCJWbknFz9ORnh0CLB1JCCGqSPE3k4rrALfmTF4x36w+iI+bPW1DPC0dSwghAOn2MSutRsNT8RH4eTry8aI9ZGQXWjqSEEIAUvzNztFex9+GRaHTKnzw027OF5VaOpIQQkjxbwje7g5MvD+K3POlfPRLMmVWeMEIIUTTIsW/gbQMdGPcoLYcPnWOr1ful6lyhRAWJcW/AXVt68d9PVrw597TJPxW84VxhBCiIcjRPg1sULcQMnOKWbDqAM62Wm5v1/ivbSCEaHyk+DewiusAtyG/uIwvl+/Hy82eVoFulo4lhGhipNvHAmx0Gl4ZcxueLnbMWpjEWbkOsBCigUnxtxA3ZzueHR6FQa4DLISwACn+FqT3cmLC0EhO5xQxZ3Ey5QY5BFQI0TCk+FtY2+YejO4Xzt7juXy39pAcAiqEaBAy4GsFenQIIDO3iJWbU/H3dKRv12aWjiSEuMVJ8bcS99/VkjM5xSSsP4KvhyMdW8t1gIUQ5iPdPlZCoyiMi2tHc38XPl2ylxOZ1ndFISHErUOKvxWxs7l0HeCZC5PIPS/XARZCmIcUfyvj7mzHs8OiKLpQzsyfk7hQarB0JCHELUiKvxVq5ufCk4Pbk3rmPJ8t3VuvC9cLIcT1SPG3Uh1aefNQbGt2Hs7iZ7kOsBDCxG54tM+MGTNYvXo1aWlpLF26lLCwsKvaLFy4kK+//hqNRoPRaGT48OGMHj266vEVK1YwZ84cVFVFURTmzp2Lt7cczXIjfbpUXAd41dZU/DwduKtjoKUjCSFuETcs/rGxsYwePZoRI0Zcs02/fv0YOnQoiqJQUFBAXFwcXbt2pU2bNiQnJ/PRRx8xb948fHx8OH/+PLa2tiZ9EbcqRVF4uE/FdYC/XXMIb3cH2st1gIUQJnDDbp/o6Gj0ev112zg7O6MoCgAlJSWUlZVV3f7666957LHH8PHxAcDFxQU7O7ubzd1kXLwOsL+XI7MX7SE9S64DLIS4eYpay/kEevfuzSeffFJjtw/AunXreP/990lNTWXy5Mk8+uijAAwZMoS77rqL7du3U1RUxD333MNTTz1VtXMwp7KcdM5tXY5dYGscWnRE5+xu9uc0lzM5RUz+cCN2tlr+/WxP3JxlByqEqD+TneEbGxtLbGws6enpTJgwgZ49exIaGorBYODgwYPMnTuX0tJSxo0bR0BAAEOGDKnT+rOzC+p81IvhbBYXDvxJ/o5VAGi8m6MLikQbHInWryWKxnInOPv4uHD2bO1P5FKACUMjeO+7nfzj8z954aGO2Oi0Fs/VUCRX3VlrNslVN/XNpdEoeHk5X/vxmwlVk4CAACIjI9mwYUPV7f79+2Nra4uzszOxsbEkJSWZ+mlrpPVpQbNnv8Bx6D+wve1+FJ0dpbtXULz0HQrmTaR4zSxK92/AWJDdIHluVssAN8YNaseRU+eYu+KATAInhKg3k3z0TUlJoWXLlgDk5OSwZcsW+vbtC8CgQYP43//+R3x8POXl5WzevJl+/fqZ4mlrRVE0aL1D0HqHQKc41AuFlKftw3AqmfKTeyg/voMLgMYjEG1wZMU3A30YitamwTLWxW1tfDndM5RfNh7Fz9OR+JgWlo4khGiEblj8p0+fzpo1a8jKymLs2LG4u7uzfPlyxo8fz6RJk4iMjCQhIYFNmzah0+lQVZWRI0cSExMDwMCBA9mzZw8DBgxAo9EQExPDsGHDzP7CrkWxc8Im9DZsQm9DVVWMuekYTiVRfnIPZXt+oyxpFehs0Qa0RRcUiS44Eo2bdV1nd+CdzTmdU8Svicfw83Dgjvb+lo4khGhkaj3ga2n16fOHuvWXqWUXMGTsp/xkxbcCNf80AIqrb8WOoFkkWn1bFJubH2y92f7FcoORf/2wi6Pp53jh4U60DnK/6UymyGUukqvurDWb5Kobc/X5y5TOl1Fs7NA164iuWUcAjOdOU34qmfKTyZQd+p2yfetAo0OrD0cXHIE2KAqNR0CDHLl0JZ1WwzNDI5k+fzuzFiYzZUw0vu4ODZ5DCNE4SfG/Do2bH7Zufti274NaXooh8zDlp5IxnEzmwuYEIAHFybNyRxCJLrAdip1Tg+VzdrDhb8M78Nb87Xz4025eHdUFR3vrHKsQQlgXKf61pOhs0QW1RxfUHu54CGNBNuWn9mA4mUxZyjbKDmwERYPWrxXaoAh0wVFovJuhKOadPsnf05Fnhkbyrx92MXvxHv42vAM6rUzZJIS4Pin+9aRx9sK2zV3Q5i5UYzmGM0cxnKzoIird/gul239BcXCt3BFEog1sj8bB1SxZwpt5MKZ/G75asZ9v1xxiTP9wi3RFCSEaDyn+JqBodOj8w9D5h2F32/0Yi85hSNtL+ckkDKlJlB/+A1DQ+ISgqzycVPXqYNIMMVF6TucWsfzPE/h7OtL/drkOsBDi2qT4m4HG0Q1N627YtO6GajRizDpeNXBcunMppX8t4cQaJzQB7arOONY4edz0897XM5TTOUX89N8j+Ho40DnMxwSvRghxK5Lib2aKRoPWNxStbyh2neMrTzLbi83ZAxQc/ovyo9sA0HgGoQuOqpx6ojWKtu6/Go2i8PigdmTn/8VnS/fyyoguNPd3MfVLEkLcAqT4N7CKk8y64nN7LOqZfIy5py6NFSSvht0rQGeHLrBd1RnHGtfaf4K3s9Ey6f4ops/fzoc/72bK6Gg8Xe3N+IqEEI2RFH8LUhQFrWcwWs9gbDsMQC0rwZB+8SSzZMpP7OQCoLj5V40VaAPCUXTXP8nMzdmOZ4d14O1vdzDz5yReHtkZe1v5VQshLpGKYEUUG3t0zTuha94JVVVRLz/JbP8GyvasBa0Orb7NpbECd32NR/YE+TrzZHwEH/68m8+W7OOZoZFoNHIEkBCighR/K6UoCoq7P7bu/thG3FN5ktkhyk9ePMnse9j8PYqzV8WhpMGR6ALaodheOss3qqUXj/QJY8HaQ/z43yM8FNvagq9ICGFNpPg3EhUnmUWgC4qAOx/GeD7r0klmRzZTtn8DKFq0/q0ujRV4NSO2SxCZOUWs2XYSP09H7u4k1wEWQkjxb7Q0Lt7Ytu0FbXtVnGR2OqVy4DiJ0q0/U7r1ZxQHN7TBEQwLiSA/x5EFaw7h425PRAsvS8cXQliYFP9bgKLRodOHo9OHY9d1GMaiPAyn9lQOGu+CQ5sYqSj09vBl7/LdePftg1+rdigamQZCiKZKiv8tSOPojiYsBpuwmMqTzI5RfjIZ/+O78c/ahWbDLs7/4YRNcOXUE0ERaBzdLR1bCNGApPjf4ipOMmuJ1rcldl2GcPxEBisXraKz9jTt0g9QnrIFAI1XM3TBkRS164JRdUFx8rDoNY6FEOYlf91NTEhzPbf1H8jsxXvo2saHcfe6Yqicprp09yoydy2vbKmgOLqhOHmicfZEcfZC4+SJ4uyJxtkLxdkTxcHV7LOWCiHMQ4p/ExTdxpf77wpl4f+O4u/lxJAeg6DjINTSYpxLM8g7dQpjYQ5qQTbGghyMuWkYTyZBeWn1FWm0l3YOTpd2ChW3vdA4e4Kto8wwKoQVkuLfRA24ozmnc4pZsuk4fh6O3Bnhj2LrgGNgBwqdQ69qr6oqXCistlNQC3MwFmSjFuRgOH2Y8pStoBqqL6izu7RTcKr8BnHFzkLR2TbQqxZCXCTFv4lSFIXR/cPJOlfM3JX78XKzJyzY/brtsXdGa+8MXjVPF60ajajF5yp3ClfvJMqzT6IWn7t63XbO1XYKl3ctaZw8UZyunUsIUT9S/JswnVbD0/dF8tb87Xz0SzJTRnfBx6f+s4AqGg2Kkwc4eaD1bVljG9VQhlqYe9lOoXInUZiD8XwWxoyDUFp0xYoVip09UB08rvktomL8QbqXhKgtKf5N3MXrAE+fv50PfkriP8/dZdbnU7Q2KK6+aFx9r9lGLSuptlNQC3KwLT9PcXYmhuxU1BO7wHDl+IPusp1C5TeHywernT1RbB3N+tqEaExqVfxnzJjB6tWrSUtLY+nSpYSFhV3VZuHChXz99ddoNBqMRiPDhw9n9OjR1docPXqU++67j0ceeYSXXnrJNK9A3DS/y64D/M68bTwV3x47G63F8ig29mg9AsAjoOo+Hx8Xzp49D1SMP6gXClALKnYMxoLsat8iDBkHKS/MBdVYfcU29tcZf6j8BiHjD6KJqFXxj42NZfTo0YwYMeKabfr168fQoUNRFIWCggLi4uLo2rUrbdq0AcBgMPD666/Tp08f0yQXJhXezIOxA9rw5fL9vLvgLybdH4WHy/WnjrYURVFQ7F3A3gW8m9fYpmr8oWrcofL/ghyMhTmUZ51ALc6/et32LjV/c6j8RqE4uqNoLLdjFI2DqqqgqkDlP5XLPoxUPqaqlTeNFxeq/O/S7Yr3mnkuyFSr4h8dHX3DNs7OzlU/l5SUUFZWVq0P9rPPPqNXr14UFRVRVFRU0yqEhXWL0KP3deW9b7fz5rxtTLo/ihZ681x03tyqjT/41dxGLS9FLcqrOmLp8m8QxnNnMKbvh9LiK1dcsQOo/PaQ7e1LSYmBir/uiytWqy9TVQSuvA+qCsPFn2t6vNpD6jXuu7jIpeXO2NtQUlx2WfsrMtT03NXaXGO5G7RRr8x+xeMZNlpKS8uu2AaXF0uqbqtcdr96Wduq28aa71eNF7dK9UJ7ncJbpAGj4dLt6s9dPVf1on757Su38c1ScBn5Bjia/prcJu3zX7duHe+//z6pqalMnjyZ8PBwAA4cOEBiYiLz589n9uzZ9Vq3l5fzjRtdw80MYpqTNeby8XHhX5N6Mu2rLcxY8BeTHuzEXZ2DLB0LMNf28gJqHpwGMF4oojw/i/L8bMrPna34/3zl7dxU8k8mXSogigJUfuCp+tyjVD126S7liseqt7vU7Ip21Za/8fOUXL58De2u+TyXt71yEP2ytsqV66xle2O5gk5RLr0ORUHRXPxZU/3+qp8BNFXbSqm2PBXLXXwtly1fcZ/mUg7linVcbHfZupSr7lMubdfLlq+W76p1V293cV3KZVmr33/ZOiofUxQFRWeLXUArHGxM/y3cpMU/NjaW2NhY0tPTmTBhAj179iQ4OJjXXnuNd955B622/l+Xs7MLMBrrvle9vK/YmlhzLiedwt9Hdmb2L8n8a8EODhzLZkiPFmgseDSNZbeXB7h6gGsroOJv2qbyn7X+HsF6s1l7rmtVGVN/pq8tFxu7em0vjUa57odmsxztExAQQGRkJBs2bKB///6kpqbyxBNPAJCfn4+qqhQUFDBt2jRzPL0wAVdHW55/uBPfrD7Isj+Ok5FVyLhB7bCzlf5uIW4FJiv+KSkptGxZ8fU5JyeHLVu20LdvXwICAtiyZUtVu1mzZlFUVCRH+zQCOq2GR+9tQ6C3Ewn/PcI73+5g4v1ReLnJBeGFaOxqNSvX9OnT6dmzJ5mZmYwdO5aBAwcCMH78eJKTkwFISEhg4MCBxMfH8+ijjzJy5EhiYmLMl1w0CEVR6Nu1Gc8O68DZc8VMm7+dI2lXn6UrhGhcFFU1+fC0WUiff8O4Xq70rEJm/pxEzvkSHr23Dd0i9FaRy5KsNRdYbzbJVTf1zXWjPn+Zj1fUWoC3E1PGRNMq0I0vlu3npw1H6rVDFkJYnhR/USfODjb8vwc70qtTICs3p/LRL8kUXyi3dCwhRB1J8Rd1ptNqGNU3jBH3hJGUks3b3+4gK6/4xgsKIayGFH9RL4qiENsliOce6EBu/gXenLedQyfzLB1LCFFLUvzFTWnfwpMpY6JxcrDhn9/v5Pfd6ZaOJISoBSn+4qb5ezoyZXQX2jRzZ+7KA/yw7rAMBAth5aT4C5Nwsrfhbw90oE+XINZsO8kHP++mqEQGgoWwVlL8hcloNRoeuSeM0f3D2X88l7e+2c7pXJnBVQhrJMVfmFyvjoFMfrAj+YWlTJ+3nf0nci0dSQhxBSn+wizaNPfgtTHRuDrZ8n7CLjbsTLN0JCHEZaT4C7Px9XDk1VHRtG/hyfzVB1mw5hAGo/HGCwohzE6KvzArR3sdk+6Pol/XYNb9dYr//LibwpIyS8cSosmT4i/MTqNReLB3a8be24aDqXlMn7+DzBwZCBbCkqT4iwbTo0MALzzcicLiMqbP287eYzmWjiREkyXFXzSosGB3po6JxsPVjv/8uJt1O07RSGYVF+KWIsVfNDhvdwf+PrILUS29WLD2EN+sPki5QQaChWhIUvyFRTjY6Xjm/kgG3NGcDbvSeT9hFwXFMhAsREOR4i8sRqMoDOvVknGD2nIk7RzT5m0jLavQ0rGEaBKk+AuL6xah56VHOnOhzMjb32wnKSXb0pGEuOVJ8RdWoWWgG6+NjsbHzYEPf97N6q2pMhAshBlJ8RdWw8vNnldGdqFzax8S1h9h7soDlJXLQLAQ5iDFX1gVO1stT90XQVy3EBKTMvjXDzvJLyq1dCwhbjm1Kv4zZsygd+/ehIeHc+jQoRrbLFy4kLi4OOLj44mLi2P+/PlVj3388ccMHDiQuLg4hg4dyu+//26a9OKWpFEU7usZypPx7TmeeZ5pX2/neEa+pWMJcUvR1aZRbGwso0ePZsSIEdds069fP4YOHYqiKBQUFBAXF0fXrl1p06YNUVFRPPbYYzg4OHDgwAFGjhxJYmIi9vb2Jnsh4tbTta0fPu4OzFyYxIuzNjJuUDs6tfaxdCwhbgm1+uQfHR2NXq+/bhtnZ2cURQGgpKSEsrKyqts9evTAwcEBgPDwcFRVJS8v7yZii6aihd6VqWNuI9DXhY8WJrNi8wkZCBbCBGr1yb+21q1bx/vvv09qaiqTJ08mPDz8qjaLFy+mWbNm+Pv712ndXl7O9c7l4+NS72XNSXLVjo+PC+883Z2ZCbv4eUMK2ecv8MzwjtjaaC0dDbC+7XU5a80muerGHLlMWvxjY2OJjY0lPT2dCRMm0LNnT0JDQ6se37p1Kx9++CFfffVVndednV1Qr4uC+/i4cPbs+TovZ26Sq258fFx4tF8YXi62LP79GKkZ+TwzNBI3ZzuL57LG7QXWm01y1U19c2k0ynU/NJvlaJ+AgAAiIyPZsGFD1X07d+7khRde4OOPP662QxCithRFYXD3Fjw9JIKTZwuYNn87JzKt749ViMbAZMU/JSWl6uecnBy2bNlCWFgYAElJSTz33HPMnDmT9u3bm+opRRMV3caXV0Z0QVXhnQU72HHwjKUjCdHo1Kr4T58+nZ49e5KZmcnYsWMZOHAgAOPHjyc5ORmAhIQEBg4cSHx8PI8++igjR44kJiYGgDfeeIOSkhKmTp1KfHw88fHxHDx40EwvSTQFzf1dmDommiAfZz5etIelm47JQLAQdaCojeQvRvr8G0Zjy1VWbuDrlQf4c+9purb15bEBbRt0INhatxdYbzbJVTfm6vM36YCvEA3NRqdl3KB2BHg78cv/jnImt5iJ90fh4WLZgWAhrJ1M7yAaPUVRGHhnCM8MjSQju4hp87ZxTM4IFuK6pPiLW0anMB/+PqoLWo2Gdxf8xdb9py0dSQirJcVf3FKCfZ15bUw0If4ufPLrXhZtPIqxcQxrCdGgpPiLW46rky3PP9SJmEg9S/84zpzFe7hQarB0LCGsihR/cUuy0WkYO6AND/ZuxV+HzvLOgh3k5JdYOpYQVkOKv7hlKYpCv67NeHZYFGdyi3lz3nZS0s5ZOpYQVkGKv7jlRbX05tXR0djZaJjx3U7+3JNp6UhCWJwUf9EkBHo7MWV0NC0DXPl82T5+3pAiA8GiSZPiL5oMF0dbJj/Ukbs6BrBi8wk+WphM8YVyS8cSwiKk+IsmRafVMLpfOI/0ac3ulCze+XYHWXnFlo4lRIOT4i+aHEVR6BMdzHMPdCA7/wLT5m/n0Mk8S8cSokFJ8RdNVkQLL6aM7oKjnY5/fr+T35PSLR1JiAYjxV80aXovJ6aMiSa8mTtzVxzgh3WH6zV7rBCNjRR/0eQ52dvwt+EdiO0cxJptJ5m5MEkGgsUtT4q/EFQMBI/oG8aofuHsOZrDW9/s4ExukaVjCWE2UvyFuMzdnQKZ/GAHzhVcYNq87Rw4kWvpSEKYhRR/Ia7QNsSTKWOicXWy5d8Ju9iwK83SkYQwOSn+QtTAz8ORV0dF0zbEg/mrDrJg7SEMRqOlYwlhMlL8hbgGR3sdfxvWgb63BbNuxyk++HE3hSVllo4lhElI8RfiOjQahYdiW/PovW04kJrH9Pk7yMyRgWDR+EnxF6IWenYI4PmHOlJYXMb0edvZezzH0pGEuCk3LP4zZsygd+/ehIeHc+jQoRrbLFy4kLi4OOLj44mLi2P+/PlVjxkMBt544w369OnDPffcw08//WS69EI0oPBmHrw2JhoPFzv+k7CbdTtOWTqSEPWmu1GD2NhYRo8ezYgRI67Zpl+/fgwdOhRFUSgoKCAuLo6uXbvSpk0bli5dSmpqKmvWrCEvL48hQ4Zw5513EhQUZNIXIkRD8HF34O+juvDZkr0sWHuI7IJSBnQNxtnBxtLRhKiTG37yj46ORq/XX7eNs7MziqIAUFJSQllZWdXtFStWMHz4cDQaDZ6envTp04dVq1aZILoQluFgp2Pi/VHce3szVv15nP/3USKzFyWTlJIlRwSJRuOGn/xra926dbz//vukpqYyefJkwsPDAcjIyCAgIKCqnV6vJzOz7ldS8vJyrnc2Hx+Xei9rTpKrbqwt19MPdOLemFB+25rKf3ecYvvBs3i62nF3l2D6dG1GkK/l81rbNrtIctWNOXKZrPjHxsYSGxtLeno6EyZMoGfPnoSGhppq9WRnF9Rrwi0fHxfOnj1vshymIrnqxlpztQhwY0j3EAbd0YzdR7JITMpg0YYUFv73CK0C3YiJ0nNbG18c7Ez2p1Zr1rrNJFfd1DeXRqNc90Ozyd+RAQEBREZGsmHDBkJDQ9Hr9aSnpxMVFQVc/U1AiFuBTquhS7gvXcJ9ySu4wJ97MklMzuDrlQf47rdDdAnzpUeUnrBm7mgqu0SFsCSTFP+UlBRatmwJQE5ODlu2bKFv374A9O/fn59++om+ffuSl5fHb7/9xoIFC0zxtEJYJXdnO+69ozn9b2/G0fR8EpMz2Lr/NH/uzcTbzZ6YSD3dIv3xdnOwdFTRhN2w+E+fPp01a9aQlZXF2LFjcXd3Z/ny5YwfP55JkyYRGRlJQkICmzZtQqfToaoqI0eOJCYmBoD4+Hh2795dtTOYMGECwcHB5n1VQlgBRVFoGehGy0A3HoptzV+HzpKYlMHixGP8mniMNs09iInS0yXMB1sbraXjiiZGUVW1UVy5Qvr8G4bkqpv65MrKK2bTnkw2JWeQda4EBzsdt7f1pXuUnlC9a9WRcpbI1hAkV900mj5/IcT1ebs7EB/TgrjuIRw8kUticgZ/7Mlkw650ArydiInUc2d7P9yc7SwdVdzCpPgLYSEaRaFtiCdtQzwZcU852w6cJjE5gx//e4SfN6QQ1dKL7pF6OrTyQqeVmViEaUnxF8IKONrruKtjIHd1DCQju5DEpIpvA7uOZOHsYMOd7f3pEaUnyLf+57sIcTkp/kJYGb2XE8PvbsXQu0LZczSHxOQM1v91irXbT9Lc34WYSD23t/OTKSXETZHiL4SV0mo0dGjlTYdW3pwvKmXzvtMkJmWwYO0hEtYfplNrH3pE6WkX4olGI+cOiLqR4i9EI+DiaMs90cHcEx3MiczzJCZnsHlvJtsOnMHDxY5uEf7EROrx83S0dFTRSEjxF6KRae7vQnN/Fx64uxW7KqeUWLH5BMv/PEHroEtTSghxPVL8hWikbHQabmvjy21tfMk9f4E/9mSQmJzJ3BUH+G7tYWI6BhDd2puwYHeTnTsgbh1S/IW4BXi42DHwzhAG3NGclLR8fk9K54+kdNZtO4mvuwPdo/R0j/DH09Xe0lGFlZDiL8QtRFEUWgW50SrIjUkPdWbVpqNsSs5g0cajLN54lHYtPImJ1NM5zBsbnUwp0ZRJ8RfiFmVvp6N7pJ7ukXrO5BXzR3IGm5Iz+HTJXhztdNze3o+YSD0h/i7SLdQESfEXognwdXdgSI9QBse0YP+JXDYlZZCYlMF//0oj0OfilBL+uDrZWjqqaCBS/IVoQjSKQvsQT9qHeFJUUsbW/WdITM4gYf2lKSViovREhsqUErc6Kf5CNFGO9jb06hRIr06BpGUVsikpgz/2ZrLzcBaujjbcWXnuQKCPTClxK5LiL4Qg0NuJB3pXn1Lit+2nWL31JC30rsRE6bm9rS+O9jKlxK1Cir8QoopOq6Fja286tvYmv7CUzXsrLkf5zeqD/LDuMJ3DfIiJ0tO2uYdcjrKRk+IvhKiRq5Mtfbs2457bgjlx+jyJSRls3nuaLftO4+VqR7cIPd2j9Pi6y+UoGyMp/kKI61IUhRB/V0L8XXmwdyt2Hq6YUmLZH8dZ+sdxwoPdiYnSEx3ui52tnDvQWEjxF0LUmo1OS9e2fnRt60dOfgl/7KnoFvpy+X6+XXuIrm18iYnS0yrQTc4dsHJS/IUQ9eLpas+gbiEMvLM5h0+dIzEpg637z/B7UgZ+no7ERPrTLUKPh4tcjtIaSfEXQtwURVEIC3YnLNidR+5pzfYDZ0lMzmDh/47yy8ajRLSoOHegYytvbHRy7oC1kOIvhDAZe1sdMVF6YqL0nM4tYlNyBpuSM5mzeA9O9jpub+fHHVGBeDnZyDcCC6tV8Z8xYwarV68mLS2NpUuXEhYWdlWbjz/+mBUrVqDRaLCxseG5556jR48eABw7doypU6eSn59PaWkpAwYMYOLEiaZ9JUIIq+Ln4cjQni0ZEhPKvhM5JCZlsHF3Buv/SgMqZiIN1bvSIsCVUL0rzf1dcLCTz6MNpVZbOjY2ltGjRzNixIhrtomKiuKxxx7DwcGBAwcOMHLkSBITE7G3t+ef//wn/fr1Y+TIkRQWFjJo0CDuuusuoqKiTPZChBDWSaNRiGjhRUQLL0rLDJwvNfLXvkyOZuRzLD2fHYfOAqAAAd5OVTuDFnpXAn2cZJoJM6lV8Y+Ojr5hm4uf8gHCw8NRVZW8vDz8/f1RFIXz588DUFJSgqIoeHp61jOyEKKxsrXR0ibAHS+nS2cKFxSXcTQ9n2MZ+RxNz2dX5aGkALY6Dc38XQjVuxIaULFD8HazlyOJTEBRVVWtbePevXvzySef1Njtc7lFixYxf/58Fi1aBEBaWhpPPvkkeXl55Ofn8+KLL173W4QQoulSVZXTOUUcPJHLoZO5HE7NI+VUHqXlRgDcnG1pHexBWDMPwpt50LqZOy6OMhtpXZm8g23r1q18+OGHfPXVV1X3JSQkEB8fz7hx4zhz5gyjRo0iIiKCDh061Hq92dkFGI213k9V8fFx4ezZ83VeztwkV91Irrqz1my1yaUF2gW70S7YDbpBucFI2tlCjmbkczT9HMcyzrNj/2kuVgQ/DwdaVH4zCA1wpZmvc50vVtOYt1dNNBoFL69rT8pn0uK/c+dOXnjhBWbPnk1oaGjV/d988w2//fYbAL6+vtxxxx1s27atTsVfCNF06bSaqgvX390pEIDiC+Ucz8iv3CHks/9ELpv3ngZAq1EI9nWu6ioKDXDFz9NR5iO6jMmKf1JSEs899xwzZ86kffv21R4LCgri999/Z8iQIRQUFLBjxw569+5tqqcWQjRBDnY62oZ40jbk0vhh7vkLHE0/VzWYvGlPZtXRRQ52OlroXS7tEPSuuDk33cNNa9XnP336dNasWUNWVhYeHh64u7uzfPlyxo8fz6RJk4iMjOT+++8nLS0NPz+/quXee+89wsPD2bNnD9OnT6eoqIjy8nIGDBjAM888U6eg0u3TMCRX3VhrLrDebA2Zy2hUycgurNoZHM3I59SZQoyVZc/L1Y4WlYebdm7rj5u9Fntb6zrc1FzdPnUa8LUkKf4NQ3LVjbXmAuvNZulcF8oMpJ4+X7UzOJqeT9a5EgAUpeLaBpe6i9wI8HZEq7Hc4aaNos9fCCGsnZ2NltZB7rQOcq+6L7+olJzCMnYdOM3RjHx2HDzLxt2Vh5vaaAjxcyE0wK1yUNkFL9fGf7ipFH8hRJPn6mhLy+ZehPg4ARWHm57JK674dlB5DsJvO05RvrXicFNXJ9tqZye30Ls0uqucSfEXQogrKIqCn4cjfh6O3NHeH6g43PTkmYKqk9GOZeSz60hW1TL+no5VRxaFBrgS5ONs1RPZSfEXQoha0Gk1FYPDeld6d664r6iknGOZFYPJxzLy2Xc8hz/3Zla2V2jm51J1ZFFogCu+Hg5W010kxV8IIerJ0V5H+xBP2lcebqqqauXhpvlVRxglJmWwbscpAJzsdYRU7gwudhm5Olnm7GQp/kIIYSKKouDpao+nqz3RbXyBisNN07MKq44sOpaRz7I/j3PxOEtvN/uq7qIWlbOb2tmY/3KYUvyFEMKMNBqFIF9ngnyd6dkhAIALpQZOnD5fbUK7bQfOVLRXFIJ8KmY3bRngxuBeTmbJJcVfCCEamJ2tturqZxedKyytNpi8bf8Z/rcrneZB7gR7Opg8gxR/IYSwAm5OtnRs5U3HVt5AxfjB+eIyWjb3MstJcdZ7HJIQQjRhiqLgasapqqX4CyFEEyTFXwghmiAp/kII0QRJ8RdCiCZIir8QQjRBUvyFEKIJajTH+Ws09Z8M6WaWNSfJVTeSq+6sNZvkqpv65LrRMo3mSl5CCCFMR7p9hBCiCZLiL4QQTZAUfyGEaIKk+AshRBMkxV8IIZogKf5CCNEESfEXQogmSIq/EEI0QVL8hRCiCWo00ztcz7Fjx3j55ZfJy8vD3d2dGTNmEBISUq2NwWBg+vTp/P777yiKwhNPPMHw4cMtnmvWrFl89913+Pr6AtC5c2def/11s+aaMWMGq1evJi0tjaVLlxIWFnZVG0tsr9rkssT2ys3N5cUXXyQ1NRVbW1uaN2/Om2++iaenZ7V2xcXFvPLKK+zduxetVstLL73E3XffbfFcL7/8Mn/88QceHh4A9O/fn6eeespsuQCefvppTp06hUajwdHRkddee422bdtWa2OJ91htclniPXbRRx99xKxZs2p8/5v8/aXeAkaNGqUuXrxYVVVVXbx4sTpq1Kir2ixatEh97LHHVIPBoGZnZ6s9evRQT548afFcM2fOVN99912z5rjStm3b1PT0dPXuu+9WDx48WGMbS2yv2uSyxPbKzc1VN2/eXHX73XffVV955ZWr2s2aNUt99dVXVVVV1WPHjqndunVTCwoKLJ7rpZdeUr/55huz5ahJfn5+1c9r165VhwwZclUbS7zHapPLEu8xVVXVPXv2qI8//vg13/+mfn81+m6f7Oxs9u3bx6BBgwAYNGgQ+/btIycnp1q7FStWMHz4cDQaDZ6envTp04dVq1ZZPJclREdHo9frr9umobdXbXNZgru7O7fffnvV7Y4dO5Kenn5Vu5UrV/Lggw8CEBISQkREBBs3brR4LktwcXGp+rmgoABFuXqSMUu8x2qTyxJKS0t58803+cc//nHNNqZ+fzX6bp+MjAz8/PzQarUAaLVafH19ycjIqPb1NyMjg4CAgKrber2ezMxMi+cCWL58OYmJifj4+DBx4kQ6depktly11dDbqy4sub2MRiPff/89vXv3vuqx9PR0AgMDq2435Da7Xi6AuXPnkpCQQHBwMJMnT6Zly5Zmz/Tqq6+yadMmVFXliy++uOpxS73HbpQLGv499uGHHzJ48GCCgoKu2cbU769GX/wbu4ceeognn3wSGxsbNm3axNNPP82KFSuq+mdFdZbeXtOmTcPR0ZGRI0c2yPPV1vVyPffcc/j4+KDRaFi8eDHjxo3jt99+q/pgYi5vvfUWAIsXL+a9997j888/N+vz1daNcjX0e2znzp3s2bOH559/3izrv5ZG3+2j1+s5ffo0BoMBqBhEOnPmzFXdB3q9vtpX4oyMDPz9/S2ey8fHBxsbGwC6d++OXq/n8OHDZstVWw29vWrLkttrxowZnDhxgg8++ACN5uo/nYCAANLS0qpuN9Q2u1EuPz+/qvuHDBlCUVFRg36LGzJkCFu2bCE3N7fa/ZZ+j10rV0O/x7Zt20ZKSgqxsbH07t2bzMxMHn/8cRITE6u1M/X7q9EXfy8vL9q2bcuyZcsAWLZsGW3btr2qa6V///789NNPGI1GcnJy+O233+jXr5/Fc50+fbrq5/3795OWlkaLFi3Mlqu2Gnp71Zalttf777/Pnj17+Pjjj7G1ta2xTf/+/UlISADg+PHjJCcn06NHD4vnunyb/f7772g0Gvz8/MyWqbCwkIyMjKrb69evx83NDXd392rtGvo9VttcDf0ee+KJJ0hMTGT9+vWsX78ef39/vvzyS2JiYqq1M/n7q95DxVbkyJEj6rBhw9S+ffuqw4YNU1NSUlRVVdVx48apSUlJqqqqanl5uTp16lQ1NjZWjY2NVX/44QeryPXiiy+qAwcOVOPi4tShQ4eqGzZsMHuuadOmqT169FDbtm2rduvWTR0wYMBVuSyxvWqTyxLb69ChQ2pYWJjat29fdfDgwergwYPVp59+WlVVVR08eLCamZmpqqqqFhYWqhMnTlT79Omj9u3bV127dq1V5BozZow6aNAgNS4uTn344YfVnTt3mjXX2bNn1eHDh6uDBg1SBw8erI4aNUrds2ePqqqWfY/VNpcl3mOXu/xoH3O+v+RKXkII0QQ1+m4fIYQQdSfFXwghmiAp/kII0QRJ8RdCiCZIir8QQjRBUvyFEKIJkuIvhBBNkBR/IYRogv4/nVQrMA+JGt8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(1)\n",
    "seq2 = torch.tensor([seq2]).cuda(1)\n",
    "seq3 = torch.tensor([seq3]).cuda(1)\n",
    "seq4 = torch.tensor([seq4]).cuda(1)\n",
    "seq5 = torch.tensor([seq5]).cuda(1)\n",
    "seq6 = torch.tensor([seq6]).cuda(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[1.2574e-04, 6.3186e-04, 1.7314e-04, 9.0933e-03, 9.8998e-01]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[0.0013, 0.0040, 0.0431, 0.9048, 0.0469]], device='cuda:1',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[1.5683e-05, 1.0873e-03, 9.9861e-01, 2.9110e-04, 2.7923e-07]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[9.5644e-01, 4.3241e-02, 2.4187e-04, 4.7575e-06, 6.9292e-05]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[3.4586e-07, 3.4215e-07, 7.1945e-09, 5.3349e-05, 9.9995e-01]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[1.5711e-01, 7.7945e-01, 6.2878e-02, 2.2526e-04, 3.3181e-04]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11026.,  5323.,  1602.,   961.,  1042.],\n",
      "        [ 5090.,  7947.,  3888.,  1641.,  1306.],\n",
      "        [ 1687.,  4885.,  7572.,  4609.,  1154.],\n",
      "        [  475.,   932.,  2318., 11075.,  5369.],\n",
      "        [  512.,   545.,   440.,  3019., 15550.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(60873.)\n",
      "diag:  tensor(55371.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep = 5\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499840.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(confusion_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
