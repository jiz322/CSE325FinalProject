{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11964"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Here we extract the words that have more impact on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only considering the 20000 most common words\n",
    "## We convert all other words to N0O0N, which indicate unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpora, Get DataLoader Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:49<00:00, 1143.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:25<00:00, 1165.28it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor\n",
    "# Here, one hot embedding is used\n",
    "## A score for each words is a trainable vector. Higher means positive word, lower means negative word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(len(corpora.word_index), 5)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "        emb = self.embedding(src)\n",
    "        z = torch.sum(emb,dim=1)\n",
    "        d = torch.softmax(z, dim=-1)\n",
    "\n",
    "        # Notice that we compute d in the process of training\n",
    "        # No need to compute two times of softmax, which will make prediction inaccurate.\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Weights Initialization Goes Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_DIM = len(corpora.word_index)\n",
    "\n",
    "# initialize the model\n",
    "featureExtractor = FeatureExtractor(INPUT_DIM).cuda(3)\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "featureExtractor.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(featureExtractor.parameters())\n",
    "\n",
    "\n",
    "tmp = optimizer.state_dict()\n",
    "tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "optimizer.load_state_dict(tmp)\n",
    "print(optimizer)\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 30\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "training_losses = []\n",
    "test_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    \n",
    "#     if num_epochs_train == 1:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "#     if num_epochs_train == 2:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 3:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.000125\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 15:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 15:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.000025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 949.77it/s] \n",
      "1562it [00:05, 287.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 12s\tTrain Loss: 1.444 | Test Loss: 1.394\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 937.70it/s] \n",
      "1562it [00:05, 281.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 12s\tTrain Loss: 1.374 | Test Loss: 1.371\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 894.65it/s] \n",
      "1562it [00:05, 284.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 12s\tTrain Loss: 1.354 | Test Loss: 1.361\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1141.78it/s]\n",
      "1562it [00:05, 289.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 10s\tTrain Loss: 1.341 | Test Loss: 1.356\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1135.84it/s]\n",
      "1562it [00:05, 290.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 10s\tTrain Loss: 1.332 | Test Loss: 1.352\n",
      "epoch start:  5\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 846.15it/s]\n",
      "1562it [00:05, 287.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 12s\tTrain Loss: 1.325 | Test Loss: 1.350\n",
      "epoch start:  6\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 918.00it/s] \n",
      "1562it [00:05, 283.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 12s\tTrain Loss: 1.320 | Test Loss: 1.348\n",
      "epoch start:  7\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1133.21it/s]\n",
      "1562it [00:05, 288.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 10s\tTrain Loss: 1.315 | Test Loss: 1.347\n",
      "epoch start:  8\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 966.42it/s] \n",
      "1562it [00:05, 278.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 12s\tTrain Loss: 1.311 | Test Loss: 1.346\n",
      "epoch start:  9\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1124.78it/s]\n",
      "1562it [00:05, 288.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 10s\tTrain Loss: 1.307 | Test Loss: 1.345\n",
      "epoch start:  10\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1115.74it/s]\n",
      "1562it [00:05, 286.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 11s\tTrain Loss: 1.304 | Test Loss: 1.345\n",
      "epoch start:  11\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 863.65it/s]\n",
      "1562it [00:05, 285.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 12s\tTrain Loss: 1.301 | Test Loss: 1.345\n",
      "epoch start:  12\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1128.57it/s]\n",
      "1562it [00:05, 287.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 10s\tTrain Loss: 1.298 | Test Loss: 1.345\n",
      "epoch start:  13\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 990.88it/s] \n",
      "1562it [00:05, 285.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 11s\tTrain Loss: 1.296 | Test Loss: 1.344\n",
      "epoch start:  14\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 872.54it/s]\n",
      "1562it [00:05, 280.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 12s\tTrain Loss: 1.294 | Test Loss: 1.344\n",
      "epoch start:  15\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 897.90it/s] \n",
      "1562it [00:05, 289.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 12s\tTrain Loss: 1.289 | Test Loss: 1.344\n",
      "epoch start:  16\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 998.96it/s] \n",
      "1562it [00:05, 287.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 11s\tTrain Loss: 1.289 | Test Loss: 1.344\n",
      "epoch start:  17\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1133.85it/s]\n",
      "1562it [00:05, 291.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 10s\tTrain Loss: 1.289 | Test Loss: 1.344\n",
      "epoch start:  18\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1129.34it/s]\n",
      "1562it [00:05, 290.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 10s\tTrain Loss: 1.289 | Test Loss: 1.344\n",
      "epoch start:  19\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 946.66it/s] \n",
      "1562it [00:05, 280.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 12s\tTrain Loss: 1.289 | Test Loss: 1.344\n",
      "epoch start:  20\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 1005.57it/s]\n",
      "1562it [00:05, 284.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 0m 11s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  21\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 871.46it/s]\n",
      "1562it [00:05, 283.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 0m 12s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  22\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1118.04it/s]\n",
      "1562it [00:05, 287.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 0m 11s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  23\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 848.25it/s]\n",
      "1562it [00:05, 283.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 0m 12s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  24\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1128.22it/s]\n",
      "1562it [00:05, 287.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 0m 10s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  25\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1123.23it/s]\n",
      "1562it [00:05, 289.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Time: 0m 10s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  26\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1077.62it/s]\n",
      "1562it [00:05, 280.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 0m 11s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  27\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1125.71it/s]\n",
      "1562it [00:05, 287.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 0m 11s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  28\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 989.98it/s] \n",
      "1562it [00:05, 284.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Time: 0m 11s\tTrain Loss: 1.288 | Test Loss: 1.344\n",
      "epoch start:  29\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:06, 1016.73it/s]\n",
      "1562it [00:05, 281.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 0m 11s\tTrain Loss: 1.287 | Test Loss: 1.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(featureExtractor, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(featureExtractor, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'apr16th_5_emb.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5cddb60650>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[0.0267, 0.1064, 0.1021, 0.1483, 0.6166]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[0.0598, 0.1111, 0.2305, 0.4160, 0.1827]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[0.0094, 0.1187, 0.8530, 0.0134, 0.0055]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[0.7471, 0.1355, 0.0463, 0.0282, 0.0430]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[0.0072, 0.0597, 0.0146, 0.0817, 0.8369]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[0.7806, 0.0915, 0.0572, 0.0336, 0.0371]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = featureExtractor.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12224.,  3907.,  2082.,   911.,   830.],\n",
      "        [ 5417.,  7572.,  4232.,  1415.,  1236.],\n",
      "        [ 2153.,  3841.,  8765.,  3942.,  1206.],\n",
      "        [  606.,   793.,  2749., 10760.,  5261.],\n",
      "        [  443.,   460.,   531.,  2668., 15964.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(63108.)\n",
      "diag:  tensor(55285.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep =30\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'results/5_embs.pkl', 'wb') as f:\n",
    "    pickle.dump(featureExtractor.embedding.weight.data, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20001, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('results/5_embs.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
