{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24851"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Here we extract the words that have more impact on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only considering the 20000 most common words\n",
    "## We convert all other words to N0O0N, which indicate unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpora, Get DataLoader Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:38<00:00, 1183.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:24<00:00, 1178.42it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor\n",
    "# Here, one hot embedding is used\n",
    "## A score for each words is a trainable vector. Higher means positive word, lower means negative word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(len(corpora.word_index), 5)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "        emb = self.embedding(src)\n",
    "        z = torch.sum(emb,dim=1)\n",
    "        d = torch.softmax(z, dim=-1)\n",
    "\n",
    "\n",
    "        return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Weights Initialization Goes Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_DIM = len(corpora.word_index)\n",
    "\n",
    "# initialize the model\n",
    "featureExtractor = FeatureExtractor(INPUT_DIM).cuda(3)\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "featureExtractor.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(featureExtractor.parameters())\n",
    "\n",
    "\n",
    "tmp = optimizer.state_dict()\n",
    "tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "optimizer.load_state_dict(tmp)\n",
    "print(optimizer)\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 30\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "training_losses = []\n",
    "test_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    \n",
    "#     if num_epochs_train == 1:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "#     if num_epochs_train == 2:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 3:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.000125\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 15:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 15:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.000025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1083.37it/s]\n",
      "1562it [00:05, 295.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 11s\tTrain Loss: 1.563 | Test Loss: 1.550\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1089.89it/s]\n",
      "1562it [00:05, 295.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 11s\tTrain Loss: 1.546 | Test Loss: 1.544\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1087.10it/s]\n",
      "1562it [00:05, 295.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 11s\tTrain Loss: 1.541 | Test Loss: 1.541\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1087.94it/s]\n",
      "1562it [00:05, 296.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 11s\tTrain Loss: 1.537 | Test Loss: 1.538\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1085.59it/s]\n",
      "1562it [00:05, 294.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 11s\tTrain Loss: 1.533 | Test Loss: 1.536\n",
      "epoch start:  5\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1086.70it/s]\n",
      "1562it [00:05, 295.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 11s\tTrain Loss: 1.530 | Test Loss: 1.534\n",
      "epoch start:  6\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1082.71it/s]\n",
      "1562it [00:05, 295.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 11s\tTrain Loss: 1.528 | Test Loss: 1.533\n",
      "epoch start:  7\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1081.80it/s]\n",
      "1562it [00:05, 295.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 11s\tTrain Loss: 1.526 | Test Loss: 1.533\n",
      "epoch start:  8\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1070.13it/s]\n",
      "1562it [00:05, 294.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 11s\tTrain Loss: 1.525 | Test Loss: 1.532\n",
      "epoch start:  9\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1081.65it/s]\n",
      "1562it [00:05, 264.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 11s\tTrain Loss: 1.523 | Test Loss: 1.532\n",
      "epoch start:  10\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:05, 1082.81it/s]\n",
      "1562it [00:09, 171.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 14s\tTrain Loss: 1.522 | Test Loss: 1.531\n",
      "epoch start:  11\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 765.74it/s]\n",
      "1562it [00:17, 88.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 25s\tTrain Loss: 1.521 | Test Loss: 1.531\n",
      "epoch start:  12\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 798.75it/s]\n",
      "1562it [00:16, 93.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 24s\tTrain Loss: 1.520 | Test Loss: 1.531\n",
      "epoch start:  13\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 854.67it/s]\n",
      "1562it [00:16, 96.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 23s\tTrain Loss: 1.519 | Test Loss: 1.530\n",
      "epoch start:  14\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 819.13it/s]\n",
      "1562it [00:16, 92.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 24s\tTrain Loss: 1.519 | Test Loss: 1.530\n",
      "epoch start:  15\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 810.48it/s]\n",
      "1562it [00:17, 90.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 24s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  16\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 796.06it/s]\n",
      "1562it [00:16, 97.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 23s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  17\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:09, 691.32it/s]\n",
      "1562it [00:17, 87.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 26s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  18\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 759.68it/s]\n",
      "1562it [00:17, 86.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 26s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  19\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 846.48it/s]\n",
      "1562it [00:16, 94.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 23s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  20\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:09, 642.60it/s]\n",
      "1562it [00:17, 87.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 0m 27s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  21\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 776.85it/s]\n",
      "1562it [00:17, 89.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 0m 25s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  22\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 857.30it/s]\n",
      "1562it [00:16, 92.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 0m 24s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  23\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 778.94it/s]\n",
      "1562it [00:17, 87.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 0m 25s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  24\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 779.29it/s]\n",
      "1562it [00:17, 91.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 0m 25s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  25\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 741.37it/s]\n",
      "1562it [00:17, 90.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Time: 0m 25s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  26\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 772.15it/s]\n",
      "1562it [00:17, 89.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 0m 25s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  27\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:08, 728.19it/s]\n",
      "1562it [00:17, 91.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 0m 25s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  28\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 861.71it/s]\n",
      "1562it [00:17, 91.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Time: 0m 24s\tTrain Loss: 1.517 | Test Loss: 1.530\n",
      "epoch start:  29\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:07, 783.89it/s]\n",
      "1562it [00:17, 88.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 0m 25s\tTrain Loss: 1.517 | Test Loss: 1.530\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(featureExtractor, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(featureExtractor, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0d667d5490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[0.1601, 0.1802, 0.1678, 0.1720, 0.3199]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[0.1683, 0.1792, 0.2008, 0.2638, 0.1878]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[0.1504, 0.1538, 0.3953, 0.1503, 0.1502]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[0.3404, 0.1771, 0.1627, 0.1595, 0.1603]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[0.1522, 0.1576, 0.1522, 0.1568, 0.3813]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[0.3288, 0.1722, 0.1742, 0.1633, 0.1615]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = featureExtractor.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = featureExtractor.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12741.,  3224.,  2224.,   852.,   913.],\n",
      "        [ 5979.,  6705.,  4519.,  1341.,  1328.],\n",
      "        [ 2433.,  3266.,  9116.,  3791.,  1301.],\n",
      "        [  709.,   674.,  2899., 10228.,  5659.],\n",
      "        [  497.,   438.,   573.,  2255., 16303.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(64305.)\n",
      "diag:  tensor(55093.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep =30\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'results/5_embs.pkl', 'wb') as f:\n",
    "    pickle.dump(featureExtractor.embedding.weight.data, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20001, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('results/5_embs.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
