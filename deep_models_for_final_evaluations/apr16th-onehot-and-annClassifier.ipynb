{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Here we extract the words that have more impact on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only considering the 20000 most common words\n",
    "## We convert all other words to N0O0N, which indicate unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            input = convert(input)\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Corpora, Get DataLoader Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [06:10<00:00, 1078.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:32<00:00, 1077.27it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "# NB: DO NOT RE-RUN THIS CELL\n",
    "\n",
    "#\n",
    "#\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor\n",
    "# Here, one hot embedding is used\n",
    "## A score for each words is a trainable vector. Higher means positive word, lower means negative word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.embedding = nn.functional.one_hot(torch.arange(input_dim).cuda(3))\n",
    "        \n",
    "        # The Initialization below does not work. Initial in the next cell's next cell!\n",
    "        vector_weights = [30000.0]*input_dim\n",
    "        self.vector_weights = nn.Parameter(torch.tensor(vector_weights, requires_grad=True).cuda(3))\n",
    "\n",
    "        \n",
    "\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = torch.sum(self.embedding[src],dim=2)\n",
    "        emb = torch.tensor(emb, dtype=torch.float)\n",
    "        w = self.vector_weights[src]\n",
    "        # A Vector of Batch_size * 1\n",
    "        z = torch.sum(w*emb,dim=1)\n",
    "\n",
    "\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Weights Initialization Goes Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "\n",
    "# initialize the model\n",
    "featureExtractor = FeatureExtractor(INPUT_DIM).cuda(3)\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "featureExtractor.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(featureExtractor.parameters())\n",
    "\n",
    "\n",
    "tmp = optimizer.state_dict()\n",
    "tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "optimizer.load_state_dict(tmp)\n",
    "print(optimizer)\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer,  clip, num_epochs=0):\n",
    "    \n",
    "    global num_epochs_train\n",
    "    if num_epochs_train == 2:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 5:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.0001\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 7:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00006\n",
    "        optimizer.load_state_dict(tmp)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "\n",
    "    \n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "\n",
    "        \n",
    "          # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        num_batchs += 1\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))\n",
    "        # absolution distance loss\n",
    "        # About 0.8 after 1st ephoch (regression loss)\n",
    "        loss= sum(abs(z - torch.tensor(batch[1]-3).cuda(3)))/BATCH_SIZE\n",
    "\n",
    "        # loss= torch.sqrt(sum(pow(z - torch.tensor(batch[1]).cuda(3),2)))/BATCH_SIZE\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = featureExtractor.forward(batch[0].cuda(3))       \n",
    "        # absolution distance loss\n",
    "        loss= sum(abs(z - (torch.tensor(batch[1]-3).cuda(3))))/BATCH_SIZE      \n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "6250it [00:25, 243.19it/s]\n",
      "0it [00:00, ?it/s]/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "1562it [00:04, 355.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 30s\tTrain Loss: 0.857 | Test Loss: 0.801\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 240.64it/s]\n",
      "1562it [00:03, 395.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 29s\tTrain Loss: 0.784 | Test Loss: 0.790\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:26, 238.51it/s]\n",
      "1562it [00:03, 392.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 30s\tTrain Loss: 0.768 | Test Loss: 0.788\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:26, 239.91it/s]\n",
      "1562it [00:04, 367.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 30s\tTrain Loss: 0.763 | Test Loss: 0.787\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 243.65it/s]\n",
      "1562it [00:03, 390.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 29s\tTrain Loss: 0.760 | Test Loss: 0.786\n",
      "epoch start:  5\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:26, 238.97it/s]\n",
      "1562it [00:04, 383.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 30s\tTrain Loss: 0.755 | Test Loss: 0.786\n",
      "epoch start:  6\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 246.89it/s]\n",
      "1562it [00:03, 398.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 29s\tTrain Loss: 0.754 | Test Loss: 0.786\n",
      "epoch start:  7\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:26, 240.10it/s]\n",
      "1562it [00:03, 391.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 30s\tTrain Loss: 0.753 | Test Loss: 0.786\n",
      "epoch start:  8\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 242.88it/s]\n",
      "1562it [00:03, 396.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 29s\tTrain Loss: 0.752 | Test Loss: 0.787\n",
      "epoch start:  9\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:25, 242.60it/s]\n",
      "1562it [00:03, 395.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 29s\tTrain Loss: 0.752 | Test Loss: 0.787\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(featureExtractor, training_iterator, optimizer, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(featureExtractor, test_iterator)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(featureExtractor.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)\n",
    "    \n",
    "to_write = []\n",
    "for i in featureExtractor.vector_weights.data:\n",
    "    to_write.append(float(i))\n",
    "with open(f'results/extract_features.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(zip(corpora.index_word,to_write)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3905d7db50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watered',\n",
       " 'worst',\n",
       " '\"worst',\n",
       " 'horrible.',\n",
       " '\"broke',\n",
       " '\"save',\n",
       " 'hated',\n",
       " 'worst.',\n",
       " '\"terrible',\n",
       " 'awful.',\n",
       " 'scam.',\n",
       " 'disgusting.',\n",
       " 'case!',\n",
       " 'disappointment.',\n",
       " 'embarrassed',\n",
       " 'worse',\n",
       " 'poorly',\n",
       " 'ridiculous!',\n",
       " 'throwing',\n",
       " 'trash.\"',\n",
       " 'gross.',\n",
       " 'sucks!\"',\n",
       " 'disappointed\"',\n",
       " 'ruined',\n",
       " 'fake.',\n",
       " 'zero',\n",
       " 'terrible.',\n",
       " 'waste',\n",
       " 'unhappy',\n",
       " 'threw',\n",
       " 'dissatisfied',\n",
       " 'ridiculous',\n",
       " 'dissatisfied.',\n",
       " 'horribly.',\n",
       " 'terrible',\n",
       " 'chirp',\n",
       " 'worse.',\n",
       " 'useless!',\n",
       " 'weighs',\n",
       " 'inflate',\n",
       " 'muslim',\n",
       " 'worthless',\n",
       " 'fake!',\n",
       " 'horrible!',\n",
       " 'unnatural',\n",
       " 'headache.',\n",
       " 'horrible',\n",
       " 'dangerous',\n",
       " 'awful!',\n",
       " 'disappointed.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.argsort(featureExtractor.vector_weights)[0:50]\n",
    "top50_words = []\n",
    "for i in top50:\n",
    "    top50_words.append(corpora.index_word[i])\n",
    "            \n",
    "top50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complements',\n",
       " 'beautiful.',\n",
       " 'cabello',\n",
       " 'clears',\n",
       " 'biting',\n",
       " 'delighted',\n",
       " 'perfect!',\n",
       " 'tweezers.',\n",
       " '\"gives',\n",
       " 'amazing.\"',\n",
       " 'shaver,',\n",
       " 'maldon',\n",
       " 'disappoint!',\n",
       " 'amazing.',\n",
       " 'diapers.',\n",
       " 'subscribe',\n",
       " 'best!',\n",
       " 'norelco.',\n",
       " 'fabulous',\n",
       " 'excelente',\n",
       " 'awesome!',\n",
       " 'mall.',\n",
       " 'qtips',\n",
       " 'sooner.',\n",
       " '\"heats',\n",
       " 'dermatologist,',\n",
       " 'compliments',\n",
       " 'works!!!',\n",
       " 'diaper',\n",
       " 'disappoint.',\n",
       " 'amazing!',\n",
       " 'tweezer',\n",
       " 'works!!',\n",
       " 'pampers',\n",
       " 'gorgeous!',\n",
       " 'add-on',\n",
       " 'great!!!',\n",
       " '\"tastes',\n",
       " '\"love',\n",
       " 'gallon',\n",
       " 'cleared',\n",
       " 'trick!',\n",
       " 'compliments.',\n",
       " 'swabs',\n",
       " '\"best',\n",
       " 'healed',\n",
       " 'works!',\n",
       " 'q-tips',\n",
       " 'sucking']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot50 = torch.argsort(featureExtractor.vector_weights)[-50:-1]\n",
    "bot50_words = []\n",
    "for i in bot50:\n",
    "    bot50_words.append(corpora.index_word[i])\n",
    "            \n",
    "bot50_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-0.7972, -0.7784, -0.6767,  ...,  0.6563,  0.6590,  0.6916],\n",
       "       device='cuda:3', grad_fn=<SortBackward0>),\n",
       "indices=tensor([ 3601,  2218, 14598,  ..., 16209,  6590, 11934], device='cuda:3'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50 = torch.sort(featureExtractor.vector_weights)\n",
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0211, -0.2522,  0.0054,  0.0728, -0.0466,  0.0178,  0.3600,  0.0023,\n",
       "         0.0056, -0.0116], device='cuda:3', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureExtractor.vector_weights[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N0O0N', '\"not', '', 'once', 'touch', 'water,', 'gone!', 'light', 'on', 'to']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpora.word_index.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   47,    58,    61,   101,  8879,   110,  6713,    47,    58,    18,\n",
      "           331,  3919,   131,   234, 11986]], device='cuda:3')\n"
     ]
    }
   ],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n",
    "\n",
    "print(seq6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([0.3545], device='cuda:3', grad_fn=<SumBackward1>)\n",
      "Example:  good \n",
      "prediction:  tensor([0.1642], device='cuda:3', grad_fn=<SumBackward1>)\n",
      "Example:  okay \n",
      "prediction:  tensor([-0.0048], device='cuda:3', grad_fn=<SumBackward1>)\n",
      "Example:  trash \n",
      "prediction:  tensor([-0.3409], device='cuda:3', grad_fn=<SumBackward1>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([0.3735], device='cuda:3', grad_fn=<SumBackward1>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([-0.1871], device='cuda:3', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "z = featureExtractor.forward(seq1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", z)\n",
    "z = featureExtractor.forward(seq2)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", z)\n",
    "z = featureExtractor.forward(seq3)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", z)\n",
    "z = featureExtractor.forward(seq4)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", z)\n",
    "z = featureExtractor.forward(seq5)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", z)\n",
    "z = featureExtractor.forward(seq6)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8569440305709839,\n",
       " 0.7835218748950958,\n",
       " 0.7681020613384247,\n",
       " 0.7634931796979905,\n",
       " 0.7601615890884399,\n",
       " 0.7553226647615433,\n",
       " 0.7543391159296036,\n",
       " 0.7528399777173996,\n",
       " 0.7523440411233902,\n",
       " 0.7518714605522155]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02109731361269951"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('results/extract_features.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data[\"N0O0N\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that the forward function we do not consider the sentence length, so all values are arround zero, because the training minimized the impact of sentence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# Below is a NN Classifier using the extracted features\n",
    "1. use the same corporous\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02109731361269951"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('results/extract_features.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data[\"N0O0N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import embedding, nn\n",
    "\n",
    "# Draw 4 lines that classiy the sum of features into 5 possible classes\n",
    "# Use device 2!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Current best: hid=256, 3 square hid layers\n",
    "        hid = 256\n",
    "\n",
    "        \n",
    "        # The Initialization \n",
    "        self.data = (torch.tensor(list(data.values()))*4).cuda(3)\n",
    "        \n",
    "        # Convert Sentence_len * 1 input to Sentence_len * 5, the sum up on sentence_len dim, perform softmax, \n",
    "        # then we get the distribution!\n",
    "        self.fc = nn.Linear(1, hid)\n",
    "        self.fc2 = nn.Linear(hid, hid)\n",
    "        self.fc3 = nn.Linear(hid, hid)\n",
    "        self.fc4 = nn.Linear(hid, 5)\n",
    "        \n",
    "        \n",
    "                                  \n",
    "        self.dropout1 = nn.Dropout(0.8)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "                                  \n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emd = torch.sigmoid(torch.sum(self.data[src].unsqueeze(2),dim=1))\n",
    "        # [batch_size, sentence_len,5]\n",
    "        l1 = self.dropout1(nn.ReLU().forward((self.fc(emd))))\n",
    "        l2 = self.dropout2(nn.ReLU().forward((self.fc2(l1))))\n",
    "        l3 = self.dropout(nn.ReLU().forward((self.fc3(l2))))\n",
    "\n",
    "                               \n",
    "        z = self.fc4(l3)\n",
    "#         z = torch.sum(z, dim = 1)\n",
    "        \n",
    "        d = torch.softmax(z,dim=-1)\n",
    "            \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "lc = LinearClassifier(data).cuda(3)\n",
    "\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, - 0.08, 0.08)\n",
    "lc.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(lc.parameters())\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "\n",
    "    tmp = optimizer.state_dict()\n",
    "    tmp[\"param_groups\"][0][\"lr\"] = 0.001/(num_epochs_train + 1)\n",
    "    optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 1:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.0005\n",
    "#     if num_epochs_train == 2:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 3:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.000225\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "#     if num_epochs_train == 4:\n",
    "#         tmp = optimizer.state_dict()\n",
    "#         tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "#         optimizer.load_state_dict(tmp)\n",
    "        \n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = lc.forward(batch[0].cuda(3))\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = lc.forward(batch[0].cuda(3))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(3))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 288.51it/s]\n",
      "1562it [00:05, 262.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 27s\tTrain Loss: 1.552 | Test Loss: 1.554\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 296.37it/s]\n",
      "1562it [00:05, 265.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 26s\tTrain Loss: 1.552 | Test Loss: 1.554\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:20, 304.17it/s]\n",
      "1562it [00:05, 265.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 26s\tTrain Loss: 1.552 | Test Loss: 1.554\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:20, 304.99it/s]\n",
      "1562it [00:05, 264.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 26s\tTrain Loss: 1.552 | Test Loss: 1.554\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 293.70it/s]\n",
      "1562it [00:05, 263.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 27s\tTrain Loss: 1.552 | Test Loss: 1.554\n",
      "epoch start:  5\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:22, 277.59it/s]\n",
      "1562it [00:05, 262.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 28s\tTrain Loss: 1.552 | Test Loss: 1.554\n",
      "epoch start:  6\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:22, 277.85it/s]\n",
      "1562it [00:05, 263.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 28s\tTrain Loss: 1.552 | Test Loss: 1.554\n",
      "epoch start:  7\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 289.62it/s]\n",
      "1562it [00:05, 264.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 27s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  8\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:20, 301.74it/s]\n",
      "1562it [00:07, 210.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 28s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  9\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 288.91it/s]\n",
      "1562it [00:05, 265.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 27s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  10\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 286.95it/s]\n",
      "1562it [00:05, 264.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 27s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  11\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 287.43it/s]\n",
      "1562it [00:05, 264.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 27s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  12\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 287.32it/s]\n",
      "1562it [00:05, 265.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 27s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  13\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:20, 301.65it/s]\n",
      "1562it [00:05, 262.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 26s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  14\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:20, 303.73it/s]\n",
      "1562it [00:05, 263.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 26s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  15\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:20, 303.72it/s]\n",
      "1562it [00:05, 264.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 26s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  16\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:20, 303.95it/s]\n",
      "1562it [00:05, 263.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 26s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  17\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 295.83it/s]\n",
      "1562it [00:05, 263.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 27s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  18\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:22, 279.04it/s]\n",
      "1562it [00:05, 264.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 28s\tTrain Loss: 1.551 | Test Loss: 1.554\n",
      "epoch start:  19\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:21, 291.11it/s]\n",
      "1562it [00:05, 265.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 27s\tTrain Loss: 1.551 | Test Loss: 1.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(lc, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(lc, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(lc.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f379113bd50>"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD7CAYAAACFfIhNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABGG0lEQVR4nO3deXhU5d3/8fc5s2WZJJNlErInJIRdIERQcGFxQRZFn2pxLbhVbcGnyk+wVqmKtdCW1lJFbdH6KNStikJYFVEWF/Z9CWEJWUlCAtknM3N+fwwOAgGSMJOZhO/rurgSMmf5zMlkvnPu+5z7VjRN0xBCCCEA1dcBhBBC+A8pCkIIIdykKAghhHCToiCEEMJNioIQQgg3KQpCCCHcpCgIIYRw0/s6gCdUVNTgdLb8dovISDPl5dVeSHTxJFvrSLbWkWyt016zqapCeHhwk491iKLgdGqtKgo/ruuvJFvrSLbWkWyt09GySfOREEIIt2adKcyYMYNly5ZRUFDAwoULycjIOGuZ2bNnM3/+fKKjowHIzMxk2rRp7sffffdd5s2bh8FgQFVVPvvsMwCef/55vv32W4xGI0FBQTzzzDP07t3bE89NCCFECzWrKAwfPpz77ruPu++++7zLjR07lilTppz18+XLl7N06VI+/vhjzGYzZWVl7seuueYafvvb32IwGPjqq6/4zW9+wxdffNHCpyGEaEuaplFRUYrNVg94t/nk6FEVp9Pp1X20lj9nKy1V0elMhIdbURSl2es1qyhkZWW1OhjAW2+9xeOPP47ZbAYgKirK/djQoUPd3/ft25fi4mKcTieqKi1bQvir6urjKIpCTEwCiuLdv1W9XsVu9883Xn/OptNBWdlRqquPExJiafZ6Hu1ozs7OZs2aNVitViZOnEi/fv0AyM3NZevWrbzyyivYbDbGjRvHHXfccdb68+bNY8iQIS0uCJGR5lZntlpDWr2ut0m21pFsrdOSbOXlhURGxqDXt821Knq9/35I9Ods4eGRHDtWgtWa2Ox1PPYbHTduHI888ggGg4G1a9fy2GOPsXjxYsLDw3E4HBQVFTF//nwqKiq48847SU1N5fLLL3evn52dzcKFC5k3b16L911eXt2qXnarNYTS0qoWr9cWJFvrSLbWaWm2xsZGNK1tPiX786dxf8+maSo2W+NZv1tVVc75YdpjJc5qtWIwGAAYPHgwsbGx5OTkABAXF8fo0aNRVZXIyEgGDRrEtm3b3OuuWLGCv/71r8ydO/e0piVvsu35msJ3n0OmkxCidVrSTi18ozW/I48VhZKSEvf3u3fvpqCggNTUVABGjx7N6tWrAaitrWXjxo1069YNgK+++oqXX36ZuXPnkpCQ4Kk4F+Z0UJ+3E+fxorbbpxDCK+bOfYPGxsZWrbtnzy6ef/53F1yurKyUiRN/2ap9nMvcuW/wj3/8zaPbvFjNaj6aPn06y5cvp6ysjAkTJmCxWMjOzuahhx5i0qRJ9O7dm1mzZrFz505UVcVgMDBz5kysVisA48eP59lnn2XUqFEA3HLLLQwePBiAp59+GoPBwKRJk9z7+/e//014eLinn+tp9Am9aQAcR3ags8R5dV9CCO96++1/cued97pbK37Kbreft++jW7ceTJs2/YL7iIqyMnv2GxeVsz1QOsJ0nK3tU6j/+GmcwVaCbnrCC6kuTkdqf25Lkq11WpqtuPgwnTolezHRKRdqt//LX2bw6acfkZaWjqKozJ79Bn//+1/Q6XTk5R2mtraWf/97Ps8//zvy8g7T2GgjPj6Rp59+jtDQUDZt2sCrr77C3LnvUlRUyIMP3svNN9/Gd9+tpb6+nqlTn6NPn77ux7KzvwTgqquyeOSRX7Fq1VccP36cX/1qEkOGDAdg1aovefPN1zCZTAwdeh1vvvkay5d/Q1BQ0GnZ5859g7q6On796//F4XAwZ85svv9+HQADBw7i0UcnotPp+OyzT/jww/kYDEY0zckLL/yRxMQkZs2ayaZN6zEYjAQFBTJnzltnHbemflfn61PoEMNctMbmfaUYnAkkF25Fs9tQ9EZfRxKiXVq7vYg127zTDHvVZbFc2y/+vMs8+eQUPv30I+bMeeu0N92cnH384x9vEhgYCMDjj0/GYrEA8OabrzFv3js8+ujEs7Z3/PhxevW6jF/+8lcsX76E11//+2lvtj8VHBzMv/71f2zbtoXnnnuaIUOGc+xYOTNn/oE33nibxMQkPvigeRfPfP75p+Tk7OOtt1zLT548ic8//5Rbb/0Zr732CvPm/ZeoqChsNhtOp5P9+/exefMG3nvvI1RV5cSJE83az4X477VUXpZ3tJpl+SHgsOEozvF1HCGEhw0ZMtxdEACWLl3E/fffw333/ZwVK5aRk7OvyfUCA4MYPPhqAHr27E1BQcE593H99Te6lysrK6WhoYFdu3aQkdGVxMQkAEaNuqVZeTds+J6RI0djMBgwGAyMHDmGDRu+ByAz83JeemkaH3/8PqWlRwkICCAuLgG73c4f//giS5dmN2sfzXHJninERQWzxBaDpuiw529Hn9DT15GEaJcG945lcO9YX8c4S1DQqYKwdetmFiz4L3PmvEV4eDjLly/l888/aXI9o/FUv4Sqqjgc9nPuw2g0AaDT6QBwOByeiH6WP/zhT+zevZONGzcwadIjTJ78NFdeOZh33/2QzZs3smHDD8yZM5u33nqPyMiLu4Lzkj1TiIsMwoaBmtBkHPk7fB1HCHERgoKCqak59xDWVVVVBAebCQsLw2azkZ39udey9OjRi3379lJQkA/AkiWLmrVeVtZAlixZhN1ux263s2TJIi6/fCB2u53CwgJ69OjFvfeOZ8CAK8jJ2UtFRQX19fUMHHgljzzya8xmM4WF5z6raa5L9kwhJiIIVVUoMqZgLl2Js6YCNdi7VzwJIbxj3Li7mTTpEUymgCavELriikEsX76EO++8jbAwC3379mPXrp1eyRIREcnkyU8zefIkAgICGDToavR6PQEBAedd7+abbyU//wgTJtwFwIABVzJmzK04HA5eeun3VFdXoSgqMTExPPLIrykuLmbGjOk4HA4cDgdXXDGInj0vfjDRS/rqo2fn/kD3kCrGVL5LwLUPYOh6tRfStU5HulKlLUm21mnPVx/50rmy1dbWEBTkmsQmO/tzFi36jDlz5vokm1x91AKJMWZ2Fjq4OTAUe/5OvyoKQoj266OP3uerr77E4bATGhrGlCkXvjnOX1ziRSGEH3aWoKb3xJG/A01zen3ERyFEx/eLXzzAL37xgK9jtMol/Q6YFBOCU9OosmSg1VfhLDvs60hCCOFTl3RRSIhxDRVcqHe1t9mPbPdlHCGE8LlLuyhEm1GAI1UKapRcmiqEEJd0UQgw6okMC6CwrAZ9Qm8cJblotjpfxxJCCJ+5pIsCuO5sLiyrRZfQCzQH9sJdvo4khBA+I0UhMpjiY7Uo1jQwBOA4Ik1IQrQ3FzOfQnO2UVRUyKhRwy9q++3FJV8UYiODsDuclFU3oovthj1/h8zGJkQ78/bb/7zoouCJbXQEl/R9CuBqPgIoKqslPLEXDXlb0E6UoIR1Ou96mqbJdIRCAI371tK49xuvbNvQ9Rr0Pc5/U+lf/jIDgEcfvd89n4KqKsye/Vdyc3Ow2Wz065fFxIm/QafT8dZbb/LFF8swGk0oCvz972/w5puvnbWNkJCQc+7zu+/W8cYb/8DpdGKxhPP//t9vSUhIJC/vEC+99Dz19fU4nQ5uumkMd911L6tXr+Kf/5yDqupwOOz85jdPkZmZ5anD5FGXfFGIjXQVhcLyGi7r7pqNzX5kB8bzFAXn8WJqF/8FY4+hGPuMbKOkQoimNDWfwh//+CJ9+2YydeqzOJ1Onn/+d2Rnf86QIcP48MP5fPbZUkymAGprazAaTeeck6EpFRXHmD79OWbPfpMuXdJZsOATnn/+d/zzn+/wyScfc9VV13DvvRMA3HMc/Otfb/DUU8/Qq9dlOBwO6uv994KWS74oBAXosZiNFJbVoIYlo4RYsedvx9jruiaXd1aVUbtoJlrNMRo2LECffqUMpCcuaYaMwRgyBvs6xmnWrPmG3bt38v77rglr6uvriY6OITjYTHx8Ii++OI0BA65g0KCr3WMUNdfOnTtIS8sgNbUzACNH3sxf/jKD2toa+vbtx2uv/Z36+noyM7PcZwP9+2fx97/PYsiQYVxxxSA6d0737BP2oEu+KICrCamovAYAfWJvGvetRXPYUXSnHx5nbSW12TPRGusJuH4i9V/OoWH9JwQOaZ+3swvRcWn84Q9/Jj4+4axH3njjbbZv38qmTRt44IF7+MtfZpOe3sUjex0yZDi9el3GDz98x3vv/Zvs7M957rkXmTTpSXJz97Nx43qefXYqP//53dx8860e2aenXfIdzeBqQiosq0XTNNelqfYGHCWnz8bmrK+iLnsmWt0Jgm56AkNqfwy9rsO+bw2O8jwfJRdCwNnzKQwefA3vvfeOe9KbyspKCgsLqK2tobKykn79+vPAA7+kc+c0DhzIbXIb59KzZ29yc/dx+PAhwDVfQpcuXQkKCiY//wgREZGMHDmGCRMecg/PnZd3iLS0dO64405uuOEmdu/230vf5UwB15lCQ6ODYycaiIjrDooOx5Ht6OO6A6A11FCX/WecJ0oJvOkJdDGuUz9TvzE07l1Nw/cfEjRysi+fghCXtDPnU3j88Sd57bW/M378nSiKgsFgZNKkJ9Hr9TzzzFPYbA04nU4yMrpx7bVDm9zGuTqaw8PD+d3vXuD555/B4XBgsYTz3HMvArBy5QqWL1+KwaBHURQef/xJAObM+Qf5+XnodHrMZjNPP/1c2xyYVrik51P4cQz5vXkVzJi/mSfu6EOvzpHULnwZzVZH8P+8gNZYT+3iP+MsPUjgDY+jT7rstG3Yti+j4dv/EHjTk+gTL36CizOz+SPJ1jodKZvMp+DSHrK1dD4FaT4CYk9ellpY5upX0CX0wlmeh7OqlLplr+A8eoCA4Y+eVRAADD2Go4RYafjuAzSnf744hBCiuaQoAKFBRsyBBgrLawHQJ7g+8dd+/jKOwj0EDHkQQ2rT1xQrOj2mgbfjrMincd/qNssshBDeIEXhpLjIIApPXoGkRiWhBISg1RzDdPUvMHQZdN519amXo0anYdvwKVpjQ1vEFcLnOkDLc4fXmt+RFIWT4qKCKSqrOXmnsorpqnsJGPYIxu5DLriuoigEXDEOrbYS27al3g8rhI/9eGeu8G8Ohx1V1bVoHSkKJ8VGBVNTb+dErWvsE0PnARjSr2j2+rpOXdCnZmHbuhhnbaWXUgrhHwIDzVRVVaJp0o/mrzTNSVVVBYGBTXcon8sFL0mdMWMGy5Yto6CggIULF5KRkXHWMrNnz2b+/PlER0cDkJmZybRp09yPv/vuu8ybNw+DwYCqqnz22WcA1NXV8fTTT7Nz5050Oh1Tpkxh6NChLXoCnhIXeaqzOSzY2KptmAbcjv3wZmwbFhBwzXgPphPCv5jNYVRUlFJSkg94txlJVVWcfnoRhz9n0+lUdDoTZnNYi9a7YFEYPnw49913H3ffffd5lxs7dixTpkw56+fLly9n6dKlfPzxx5jNZsrKytyPzZ07F7PZzIoVKzh06BB33303y5cvJzi4Zbede4J7YLzyGront27YCjUsBkOPYTTu/AJDr+vRRcR7MqIQfkNRFCIiottkXx3pUt621NpsF2w+ysrKIjY2tlWhAN566y1+/etfYza7TmGioqLcjy1ZsoSf//znAKSkpNCrVy+++cY7oy1eiMVsJMCoc1+W2lqmzFvAEEDD9x94KJkQQrQdj/UpZGdnM2bMGO6//342b97s/nlubi5bt25l3Lhx3HbbbXz44YfuxwoLC4mPP/VpOjY2luLiYk9FahFFUU7OwnZxRUEJMGPqdzOOI9toWP9fNLvNQwmFEML7PDLMxbhx43jkkUcwGAysXbuWxx57jMWLFxMeHo7D4aCoqIj58+dTUVHBnXfeSWpqKpdffrkndg1wzjvzmsNqPXUre+d4Cxv3lJz2s9bQhtxKaU0R1ZsX4jy0nqgbHyQord9FZfM3kq11JFvrSLbWaU02jxQFq9Xq/n7w4MHExsaSk5PDgAEDiIuLY/To0aiqSmRkJIMGDWLbtm1cfvnlxMXFUVBQQEREBABFRUUMHDiwxfu/2GEufhRuNlBR1cDBvGOYAw0t3t5PKYPuJzBpIPVr36X4/enoO1+O6cq7mj3Mdkdsq2wLkq11JFvrtNdsXh/moqSkxP397t27KSgoIDU1FYDRo0ezerXrTt/a2lo2btxIt27dABgxYgQffOBqez906BDbt2/n6qvPP8uSN/14BdKPw2hfLH1CT4J/9iLGrNuwH95CzYdPY9u+DM3p8Mj2hRDC0y54pjB9+nSWL19OWVkZEyZMwGKxkJ2dzUMPPcSkSZPo3bs3s2bNYufOnaiqisFgYObMme6zh/Hjx/Pss88yatQoAG655RYGD3ZNyPHAAw8wdepUrr/+elRV5YUXXnB3SPtCrPsKpFq6JFg8sk1FZ8CUeTOG9CuoX/seDd/+h8Z9awi46hfu0VaFEMJfyCipPzm9cjo1Hpv1NUP6xTNuuGcm3fgpTdOwH9pIw7r5aHXHCf75DNSQqCaXba+npb4m2VpHsrVOe80mo6Q2k6oqdPrJGEiepigKhtQsAkdNBqcD+5HtXtmPEEK0lhSFM8RFusZA8iY1LBYlOAJHwU6v7kcIIVpKisIZYqOCKT/RQL3Ne4N9KYqCLr4n9sLdMgeDEMKvSFE4Q1xkEODqbPYmfUIPaKjBWX7Yq/sRQoiWkKJwhrgzZmHzFl1cDwDs0oQkhPAjUhTOYLUEolMVr58pqEFhqBGJOPKlKAgh/IcUhTPodSoxEUFeP1MA0MX3wFGcg2aX2dqEEP5BikIT4rx4WepP6RN6gtOOozjH6/sSQojmkKLQhNjIYEor62i0e3c4Cl2nrqDqsEsTkhDCT0hRaEJcVDCaBsXH6ry6H8VgQheTjqNgl1f3I4QQzSVFoQk/nYXN23TxPXGWH8ZZd8Lr+xJCiAuRotCEThGBKIr3L0uFk/0KgKNwt9f3JYQQFyJFoQkGvQ6rJZC8kmqv70uNSgFjoAx5IYTwC1IUzqFflyi27i/jyFHvFgZF1aGP64E9fycdYMBaIUQ7J0XhHEZdmUJQgJ6Pvtrv9X3p4nugVZejnTjq9X0JIcT5SFE4B3OggTGDUthx8Bg7DpR7dV/6eFe/ggx5IYTwNSkK5zE0MwGrJYAPv9rfqkl8mksJi0ExR8qQF0IIn5OicB4GvcrPhqSTX1rD2u1FXtuPoijo43vIUNpCCJ+TonABWV2tpMWF8snqAzTYvHeHsy6+J9hqcZYd8to+hBDiQqQoXICiKPx8WBeOV9tY9kOe1/aji5ehtIUQvidFoRnSE8LI6mplyfd5VFZ7Z0RTNTAUNTJRhrwQQviUFIVm+p8hadgdThasPui1fejie8pQ2kIIn5Ki0Ewx4UEMy0xg9bZC8ku9c0ObPv7kUNpF+7yyfSGEuBApCi0wZnAKgUY9H32V65Xt6zplgKqXfgUhhM9IUWgBc6CB0YNS2H6gnJ0Hj3l8+6eG0paiIITwDSkKLTS8fwJRYQF8sNI7N7TpEnriLD+Co+a4x7cthBAXIkWhhVw3tKWRX1rN8vVHPL79H4e8qDu0zePbFkKIC5Gi0AqXd4umb3oUH361n0+/OeDR0U1dQ2kHUXdQioIQou3pm7PQjBkzWLZsGQUFBSxcuJCMjIyzlpk9ezbz588nOjoagMzMTKZNmwbA1KlTWbduHeHh4QCMGDGCRx99FIAtW7bw0ksvYbPZsNvt3HPPPdx5550eeXLeoigKv7qtF/+3dC8L1x2ioqqB+0Z0Ra+7+BqrqCr6uO7UHtxG4AANRVE8kFgIIZqnWUVh+PDh3Hfffdx9993nXW7s2LFMmTKlyccefvhh7rnnnrN+Pm3aNP73f/+XoUOHUlpayg033MD1119PVFRUc6L5jE5VGX9TN8JDTHy+9hCVNQ08NrYXAcZmHdLzbzuuGw2HNqJVl6OE+PdxEEJ0LM36aJuVlUVsbKxXAiiKQlVVFQA1NTUEBwcTGBjolX15mqIojL26M+Nv6saugxXMmLeZ4x6441nXyXUm5iiW+xWEEG1L0VrQID5s2DBef/31czYfffTRR4SFhWG1Wpk4cSL9+vUDXM1H69evJygoiMTERJ588knS0tIA2L17N4899hiapnH8+HH+9Kc/cd1113no6bWd9buKmfHuBixmE88/fCXxVnOrt6U5HRyaNR5zj8FYRz7iwZRCCHF+HisKpaWlWCwWDAYDa9euZfLkySxevJjw8HBKSkqwWq2oqsqCBQt45ZVX+OKLL9DpdDz55JMMHz6ckSNHcuDAAcaPH8/7779PXFxcs59EeXl1qy4PtVpDKC2tavF653Kg8AR/+2grAI//7DLS4sNavS37F6/QUFFC8O1/8FQ8j/H0cfMkydY6kq112ms2VVWIjGz6g6vHrj6yWq0YDAYABg8eTGxsLDk5OQDExMSgqq5djR07ltraWoqLizl27BhffPEFI0eOBKBz585kZGSwdetWT8VqU53jQnnmvv4EmfT86T+b2bCn9dNrBiR1x1lRiFbv3TmihRDipzxWFEpKStzf7969m4KCAlJTU896bPXq1aiqSkxMDGFhYRiNRtavXw+4zjb27NlDenq6p2K1uZjwIH57b38SY8y8tmAHn3yTi7MVl6wGJHYHwC79CkKINtSsS2WmT5/O8uXLKSsrY8KECVgsFrKzs3nooYeYNGkSvXv3ZtasWezcuRNVVTEYDMycOROr1QrAlClTKC8vR1EUzGYzc+bMQa937fqvf/0rf/jDH3A4HDidTiZOnEiXLl2894zbQGiwkafuzOS95XtZtO4wR0qqeWhMT4ICmn9lkikuHVQ9juJ9GFIyvZhWCCFOaVGfgr/ylz6FM2maxspNBbz/ZQ5WSyAT/6c3sZHBzc52+F9T0TQHwWOf81rG1miv7ai+JtlaR7K1js/7FMTZFEVheP8EJo/rS3VdI9P/bwPbcsuavb4uNgNn6WG0RplfQQjRNqQotIGuSeE8Nz4La1ggr3y0jexvDzVraAxdpwzQHDiOemeobiGEOJMUhTYSFRbI0/f25/Lu0fz36wO8/tlOqusaz7uOLiYdUHAU57RNSCHEJe/ix2QQzWYy6PjlzT1Jignhk68PsCevgnHDu3BFj5gmxzhSTMGoEQlyZ7MQos3ImUIbUxSFkVck89z4LKLCAvnnwl385YMtlByrbXJ5XacMHCX70ZyONk4qhLgUSVHwkaSYEJ65tz/33JDBwaITPDv3Bz5fc5BGu/O05XSxGWBvwFl22EdJhRCXEmk+8iFVVRiWmUBmhpX3v8xhwZqDfLerhPtu7IrVGgL8dHC8HHTRnX0ZVwhxCZAzBT9gMZt45JZe/OaOPtgdTmb+ZzNzP98BgBocjhJilX4FIUSbkKLgR3p3juTFBweS1S2az77JpaHR1Y+g65SBo3ifR2d4E0KIpkhR8DMmg44B3aLRNCgsqwFc/QpafRXa8WIfpxNCdHRSFPxQQrTr9vP8o64RUnWdXGNByeB4Qghvk6Lgh6ItgRgNOvJLXWcKalgsSkAIjiIpCkII75Ki4IdUVSEpxkx+qetMQVEUd7+CEEJ4kxQFP5UcG0pB6akJdnSdMtCqSnHWVPgwlRCio5Oi4KdSYsM4UdvIiRobcKpfQc4WhBDeJEXBT6XEum5e+7EJSY1KBr1J+hWEEF4lRcFPJceGArg7mxVVhy4mHUeJFAUhhPdIUfBT4SEBhAQZ3GcK4OpXcJbnozXU+DCZEKIjk6LgxxKsZve9CvBjv4KGo2S/70IJITo0KQp+LN4aTGFZjXv+aV1MGig66WwWQniNFAU/lmA1Y7M7Ka2sA0DRm1CtyTITmxDCa6Qo+LHEH4e7OKNfwXH0AJrd5qtYQogOTIqCH4uLCkbh1BVIcHJ+BacdR+lB3wUTQnRYUhT8mMmgwxoeeNqZgv4nk+4IIYSnSVHwcwlW82lnCkqAGTU8nsa93+A4lu/DZEKIjkiKgp9LsAZztKLWPeEOgGnwvdBYT+2nv8e2fTma5jzPFoQQovmkKPi5BKv5tAl3APRx3Qj62XR08b1o+HY+dUtmyUB5QgiP0DdnoRkzZrBs2TIKCgpYuHAhGRkZZy0ze/Zs5s+fT3R0NACZmZlMmzYNgKlTp7Ju3TrCw8MBGDFiBI8++igATqeTv//97yxZsgSj0UhsbCxvvvmmR55cRxBvDQZcVyClnhz6AkANDCXwxsdp3L2Khm//Q+3Hz2K6ZgKG1P6+iiqE6ACaVRSGDx/Offfdx913333e5caOHcuUKVOafOzhhx/mnnvuOevn77zzDgcPHmTRokUYDAbKysqaE+mSERMehEGvUlB69tAWiqJg7DEUfVw36la+Qf2K2Ti6Xo1p0N0ohgAfpBVCtHfNKgpZWVleC/DWW28xf/58DAYDAFFRUV7bV3ukqgpxUcGnXYF01jKWWIJu+R22jQuwbcnGXrSXwOt+hS4quQ2TCiE6Ao/2KWRnZzNmzBjuv/9+Nm/efNpjb7/9NmPGjOGxxx4jNzcXgKqqKiorK1myZAm33347P//5z/niiy88GalDSLAGn3YFUlMUnR7TgJ8ROGYqOOzULvojjqO5bZRQCNFhaC0wdOhQbe/evU0+dvToUc1ms2mapmlr1qzRrrjiCu3YsWOapmlacXGx5nA4NE3TtE8//VQbMmSIZrfbtYqKCi0jI0ObM2eOpmmadujQIW3QoEHa4cOHWxKrw/t0VY42+okFWmVVfbOWb6w8qh1+9THtwMy7tbq83V5OJ4ToSJrVfNQcVqvV/f3gwYOJjY0lJyeHAQMGEBMT435s7NixvPzyyxQXFxMfH09QUBA333wzAMnJyfTo0YNdu3aRlJTU7H2Xl1e7B41rWeYQSkurWrxeW/hpNkugq2lt6+5iuqdENGPtAEwjp1C7aAaF818g8KYn0Md29Uo2fyPZWkeytU57zaaqCpGR5qYf81SAkpIS9/e7d++moKCA1NTUsx5bvXo1qqq6C8Xo0aNZvXo1AOXl5ezZs4cuXbp4KlaHkOC+Aqn58yioweEEjZmKao6kbvFfsBfs8lY8IUQH0qwzhenTp7N8+XLKysqYMGECFouF7OxsHnroISZNmkTv3r2ZNWsWO3fuRFVVDAYDM2fOdJ89TJkyhfLychRFwWw2M2fOHPR6165/85vf8Nvf/pZ3330XRVF44oknSEtL894zbodCg42YAw0cOU9nc1PUIAuBY6ZSlz2TuqV/JfCGSegTe3sppRCiI1A0TWt5u4uf6ejNRwAz52+iodHBs7+4vMXbctZXUZf9J5wVhQRe/2v0yX09ms2fSLbWkWyt016ztUnzkfCuhGgzBWU1OFtRw9WAEIJGPYUamUjditk0HtrohYRCiI5AikI7kWA1Y2s8NeFOSykBZoJGTkaNSqZ+xWvY83d4OKEQoiOQotBOJFhPTrhztPmdzWdSTMEEjfx/qJZY6r96E2dtpYfSCSE6CikK7UT8yQl3ClrY2XwmxRhIwPBH0Wz11H/1TxlhVQhxGikK7YTJqMNqCTzvcBfNpYuIxzToLhwFO7FtXeqBdEKIjkKKQjsS34zhLprL0O1a9J0vx7b+vzIchhDCTYpCO5JgNVNSUYvtJxPutJaiKARcPR4l2ELdl6+j2Wo9kFAI0d5JUWhHEqJPTrhT7pmzBcUUTODwR9Gqy6lf/Q4d4JYVIcRFkqLQjriHu7iIK5DOpItJx5h1K/bc77HvXX3R29NsdTirSj2QTAjhCx4bEE94348T7niis/mnjH1G4SjYRf3a91Bj0tGFx7VqO47Sg9Qt/Sta3QmUECv6+J7oEnqij+uOEtD03ZNCCP8iRaEdUVWFuMjgi74s9UyKqhIw9GFq//sc9V/OIWjssyh6Y4u2YT+8hbovX0MJDMV0xTgcRXtpzP2exj2rAAXVmuIuErrotBZvXwjRNqQotDMJ1mB2HDzm8e2qweEEDHmQuqV/peG79zENvhdFUZq1rm3XShrWvosalULgjf+LGhQGl41Ac9pxHD2II38H9oKd2LYuhi2LQFFQLbGokcnoopJOfk1GMQV7/HkJIVpGikI7E281s3ZHMVW1NkKCPPtpW5/UB0PvG2ncvgxn+RGM/W9BF9/znMVB05zYfvgY29bF6JL6EDj8MRSDyf24ourRd+qCvlMXTFm3otlqcRTuxVF6AEd5Ho6iPdj3f3tqeXMkOmsqpivvRDVHevS5CSGaR4pCO5MQfWpuhe7Jnm+CMQ28AzXEim3rYuoW/xnV2hlT5s3okvqcVhw0RyP1q+Ziz/0OQ/ehmAbfg6LqzrttxRiEPqUf+pR+7p85607gLM/DUXYYZ9lh7HlbwOkg8MbHPf7chBAXJkWhnXGPgVRaTffkcI9vX1F1GHtdh6H7tTTuW4ttyyLqlv0NNTIZY+bN6FP64airpm7xn3EU7cU44HaMfUY2u6npTGpgKGpCL/QJvQBo2PQ5tg2fYC/OQd9JJlsSoq1JUWhnwk5OuJN/1LOdzWdSdAaM3Ydg6HoV9pxvadi8iPoVs1EjEmhQNBwVxQQM+yWG9Cs9ul9j7xtp3LWShu8/QHfzM60uNkKI1pH7FNoZRVHokhDG97tK2H3I8x3OZ+1P1WPoejXBd/yBgKEPg9OBo6aSwJGTPV4QABSDCWP/sThL9mM/vNnj2xdCnJ8UhXboFyO6YbUE8srH29hzuKJN9qmoOgxdBhF0+0skTfon+rjuXtuXoevVqGGdsP3wEZrz4of0EEI0nxSFdig02Mj/u7MfUZZA/vbxVvbmtU1hAFAUFfUnVxh5ZR+qDuOA23FWFtG4b41X9yWEOJ0UhXbqx8IQGRrAXz9q28LQFvQpmagx6dg2fIpmb/B1HCEuGVIU2rGwYCNPnSwMf/toG/uOVPo6kscoioJpwO1otZXYtq/wdRwhLhlSFNq5MLOJ/3dnP8JDTPz1o63k5Ff6OpLH6GO7okvqi21LNs76qovalvN4MXWr/kXt4j/TsOlz7EV70RyNHkoqRMchRaEDsJhNPHVXPyxmE7M+3Mr+/OO+juQxpgG3g70e2+ZFrVrfeeIodav+Rc2HT2PP/QGtpgLbhk+oW/gy1f9+lNqFL9Ow4RPsBbvQGqWZSgi5T6GDsJhNPHVnP2bO38SsD7fwwKge9MuIQm3n1/nrIuIxZFxF484vMfa6DjXE2qz1nFWl2DYvpHHvGlB1GHrdgLHPSNSgMLT6auzF+3AU7cVRtBfb5oWw6XNQdOjTLsc04PYWDbOhaRr2gxuwH1iPMWssOkvrRpkVwh9IUehAwkNMPHVXJn/5YAuvfrqdBGswI69M5vJu0ejU9ntSaOx/K437v6Nh/ScEDvvleZe1nyijfvX7NO79BhQFQ8/hGPuOQg2yuJdRAswYUjIxpGQCrjkgHMU52PO307h7FfaDGzFeNgJj31EohoDz7694Hw3ffYDzaC6gYM/fTuCwR9EnXXaxT1sIn1C0DjDdVnl5NU5ny5+G1RpCaenFtVV7y8Vkczid/LDrKNnfHaawrIZoSyA3XZHEoF6xGPQXXxx8cdwavv8Q29YlBN32e3RRye6fO2uP4yw9gKP0II6jB3AU7QFNw9DtWox9R6OaI1q0H2d1OQ3ff4Q99zuUIAumAT9D32UQinL6cXNUFmL74WPshzahBFkwZt2KPq47dStm4zyWj2ngHRh6jzjtjuyO+nrzNsnWOufLpqoKkZFNz3EiRaEd/kKby6lpbMkpY9G6QxwqrsJiNjJiQBLX9o3HZDz/4HXeztZSWkMN1e8/hS4iAV1iH3ch0KrLXQsoKmpEPObOl+HoMuyiR1l1FOdQ/+1/cJYeQI1KwTToLvSdMnDWVmLb+BmNe74GvRFjn5EYe9/oHh1Wa2ygftU/sR/cgL7LINc82CfnjujorzdvkWytI0VBisI5aZrGrkMVZH97iD15lZgDDdx3Y1eyukX7PFtL2LYtpeG79wFQQqzoojujs3ZGje6MLioJRW/y8HFzYt//HQ0/fIRWU4EuvieOkv3gsGPoMQRj5i2ogaFNrKdh2/w5tg2folo7E3jDRNTg8Evm9eZpkq11WlsUmtWnMGPGDJYtW0ZBQQELFy4kIyPjrGVmz57N/PnziY52vdFkZmYybdo0AKZOncq6desID3eN6jlixAgeffTR09b/9NNPmTp1Kq+//jpDhw5tTizRTIqi0DM1gp6pEezPP85/vszhtQU7GHVlMrde3RlVbR+d0YbeN7hmbbN0Qg0I8fr+FEXF0GUQ+pT+2LYtoXHnl+gTe2Ma8DPUsE7nWU/BlHkLangC9V+9Se2nzxN4wySw9vF6ZiEuVrOKwvDhw7nvvvu4++67z7vc2LFjmTJlSpOPPfzww9xzzz1NPlZcXMwHH3xA3759mxNHXIT0hDCm3p3JvBV7yf72MHkl1Tx8cw+CAwy+jnZBiqKi88Fw2orBhKn/WEz9x7ZoPUNqf9TQ31G37G/ULvwDJxoeQLP2bnfzVdvzd6DVHkff5cqz+lYuxHm8mIb1/0WfeBn6jKtk1Nt2oFlFISsry6shnn32WZ5++mn+/Oc/e3U/wsWgVxl/U3dSOoUyb8U+XnxnAxNv6028tX29WbUHushEgm6dRv0Xr1K25A0A1PAEdLEZ6Dq5/rW0M7ytaE47DT98TOO2pQDoctYScM39qCFRF15X02jc8zUN384Hhx37gfXo9n9HwNW/QA1tXbOlaBsevSQ1OzubNWvWYLVamThxIv36nZph6+233+aDDz4gMTGRJ598krS0NADmz59Peno6ffq0/tT6XG1jzWG1er8ZorW8ne32G7rRs4uVl99Zzx/e28j/jstk0GXNu8b+Uj5uLReCNv5F6o/sof7IbuqP7KJ+/zoad60EQB8WTUBSd4LS+xPc7YoLzmDnLT89bvYTZZR8OovG/L2EZt6IMTqJ8pXvUvvfZ4m8bjwhfYef81O/vbqSsuzXaNi/kcDUy7CO/hW1ORsoX/ketf99lvBrxxF2+agWPU//+52e0tGytaijediwYbz++utN9imUlpZisVgwGAysXbuWyZMns3jxYsLDwykpKcFqtaKqKgsWLOCVV17hiy++oLCwkMcff5z58+cTEBDAvffey/3339/iPgXpaL44FVUN/OOT7RwsOsGYQSnccnXqeW96k+PWOj/NpjkdOMuP4Cjei6M4B0fxPrS6EyghVox9RmLIGOy+aul8HMfyady1ksbc712z2Fk7o4tOdXXARyai6JrXLPjTbPa8bdR/9Saa007ANRMwpA0EXDcE1n/9Fo7C3egSernOGs44y7Ef3kz912+hNdZhGnAHhl7XuZucnNXl1K/5Pxx5W1GtnQm4dgK6iMQWZfM37TWbx64+Ol9RONNtt93G1KlTGTBgwFmPDRw4kE8++YRNmzbxxz/+EZPJdTlfaWkpISEhPPHEE/zsZz9rbiwpCh7QaHfw7vJ9rNlWRK/UCK7pE0dGkoXQoLPfmOS4tc75smmaE/vhzdg2L8JZetB170PvGzF0H4JiDDx9WYcd+6GNNO5aiaNoL6h69CmZaHYbztIDaHUnXAuqetTIJHeR0EWnoYTFNPkJ32oN4WhJJbYNn2Dbko0akUjgdb9CtZzeoa5pThp3fUXD9x+AqiPgyrvQZ1wF9gYavn2fxj2rUCMTCRj6S3QRCU08Tw177vc0rJuH1lCLsd8ojP3GnLd4tdffqa959eqj5igpKSEmJgaA3bt3U1BQQGpq6lmPrV69GlVViYmJYcyYMYwZM8a9jdaeKYiLZ9DrmHBTN5JjQvh4VS47DrpmdYuLCiYj0ULXRAtdkyxYzN6dS+FSpSgqhpT+6JMzcRTswrZlEQ3ff0DDlkUYe16Hsdf1aPYGGnevonHP1+6zCtPAO9B3vdp9NZamaWg1x3AcPYDz5A19jfvW0rjzS9eOTMHootNc/2LS0FlTUUzB2KuOUZftmnfb0O0aTIPuafJMRVFUjD2Ho0/sTf3Xc6n/ei66Az/gPH4U7cRR130bWbee801eURQM6VegS+hJw7r52DZ9TmPuD+iT+6KLTEKNTEa1dPJZExqcPIYnjuI4mouzsghdfA90sV1b3MneXjXrTGH69OksX76csrIywsPDsVgsZGdn89BDDzFp0iR69+7NlClT2LlzJ6qqYjAYmDRpEtdeey0A48ePp7y8HEVRMJvNPPXUU01eaSTNR6f4Mpvd4eRQcRV78yrYe6SSnPzjNNhcM6DFhAcysHcsw/rGNXkW4Wsd6XfqOJqLbfMi17SkOiM4G0EDXdJlGHsMR5fYq1lvVJrTibOy0PUmdzQXR8kBnBUFgOtvRrXEgq0Gp62egKvHY+gyqFn5NM1J484vafj+I5TAEAKGPIQ+rluznx+4mqoaNn2GszwPfhy1VmdAjUhwFYmoZCI7d+W4IwglKMwrb8yarc51R3zJ/pPH6ADaGaPyKsERGNKvQN9l0GlnQBf6nWqaBk4HOBrRnHawN4LT7hqh12F3zRViq0Wz1aOd/Epjnev7xgZUSxz6hB6okUktfu5y85oUBa9xOJ3klVSzN6+SPXkV7Dx4DKNBx82DUxjePwG9zn8+QfnTcTtTa7M5juXTuPNLFFMwhu7XNntQwPNxvxEezcVRkotRp6Fk3YEuPL7F23LWnUDRm9x3dbcqj9OBs7IIZ3kejrLDrq/ledBQc2ohVY9ijkQNiUI1R6KERLmuhDIEQEON6420ofbk1xq0hlrXG66jETTt5D+n6yuur5rDjlZVxqkCGYf641lUdBpqqBX74S007v8Wx5HtoDlRI5MwdLkSffqVxCQncvToCbTaSlf+ikLX10rXV632uHvbzaaoYAxE0RnQaitdPzKZXWcsCT3Rx/do1mtAioIUhTZT74Q5H29l+4FyYiKCuHN4OpelXfgyxbbgz8dNsrWMpmlo1eWEOI9RUZCPVlWGs6oMZ3UZWlXZqb6TMxkDUYxBKKZgFGMQ6I2gKIDi6k9RVNf/FdU1PIql08kmtc4opuBz5nHWncCe+z2NOetwlh50DbgYlUhjZSk01p1a0BCIGh6LaolFDY4AvRFFpwfVADq9q2lNd/J7vQnFGOjqNzIGohgCXcuf7Pdx1lbiKNiFPX8njoKdp4pEaDT6pD6YBtx+zgsSpChIUWgzP2bbllvG+1/up/hYLb06RzBuWBfios79R9WW2fyRZGudc2XT7Da06nI0ewOKMRjFFASGQJQ2GBHYWVlE4/5v0R0/gj0gwlUALHGolliUIItXbtLTNM3VDHiySDiPFxM0cvI57xvxeUezuPRclhZFj5QIVm7M57O1h5j21g8MzYxnzKAUQvywv0F0LIreiGKJ9cm+VUsspqzb2rSYKoqCLjweXXg8xl7Xe20/UhTERdHrVG4YkMQVvTqx4JsDfLkxny835BNvNZORGEZGooUuCRbCQ+SqJSHaAykKwiNCg4zcN6Ibw/onsGlfKTlHKlm7vZiVmwoAsFoCyEiw0CXRQt8uUX555ZIQQoqC8LAEq5mEk2Mo/XjV0r4jlew7UsnW3HLW7ijGuELl2r7xjBiYJGcQQvgZKQrCa3SqSmpsKKmxodw4IAlN0zhytJoV64/w5cZ8vtqcz1W9Y7npimSslsALb1AI4XVSFESbURSFpJgQHhjdg5uvSmXJd4dZs72Ib7YWcUXPGEZdmUxspG+vXhLiUidFQfiE1RLIfSO6MWZwKku/z+PrLQV8u6OY/t2iGTMohcRoGcZbCF+QoiB8KjzExJ3XdWHUlcksX3+ElZvy2bDnKJkZVsYMSiG5k/8OSyxERyRFQfiF0GAjPxuSxoiBSXyx4QgrNuSzaV8pfdOjGDM4hdTYs+dCFkJ4nhQF4VfMgQbGXt2ZGy5P5IuN+axYf4QX39nAZWmRjBmUQlp8mK8jCtGhSVEQfikowMDNg1O5PiuRlZvyWfbDEV56dyPdk8MZ2COGPulRhAXLvQ5CeJoUBeHXAk16Rl3pGo31q80FfLkxn38v2YMCpMaF0ictkj7pUSRGm2VSeCE8QIqCaBcCjHpuGpjMiAFJHDlazdb9ZWzZX86nqw/y6eqDRIaauCw9ihGDUrGa5QxCiNaSoiDalR/vdUiKCWHM4FSOVzewNbecrfvLWLu9iFWbC/jFiG5c0yfO11GFaJekKIh2Lcxs4po+cVzTJ44Gm4N/Ld7Nv5fsweFwMjTz7DmChRDn5z9TZglxkUxGHc9MGEDf9CjeXb6PFeuP+DqSEO2OFAXRoRj0Oh67tRf9M6z858scln6f5+tIQrQrUhREh6PXqfzylp4M6B7Nh1/tZ+G6Q76OJES7IX0KokPS61QeGtMDnary6TcHcDic3HJV6lmXrdodTnLyj7PjYDl7DlcSFxnEqEEpdIoI8lFyIXxLioLosHSqygOjuqPTKXy+9hAOp8Zt13TmaEUdOw4eY8eBcvbkVdLQ6ECnKqTEhrB+z1HW7SxmYI8YxgxKkVFbxSVHioLo0FRVYfxN3dCrCtnfHmbNtiKO19gAiLYEMqh3J3qlRtAtKZxAk54TNTaW/pDHyk35fL+zhMu7RzNmcCrxUVIcxKVBioLo8FRF4d4bu2IJMXG4uIoeKRH06hxBTPjZTUShwUbuGJrOiIFJLP/hCF9uymf97qNkdYtmzOAU96xyQnRUUhTEJUFRFG4enNrs5UODXKO23jggkeUnZ4pbv+cowzLjuX1IOiajzotphfAdKQpCnEdIkJH/uTaNGwck8fnag3y5IZ8dB4/x4KgepCfIiK2i45FLUoVoBnOggbuuy+Cpu/rhdGq8PG8jH63aT6Pd6etoQnhUs84UZsyYwbJlyygoKGDhwoVkZGSctczs2bOZP38+0dHRAGRmZjJt2jQApk6dyrp16wgPDwdgxIgRPProozidTh5//HH27duHyWQiMjKS559/nqSkJE89PyE8qmtSOM/fP4APVu5nyXd5bMst58FRPWSGONFhNKsoDB8+nPvuu4+77777vMuNHTuWKVOmNPnYww8/zD333NPkOkOHDkVVVd577z2effZZ3nnnnebEEsInAk16xt/UjcwMK28v2c30/9vAmMEpjLoyGZ0qJ9+ifWvWKzgrK4vY2FjP71xVGT58OOrJP6S+fftSWFjo8f0I4Q2XpUXy4gMDyeoWzYLVB5n+zkZWrD9Cfmk1mqb5Op4QreLRjubs7GzWrFmD1Wpl4sSJ9OvXz/3Y22+/zQcffEBiYiJPPvkkaWlpZ60/b948hg0b5slIQniVOdDAL2/uSWaGlU++zuU/X+YArktbuyeH0yM5nO4p4USFBfo4qRDNo2gt+EgzbNgwXn/99Sb7FEpLS7FYLBgMBtauXcvkyZNZvHgx4eHhlJSUYLVaUVWVBQsW8Morr/DFF1+g0526rO+f//wnK1as4J133iEwUP6ARPt09FgtW3NK2ZpTxtb9pVRWNQAQGxlM1+RwAkx6jAYVk0GH0aDDqFddXw069DoFpxNAw6mBpmloP34FEqLN9EiNRK+TJirhPR47U7Bare7vBw8eTGxsLDk5OQwYMICYmBj3Y2PHjuXll1+muLiY+Ph4AN59910WLVrU6oJQXl6N09ny03WrNYTS0qoWr9cWJFvr+DqbAvTtHEHfzhFoN3ShoKyG3Ycq2H24gl0Hy6lvsGOzO2m0O3G04jUbaNLRMyWCy9KiuCwtklAPzVPt6+N2PpKtdc6XTVUVIiObvhHTY0WhpKTE/ea/e/duCgoKSE1NPeux1atXo6qq+//vv/8+H374Ie+88w4Wi8VTcYTwOUVRSLCaSbCauf7yxLP+SB1OV3Gw2Z00NjpxOJ2oigKK6y7sH7ehKKBpcKjoBFtzy9mWW8aGvaUoQEqsa57q3mmRhAUb3csrJ9f9cVt6nUKAUW5LEhfWrFfJ9OnTWb58OWVlZUyYMAGLxUJ2djYPPfQQkyZNonfv3syaNYudO3eiqioGg4GZM2e6zx6mTJlCeXk5iqJgNpuZM2cOer2e6upqfv/73xMXF8eECRMAMBqNfPTRR957xkL4CZ2qojOqBDTzw354iJV+GVY0TSOvpJqtuWVsyy3nszUHWbDm4HnXVYAeqRFcfVks/bpYMeilCUo0rUV9Cv5Kmo/almRrHW9lO1FjY09eBfU2x6l+CE7vkzheY+O7nSWUn6gnOEDPlT07cXWfOBKjzV7N5gmSrXV83nwkhPCN0GAjA7rHXHC5W6/pzO5DFazeVsiqLQV8sTGflE4hXN0njhsHpdJod6BTVVRVueC2RMclRUGIS4SqKPRMjaBnagTVdY18u7OY1VuLeHfZXt5dtte9nALodIqreUtV0OkUoi2BXHVZLAN7xEjfRAcnv10hLkHmQAPXZyVyXf8EDhVXUXCsjuMn6nA4NOxODYfTicOh4XC6/uUcqeSdpXt5f+V+ruwRw7V942Vojw5KioIQlzBFUUiNDWXAZfHnbRvXNI3cghN8vaWAtTuKWbWlkJROIVzbN44B3WMINOlxOJ1UVDVQVllP2fF6yo7XUX68nmNVDSRYzfRNj6RLokXus/BzUhSEEBekKArpCWGkJ4Qx7roufLujmK+3FrrPHkICDRw70YDzJ9etKIAlxERYsJGvNhewYsMRAk16eneOoG96FL3TIgkOMPjuSYkmSVEQQrRIcICB67ISGd4/gdzCE6zZVoSt0UFUzwCiwgKJDAsgKiyAyNAA91lBvc3OrkMVbNlfxrb9Zfyw+yiqotAlIYzL0iKJjQx2rRMWQKCp7d6W7A4nOlVx3dPRxsoq6zDoVcLMpjbf9/lIURBCtIqiKKTHh5Eef+HJhgKMejIzrGRmWHFqGgeLTrB1fxlbcsr4aFXuacsGmfTuAhEZGkBCp1BsDY3o9SoGnYpBr6LXuf4Z9CrBAXqiwwOb1QFe12Bnf8Fx9hyuYE9eJYeLqwgzu8ap6pYUTvfkcCLDAlp9TJqjsrqBT745wNptRej1KjdcnsjIK5LbtBiej3+kEEJcMlRFIS0ujLS4MG67Jo0TtbaT/RB1lJ9w9UeUH6/naGUduw5X0LAxv1nbtZiNxIQHERMRSEx4ENEnv6+samBPXiV78io4VFSFU9PQqQqd40K5cUAipcfr2ZZbzrodxQBEWwLplmyhW3I43ZPCPfZJvsHmYNkPeSz5Pg+7w8n1lydyosZG9reHWb2tiNuu6cxVvWN9fkmwFAUhhE+FBhkJDTLSOS70rMc0TSMkLIii4uPYHRqNdgeNDg273Umjw4nd7qSqrpGSY7WUVNRScqyOzTllVNU2nrYdnaqQGhfKyCuT6JoUTnp8GCbDqQE5nZpGQWkNew67xqlav6eUb7YWoQCZXa2MujKZlE5n52sOp6axbnsxn3yTS2W1jf5drdw+JI3o8CAAhmcl8MGX+/n3kj18uTGfccPS6Z4S0ap9eYIUBSGE31IUhUCTnpCglg38V1tvp6SilqMVdQQH6ukSb8Fk1J1zeVVRSIw2kxjtGqfK6dQ4XFLFpn2lrNxUwMa9pfRKjWD0oBQyEi3NzrH70DE+WLmfvKPVpMaG8sgtvc5aPy0ujKfvyWT9nqN89FUuf3p/C33To7hjWDqdIoJa9Lw9QYa5aIe3qPuaZGsdydY6vs5WW2/nq835LF9/hKraRrokhDF6UAq9UiOIjg51Z2u0O8kvreZQ0QkOFlVxsPgEBaU1RIaa+J8haQzoHuMe6PBcGu0OVmzIZ9G6QzTanaTHh5HcKYTkmBCSOoUQGxHU7OYlGeZCCCG8IChAz6grU7guK5HVWwtZ+kMef/1wK0kxZq4fmExuXgUHi6vIP1rtHg7dHGggJTaEq3vHMqRfPEbDuc9Sfsqg1zHyimQG945l2Q955BypZNXmAmx2JwBGg0pitJnkmBDSE8IY2D3G41dOSVEQQohmMBl0XJeVyJB+8Xy7o5jF3x1m7uc7CTTpSekUwg0DEkntFEpKbAiRoQEX9WYdFmzkjqHpgGuI9eLyWg6XVHG4uJrDJVWs21HMV5sKSI4JITYy2FNPEZCiIIQQLaLXqVzdJ47BvWPRmQw4bI0XbBa6GDpVJd5qJt5qZlAv18+cmkZ9g4OgAM+/hcv95kII0QqqqhBlCfRqQTjnvhXFKwUBpCgIIYT4CSkKQggh3KQoCCGEcJOiIIQQwk2KghBCCDcpCkIIIdw6xH0KFzOqoK9HJDwfydY6kq11JFvrtMds58vcIcY+EkII4RnSfCSEEMJNioIQQgg3KQpCCCHcpCgIIYRwk6IghBDCTYqCEEIINykKQggh3KQoCCGEcJOiIIQQwq1DDHPRUgcPHmTq1KlUVlZisViYMWMGKSkpvo7lNmzYMIxGIyaTCYDJkydz9dVXt3mOGTNmsGzZMgoKCli4cCEZGRmAfxy/c2Xzh2NXUVHBU089RV5eHkajkeTkZF544QUiIiLYsmULzz33HA0NDcTHx/OnP/2JyMhIv8jWtWtXMjIyUFXXZ8WZM2fStWvXNssG8Nhjj5Gfn4+qqgQFBfHss8/SvXt3v3jNnSubP7zmfvSPf/yD2bNnu/8mWvV60y5B9957r7ZgwQJN0zRtwYIF2r333uvjRKcbOnSotnfvXl/H0NavX68VFhaelccfjt+5svnDsauoqNC+++479///+Mc/ak8//bTmcDi06667Tlu/fr2maZr26quvalOnTvWLbJqmaRkZGVp1dXWb5jnTiRMn3N+vWLFCGzt2rKZp/vGaO1c2f3jNaZqm7dixQ3vggQfceVr7ervkmo/Ky8vZtWsXo0ePBmD06NHs2rWLY8eO+TiZ/8nKyiI2Nva0n/nL8Wsqm7+wWCwMHDjQ/f++fftSWFjIjh07MJlMZGVlATBu3DiWLl3qF9n8RUhIiPv76upqFEXxm9dcU9n8hc1m44UXXuD3v/+9+2etfb1dcs1HRUVFxMTEoNPpANDpdERHR1NUVERERISP050yefJkNE2jf//+PPHEE4SGhvo6EtA+jp8/HTun08l//vMfhg0bRlFREXFxce7HIiIicDqd7iYRX2b70b333ovD4eCaa65h4sSJGI3GNs/1zDPPsHbtWjRN41//+pdfvebOzPYjX7/mXnnlFW6++WYSEhLcP2vt6+2SO1NoD+bNm8fnn3/Of//7XzRN44UXXvB1pHbD347diy++SFBQEPfcc49PczTlzGyrVq3ik08+Yd68eezfv59XX33VJ7leeuklVq1axW9+8xtmzpzpkwzn0lQ2X7/mNm/ezI4dO7jrrrs8sr1LrijExsZSUlKCw+EAwOFwcPToUb9qivgxi9Fo5K677mLTpk0+TnSKvx8/fzp2M2bM4PDhw/ztb39DVVViY2NPa6o5duwYqqr65CzhzGxw6tiZzWZuv/12n7/uxo4dy/fff0+nTp387jX3Y7aKigqfv+bWr19Pbm4uw4cPZ9iwYRQXF/PAAw9w+PDhVr3eLrmiEBkZSffu3Vm0aBEAixYtonv37n7T9FFbW0tVVRUAmqaxePFiunfv7uNUp/jz8fOnYzdr1ix27NjBq6++6m6C6dWrF/X19WzYsAGA999/nxEjRvhFtuPHj1NfXw+A3W5n2bJlbX7sampqKCoqcv9/5cqVhIWF+cVr7lzZTCaTz19zDz/8MGvWrGHlypWsXLmSTp06MXfuXB588MFWvd4uyUl2cnNzmTp1KidOnCA0NJQZM2bQuXNnX8cC4MiRI0ycOBGHw4HT6SQtLY3f/e53REdHt3mW6dOns3z5csrKyggPD8disZCdne0Xx6+pbK+//rpfHLucnBxGjx5NSkoKAQEBACQkJPDqq6+yadMmpk2bdtolglFRUT7P9uCDD/Lcc8+hKAp2u51+/frx29/+luDg4DbLVlZWxmOPPUZdXR2qqhIWFsaUKVPo2bOnz19z58oWGhrqF6+5nxo2bBivv/46GRkZrXq9XZJFQQghRNMuueYjIYQQ5yZFQQghhJsUBSGEEG5SFIQQQrhJURBCCOEmRUEIIYSbFAUhhBBuUhSEEEK4/X9qoy/QlXXZjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(3)\n",
    "seq2 = torch.tensor([seq2]).cuda(3)\n",
    "seq3 = torch.tensor([seq3]).cuda(3)\n",
    "seq4 = torch.tensor([seq4]).cuda(3)\n",
    "seq5 = torch.tensor([seq5]).cuda(3)\n",
    "seq6 = torch.tensor([seq6]).cuda(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[0.1492, 0.1492, 0.1504, 0.4021, 0.1492]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[0.1488, 0.1488, 0.4046, 0.1488, 0.1488]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[0.1488, 0.1488, 0.4046, 0.1488, 0.1488]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[0.1489, 0.1489, 0.4046, 0.1489, 0.1489]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[0.1489, 0.1489, 0.1490, 0.4044, 0.1489]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[0.1488, 0.1488, 0.4046, 0.1488, 0.1488]], device='cuda:3',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = lc.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = lc.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = lc.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = lc.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = lc.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = lc.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12570.,  1790.,  4242.,  1078.,   274.],\n",
      "        [ 8808.,  2092.,  6453.,  1981.,   538.],\n",
      "        [ 4254.,  1792.,  8529.,  4160.,  1172.],\n",
      "        [  303.,   303.,  4683.,  8511.,  6369.],\n",
      "        [   94.,    70.,  1797.,  5814., 12291.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(74806.)\n",
      "diag:  tensor(43993.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep = 40\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
