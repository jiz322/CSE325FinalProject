{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 400000\n",
      "('4', '\"i will recommend this product to my friends. it gives energy to my skin, my face seems younger and feels fresh\"')\n",
      "['3', '5', '1', '2', '4']\n",
      "{'2': 19877, '3': 19910, '4': 20176, '1': 19963, '5': 20069}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list2 = []\n",
    "file_data = open('../amazon_review_less_than_300_chars_balanced.csv')\n",
    "for row in file_data:\n",
    "    list2.append(row)## Data pre-processing module\n",
    "    \n",
    "list3 = []\n",
    "for i in range(len(list2)):\n",
    "    list3.append((list2[i][-2],list2[i][:-3]))\n",
    "    \n",
    "random.seed(10)\n",
    "random.shuffle(list3)\n",
    "\n",
    "lenth = len(list3)\n",
    "train_list = list3[0:int(lenth*0.8)]\n",
    "test_list = list3[int(lenth*0.8):]\n",
    "print(len(test_list), len(train_list))\n",
    "print(train_list[3000])\n",
    "\n",
    "l = []\n",
    "for i,j in list3:\n",
    "    if i not in l:\n",
    "        l.append(i)\n",
    "print(l)\n",
    "di = {}\n",
    "test_list[0][0]\n",
    "for i in test_list:\n",
    "    if i[0] not in di.keys():\n",
    "        di.update({i[0]:0})\n",
    "    else:\n",
    "        di[i[0]] += 1\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"not\n"
     ]
    }
   ],
   "source": [
    "list4 = []\n",
    "for i in list3:\n",
    "    list4.extend(i[1].split(\" \"))\n",
    "print(list4[0])\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "c = Counter(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mot'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: In this version,\n",
    "# WE ONLY embed for frequent words.\n",
    "# Other words are all converterted to \"N0O0N\"\n",
    "selected = c.most_common(20000)\n",
    "selected_index_word = []\n",
    "for i in selected:\n",
    "    selected_index_word.append(i[0])\n",
    "selected_index_word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to N0O0N\n",
    "def convert(word_list):\n",
    "    for i, v in enumerate(word_list):\n",
    "        if v not in selected_index_word:\n",
    "            word_list[i] = \"N0O0N\"\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        self.index_word = [\"N0O0N\"]\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "                self.index_word.append(word)\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            input = text.split(\" \")\n",
    "            \n",
    "            \n",
    "           \n",
    "        \n",
    "        # NB: COMMENT OUT the line below will do less data-preprocess,\n",
    "        # but a little bit lower performance\n",
    "        \n",
    "        \n",
    "            \n",
    "            input = convert(input)           \n",
    "            \n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [05:49<00:00, 1144.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:26<00:00, 1156.75it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 400000\n",
      "Number of test sentences = 100000\n",
      "Number of unique input tokens = 20001\n",
      "Maximal sentence length = 226\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n",
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 226\n",
      "Training second batch max length = 68\n",
      "Training last batch max length = 10\n",
      "Training second last batch max length = 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as LSTM and FC will use these weight correctly\n",
    "class LSTMScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        # before output, there is a dropout (except the last layer)\n",
    "        \n",
    "        if bidirectional == 0:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, batch_first=True)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 1\n",
    "        elif bidirectional == 1:\n",
    "            self.rnn = nn.LSTM(input_size = emb_dim, hidden_size = hid_dim, num_layers = n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
    "            self.fc = nn.Linear(hid_dim, output_dim)\n",
    "            self.num_directions = 2\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # -- COMMENT\n",
    "    # -- The src means sourse, which is a 2d array batch_size by sentence_len, it is a big 2d tensor\n",
    "    def forward(self, src, ep=500):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = self.embedding(src)\n",
    "        output = self.rnn(emb)[1][0]\n",
    "        logit = self.fc(output)\n",
    "\n",
    "        return logit.squeeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jiz322/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "OUTPUT_DIM = 5\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 64\n",
    "N_LAYERS = 1 # number of LSTM layers.\n",
    "BIDIRECT = 0 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "# initialize the model\n",
    "ScoreAssigner = LSTMScoreAssigner(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECT).cuda(1)\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded words\n",
    "# and the loss function should also take padded value into consideration.\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, num_epochs=0):\n",
    "     \n",
    "    global num_epochs_train\n",
    "        \n",
    "    \n",
    "\n",
    "    if num_epochs_train == 2:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00025\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 3:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.000125\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00008\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 4:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00004\n",
    "        optimizer.load_state_dict(tmp)\n",
    "    if num_epochs_train == 5:\n",
    "        tmp = optimizer.state_dict()\n",
    "        tmp[\"param_groups\"][0][\"lr\"] = 0.00002\n",
    "        optimizer.load_state_dict(tmp)\n",
    "        \n",
    "        \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "    random.shuffle(iterator.batch_sampler.index_batches)\n",
    "    \n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    print(\"training ...\")\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        # NB: SURPRISE! THE LINE BELOW BOOST TEST ACCURACY\n",
    "        optimizer.zero_grad()\n",
    "#         #skip first batch\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "        num_batchs += 1\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(1),ep=num_epochs_train)\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(1))/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "    num_epochs_train += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(5,5))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = ScoreAssigner.forward(batch[0].cuda(1))\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        d = torch.softmax(z,dim=-1)\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss=criterion(d,(batch[1]-1).cuda(1))/BATCH_SIZE\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(len(d)):\n",
    "            row = batch[1][i]-1\n",
    "            col = torch.argmax(d[i])\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:31, 197.86it/s]\n",
      "1562it [00:06, 239.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 38s\tTrain Loss: 1.402 | Test Loss: 1.364\n",
      "epoch start:  1\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:27, 228.33it/s]\n",
      "1562it [00:06, 242.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 33s\tTrain Loss: 1.340 | Test Loss: 1.348\n",
      "epoch start:  2\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 222.67it/s]\n",
      "1562it [00:06, 240.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 34s\tTrain Loss: 1.299 | Test Loss: 1.340\n",
      "epoch start:  3\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:28, 221.62it/s]\n",
      "1562it [00:06, 244.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 34s\tTrain Loss: 1.280 | Test Loss: 1.340\n",
      "epoch start:  4\n",
      "training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6250it [00:27, 226.43it/s]\n",
      "1562it [00:06, 240.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 34s\tTrain Loss: 1.270 | Test Loss: 1.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/losses_L1_D0.5_B0.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8b78a4b33972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     pickle.dump({'training_losses': training_losses,\n\u001b[1;32m     21\u001b[0m                 'test_losses': test_losses}, f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/losses_L1_D0.5_B0.pkl'"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'apr15th_rnn_tuned.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f50745cf0d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD7CAYAAACCEpQdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8T0lEQVR4nO3deXxTdb7/8dc5Sbqme9O90FJoC7Rlq2wCCkU2KSKLM8qiqDgqwow/HJdR8CLMjDh3uHdERXFDXBkHQVlFQC6rCIhC2SlgoQt0AUpbSpvk/P4IFCpbU9ImbT/Px8OHbXLOyTuH9JOT7+ecbxRN0zSEEEI0KaqzAwghhKh/UvyFEKIJkuIvhBBNkBR/IYRogqT4CyFEEyTFXwghmiAp/kII0QTpnR2gpk6fLsVqtf+ShKAgI4WFJXWQ6NZILvtILvu5ajbJZZ/a5lJVhYAA7+ve32CKv9Wq1ar4X1rXFUku+0gu+7lqNslln7rIJcM+QgjRBEnxF0KIJqjBDPsIIeqXpmmcPp1PRUU54Lhhh1OnVKxWq8O25ygNM5eCm5sHAQEmFEWxa7tS/IUQ11RSchZFUQgNjUJRHDdIoNermM2uV2QbYi5Ns3LmTAElJWfx8fG3a7sy7COEuKbz50vw8fF3aOEXjqUoKj4+AZw/X4uzgeogjxCiEbBaLeh0Mjjg6nQ6PVarxe71GnXx33usiD/8fTWnTpc5O4oQDZK948ii/tX236hGxX/mzJn06dOHhIQEDh48eMNljxw5Qrt27Zg5c2bVbefPn+dPf/oTd911FwMGDOD777+vVVh7hQR4cq6sgtkLd3P+grleHlMIUTfef/8dKisra7Xu/v17mTbtpZsuV1CQz8SJf6jVY1zP+++/wxtv/K9Dt+kINSr+aWlpfPrpp0RGRt5wOYvFwssvv0zfvn2r3f7+++9jNBr57rvvePvtt3nppZcoLS2tfeoaCvbz5Lkxt5FbWMZ7S/dilS8tE6LB+vDDd69b/M3mGx/cJSa24eWXZ9z0MYKDTcye/U6t8jU0NRrQS01NrdHG5s6dy5133klZWRllZZeHWlasWMGrr74KQExMDElJSaxfv56BAwfWIrJ92sWb+F2flny+5hBfbzjKvb1a1PljCiEc65//tI0kPPHEwyiKyuzZ7/D66/9Ep9ORlfUrZWVlzJv3GdOmvURW1q9UVlYQGRnNCy9MxdfXl59+2s6bb/6L99//mNzcHB59dAxDhgzjhx82UV5ezvPPT6VTp45V9y1btgaAHj1SeeyxJ1m/fh1nz55lwoRJ3HlnGgDr1q1h7ty3cHd3p3fvvsyd+xarVq3Hy8vrus/DYrEwZ85stm7dDECXLt154omJ6HQ6vv76K/79788wGNzQNCuvvPIq0dHNeO21mWzf/iMGgxteXp7MmfOBQ/apw7o5+/fvZ+PGjcyfP5+33nqr2n05OTnVPjWEh4eTl5dn1/aDgoy1znb/wNbkF19gyeZjtGkZTI92N/4EU19MJh9nR7gmyWUfV80Ft5bt1CkVvd42OLBxVw7rf85xVKxqerWPoEdKxA2Xee65F1i06EvefXdeVXFVFIXDhw8yZ857eHp6AjB58p/x9w8A4O233+Tzz+czYcIkdDoVRbGdNqnTqZw9e5Z27doxYcJEVq5czttvz+bddz9Ep1MBpep5A/j4GJk37xN++eVnXnrpOfr2vYvCwkJee+1vvPfeRzRr1ozPP/8EsG3/ynXBNseOqtq2+fXXCzl8+CDz538OwNNPP8XSpYsZPnwkb731OgsWLCQ42ERFRQVWq4WjRw+zY8c2vvhiIaqqUlxcfNX2bY+h2v1v7ZDiX1lZyZQpU/j73/+OTqdzxCavUlhYUqv5LUwmHwoKShh5RwuO5pzhfz7/CU+dQrNQ5/7Bmkw+5Oefc2qGa5Fc9nHVXHDr2axWa9X55RaLhqNGTRWFatuyWLQan19vNl/OpGkad9yRhsHgXnXb0qVLWLVqJWZzJefPlxMd3Qyz2YrFYkXTqPrZ09OLrl17YDZbad06iezs/7mYxQpUz9O7dz/MZiuJiW3Jz8+ntPQ8u3fvIj4+gYiIKMxmKwMHDuFf/5pVLd8ll+YlM5ut/PjjDwwcOBhFsdXJgQPTWb/+e+65ZzgdO6YybdpUbr+9J9269SAyMorQ0AgsFjMzZkyjY8dUunfvec19ZbVar/q3VlXlhgfNDin++fn5ZGVl8dhjjwFQXFyMpmmUlJQwffp0IiIiyM7OJjAwEIDc3Fy6dOniiIeuMYNe5al7k3nlo+3MXribKQ+l4uvlVq8ZhGiobk8O5/bkcIdsy5EXU3l5eVb9/MsvO1m8eCFz5nxAQEAAq1at5Jtvvrrmem5uhqqfVVXFYrl+z8DNzVYnLh3YWiz2n1ZZE3/72z/Yt28PO3ZsZ9Kkx3nmmRfo1u12PvvsP2zbto3t239kzpzZfPDBJwQFBd/y4znkVM+IiAi2bt3K2rVrWbt2LQ8++CD33Xcf06dPB2DAgAEsWLAAgGPHjrF792569uzpiIe2i5/RnaeGJVNcVsFbizIwW1zvaj4hxLV5eXlTWnr9i5nOnTuHt7cRPz8/KioqWLbsmzrL0qZNEgcPHiA7+wQAK1YsrdF6qaldWLFiKWazGbPZzIoVS7ntti6YzWZycrJp0yaJMWMeonPnrhw6dIDTp09TXl5Oly7dePzxpzAajeTkZDvkOdToyH/GjBmsWrWKgoICxo0bh7+/P8uWLWP8+PFMmjSJ5OTkG67/yCOP8Pzzz3PXXXehqiqvvPIKRmPtx/BvRWy4L+MGJjJ3yV4+W32Isf0TnJJDCGGf3/9+FJMmPY67u8c1z8jp2rU7q1at4P77h+Hn50/79h3Yu3dPnWQJDAzimWde4JlnJuHh4UH37j3R6/V4eHjccL0hQ+7lxInjjBv3AACdO3cjPf1eLBYLf/3rf1FScg5FUQkNDeXxx58iLy+P116bgdlswWKx0LVrd9q2vXG9rSlF0xrG+Y+3MuZ/rXHPL78/zIqtWYzpn0DvDvXfAHbVsWLJZR9XzQW3ni0v71fCwpo7MJFNQ5xD51rKykrx8rJ9WcqyZd+wdOnXzJnzvlNyXevfql7G/Bui4XfEcSK/lM++O0hEkBcJzQKcHUkI0YB8+eUXfP/9GiwWM76+fjz33M0vInMlTbb4q6rCH4a0Ycb8Hby5KIOpD6US7Od58xWFEAJ48MFHePDBR5wdo9Ya9dw+N+PlYWDi8GQsVo3ZC3dzoaJuuvhCCOFqmnTxBwgP8uYPQ9py4lQJ7y/fRwNpgQghxC1p8sUfICUuiBG949i+/xRLNx9zdhwhhKhzUvwvGtC5GV3bhrJow1F2Hsx3dhwhhKhTUvwvUhSFhwYkEhPmw9yle8nOt/+bcYQQoqGQ4n8FN4OOp4Yl427QMXvhbkrO127ucCGE493KfP412UZOTg533512S9tvSKT4/0agrwdPDUum6Fw5b3+dgcXqehejCNEU3Wg+//rcRmPRZM/zv5GWkX6M6Z/Ah8v3s2DtYR7oG+/sSEI4VeXBTVQeWO+QbSmKUu2sOkNCLwzxt99wnWvN56+qCrNn/w+ZmYeoqKigQ4dUJk58Gp1OxwcfzGX16m9xc3NHUeD1199h7ty3rtqGj8/1Z/f94YfNvPPOG1itVvz9A/jzn/9CVFQ0WVnH+Otfp1FeXo7VamHgwHQeeGAMGzas491356CqOiwWM08//SwdO9bsu1CcQYr/dfRMieD4qRJWbz9BdIiRnjeZb1wIUXcmT36ORYu+ZM6cD6rm83/11em0b9+R55+fgtVqZdq0l1i27BvuvLMP//73Z3z99Urc3T0oKyvFzc39mtu4ntOni5gxYyqzZ88lNrYFS5cuZtq0l3j33Y/46qv/0KNHL8aMGQfYZjEGeO+9d3j22RdJSkrBYrFQXn6+bnfKLZLifwO/69OS7PxSPv72AOFB3rSM9HN2JCGcwhB/+02PzmvKUXP7bNy4nn379vDFF58CUF5eTkhIKN7eRiIjo5k+/WU6d+5K9+49q+bgqak9ezKIi4snNtb2zX+DBg3hn/+cSVlZKe3bd+Ctt16nvLycjh1Tq47uO3VK5fXXZ3HnnX3o2rU7LVq0vOXnWJdkzP8GdKrKE0OTCPBx582vdnP63AVnRxJCVNH429/+m3nzPmPevM/44ouvmDDhj+h0Ot5550OGD7+P/PxTPPLIaA4fPuSwR73zzjTeeus9IiOj+OSTeUyfPhWASZMm89xzL6HXG5gy5Xm++WaRwx6zLkjxvwmjp4FJw1Mor7Qwe+EuKiplCgghnOG38/nffnsvPvnko6ovVzlz5gw5OdmUlZVy5swZOnToxCOP/IEWLeI4ciTzmtu4nrZtk8nMPMivvx4DbPP1t2qVgJeXNydOHCcwMIhBg9IZN2581bTRWVnHiItryX333U+/fgPZt2+vg/eAY8mwTw1Emow8NrgNs7/azbyV+xk/uA2Kojg7lhBNym/n8//jHyfz1luv89BD96MoCgaDG5MmTUav1/Pii89SUXEBq9VKfHwid9zR+5rbuF7DNyAggJdeeoVp017EYrHg7x/A1Km2L6dau/Y7Vq1aicGgR1EU/vjHyQDMmfMGJ05kodPpMRqNvPDC1PrZMbXUZOfzr40lm46yaMNRRvaOY2CXW5vn3FXngZdc9nHVXCDz+durIeeqzXz+Muxjh8HdY0hNDOE/32ey+0ihs+MIIUStSfG3g6IoPDKoNVEhRt7+eg+5haXOjiSEELUixd9O7m46Jg5PRqcqzF64m7Jys7MjCVFnGsiocJNW238jKf61EOznyYR7k8g/c553vtlTq16EEK7u0pWqwrVZLGZUVWf3elL8aymhWQAP3BXP7iOFLPy/TGfHEcLhPD2NnDt3Bk1zvSaosNE0K+fOncbT8/qN3eu56ameM2fO5NtvvyU7O5slS5YQH3/1PDcLFy5k3rx5qKqK1Wpl5MiRjB07FoDCwkJeeOEFcnNzMZvNdOnShZdeegm9vuGfZdq7QyTHT5WwYmsW0SFGurYNc3YkIRzGaPTj9Ol8Tp48ATju0+2lOuFqGmYuBTc3D4xG+2cfuGkFTktLY+zYsYwaNeq6y/Tv359hw4ahKAolJSWkp6fTuXNnEhMTefvtt4mLi2Pu3LlUVlbywAMPsGrVKgYNGmR3WFf0QN9W5BSU8uGK/YQGehEb7uvsSEI4hKIoBAaGOHy7rnp6bFPLddNhn9TUVMLDw2+4jNForLroqby8nMrKyqrfFUWhtLQUq9VKRUUFlZWVhIaGOiC6a9DrVJ68NwlfLzfe+Go3Z0tkCgghhOur8UVeffr04e23377msA/AmjVrmDVrFllZWUyePJmHHnoIsF1yPXHiRDIzMzl//jyjRo3imWeecdgTcBVHss/y7BsbiA335W9P3o5Bb38DRggh6ovDBt7T0tJIS0sjJyeHCRMm0KtXL1q0aMHKlStJSEjgo48+orS0lPHjx7Ny5UoGDBhg1/Zd4QrfG/FxU3l4UGvmLM5g1qc7GDcw8YZTQDS1j5i3SnLZz1WzSS771DZXvV/hGxERQXJyMuvWrQPgk08+YciQIaiqio+PD3369GHr1q2OfliXcFtiCIO7x7BxVy6rd5xwdhwhhLguhxT/zMzLpzoWFRWxdevWquGhqKgo1q+3fQNQRUUFW7ZsoVWrVo54WJc0tGcsHVoFs2DNYfYeK3J2HCGEuKabFv8ZM2bQq1cv8vLyGDduHHfffTcA48ePZ/fu3QAsWLCAu+++m3vuuYeHHnqI0aNH06NHDwD+8pe/sGPHDtLT0xk6dCgxMTHcd999dfiUnEtVFB4d3IbwIC/mLM7g1BnX/jYfIUTTJLN61pFTp8uY/tF2/I3u/GVMJzzdq7dXGtv4Yl2TXPZz1WySyz4NZsxf2IQEePHE0CRyC8t4b+lerA3jPVYI0URI8a9DbWIC+V2fluw8VMDXG446O44QQlRp+HMsuLi+qVEcP1XCks3HiAoxclui46+YFEIIe8mRfx1TFIUx/ROIi/Tl/WV7yTrpemOKQoimR4p/PTDoVZ66NxlvDwOzF+6muKzC2ZGEEE2cFP964md056lhyRSXVTBnUQZmi+vNHiiEaDqk+Nej2HBfHhqYyIHjZ5i7eLez4wghmjBp+Nazbm3DbN8BsPkYJh937uwQ6exIQogmSIq/E4y4I478s+V8+t1BIoK9iY/2d3YkIUQTI8M+TqCqCs+MTsXk78mbi3ZTcFamgBBC1C8p/k5i9DQwcXgyZovGGwt3c6HC4uxIQogmRIq/E4UHefOHIW05fqqE95fvo4FMsySEaASk+DtZSlwQI3rHsX3/KZZu+dXZcYQQTYQUfxcwoHMzurYNZdH6I+w8lO/sOEKIJkCKvwtQFIWHBiQSE+bD3CV7yc4vcXYkIUQjJ8XfRbgZdDw1LBl3g47ZC3dTcr7S2ZGEEI1Yoy7+msVMxalf0awNYyqFQF8PnhqWTNG5ct7+OgNLA8kthGh4GnXxN2f9zIl3/x+ln/yR8vUfYM7ahWZx7SPqlpF+jOmfwN5jp/n32sybryCEELXQqK/w1cd0JGTYZIp+2Uhl5o9U7l8PBk/0zduhj+mEPjoFxeDu7JhX6ZkSwfFTJXy3/TjRIUZ6pIQ7O5IQopFp1MVfUVSMrbtzPjgZzVyBJWcv5qM7MB/bifnwD6AzoI9Otr0RNG+P4u7t7MhVftenJdn5pcz/dj/hQV7ERfo5O5IQohG5afGfOXMm3377LdnZ2SxZsoT4+Pirllm4cCHz5s1DVVWsVisjR45k7NixVfcvX76cOXPmoGkaiqLw4YcfEhwc7NhnchOK3g19s/bom7VH62nBkncQ89HtmI/9hPnYT6Do0EW2Rh+bir55B1Qv5xZbnaryxNAkpn+0jTe+2s3Uh24jwMf1PqUIIRqmmxb/tLQ0xo4dy6hRo667TP/+/Rk2bBiKolBSUkJ6ejqdO3cmMTGR3bt388Ybb/DRRx9hMpk4d+4cbm5uDn0S9lJUHfqI1ugjWqN1H4U1/yjmozuoPLqdCxvmcWHDR+jCWqGP7YQ+phOqT/2+UV1i9DQwaXgKMz7ewRtf7eK5BzriZtA5JYsQonG5afFPTU296UaMRmPVz+Xl5VRWVqIoCgDz5s3j4YcfxmQyAeDj41PbrHVCUVR0IXHoQuJw6zwS6+kTtqGhozu4sOVzLmz5HDU4xvZGENsJnX9EveaLNBl5bHAbZn+1m49W7ufRwW2q9q0QQtSWw8b816xZw6xZs8jKymLy5MkkJCQAkJmZSVRUFKNGjaKsrIy77rqLJ554wiULmKIo6AKj0QVG495pKNazJzEf20Hl0R1UbFtIxbaFqP4RVW8EalDzenkeHeJN3NszlkUbjhId4sOALs3q/DGFEI2bw4p/WloaaWlp5OTkMGHCBHr16kWLFi2wWCwcOHCADz/8kIqKCh599FEiIiIYOnSoXdsPCjLefKHrMJlq+WnD5AMtWwK/w1xcSOmBrZQe2Er5z8uo2LkEvZ8J74QueCd2xT0qAUWx78xZe3KNuyeZU8UX+M+6w7RpGUynxFA7n0zd5KpPkst+rppNctmnLnI5/GyfiIgIkpOTWbduHS1atCAiIoIBAwbg5uaGm5sbaWlp7Nq1y+7iX1hYgtVq/6yXJpMP+fnn7F7vam4Q0xNDTE905eewHNtJ5bEdnN2+krM/LkXx9EMf09E2NBSRiKLeeNfWJtfotFZk5RYzc/52pjyYSlig1608IYflqg+Sy36umk1y2ae2uVRVueFBs0Mu8srMvHwxUlFREVu3bq06K2jw4MFs3LgRTdOorKzkhx9+IDEx0REP6zSqhw+GxF54DXga49jZePR5HF14PJWHNnN++X9TMn8S579/l8pjP6GZKxz2uO5uOiYOT0anKrz+n12UlZsdtm0hRNNy0yP/GTNmsGrVKgoKChg3bhz+/v4sW7aM8ePHM2nSJJKTk1mwYAGbNm1Cr9ejaRqjR4+mR48eANx9991kZGQwaNAgVFWlR48ejBgxos6fWH1R3DwxtOyKoWVX27UEJ/ZQeWw75l9/xnxoE+jd0Een2E4hbdYOxc3zlh4v2M+TCfcm8d9f/MzcJXuYNDwFVXW9/okQwrUpWgP5BhHnD/vYR7OaseQcwHzMduaQdv4sqHp0kW3Qx3YirGNPispq/8Hr+53ZfPztAQZ2bcbIO1s6LHdj++hb11w1F7huNslln7oa9mnUV/g6k6Lq0Ue1RR/VFu320VhPZlJ5bAfmo9u5sH4Xv274CF1Y/OVrCYyBdm2/d4dIjp8qYcUPWUSbjHRtG1ZHz0QI0RhJ8a8HiqKiC2uFLqwVWpffYS3Mwu3kbor3bubC5k+5sPlT1JAW6GNSMcR2RPWrWSF/oG8rcgpK+XDFfsKCvIgJ863jZyKEaCwa9ayerkhRFHTBzQm88368R/4Nr/v+htttI0DTqPjx35QueJ7S/7zEhe2LsBQev+H3+up1Kk/em4Svl4HZC3dztuRCPT4TIURDJkf+Tqbzj0DXIQL3DoOxniu4ONfQDip++oaKn75G8Q1BH9MJQ2wn1JAWV11L4OvlxsThKfztkx28uSiDP9/fAYNe3tOFEDcmxd+FqD7BuCX3wy25H9ays5h/3Wm7wjhjFZW7VqB4+dtmII3thC48AUW1zfPTLNSHR+5uw5zFGXyy6gAPDUx0ySuohRCuQ4q/i1K9/HBrfSdure9Eu1CKOesX2+RzBzZQuXcNirsRXfMOGFp0QhfRhtsSQzjePYalm48RHWKkb2q0s5+CEMKFSfFvABR3bwytumNo1R2t8gLmE7svTj63HfPBDWDwQN+sHYNjOnGypS9frDlMRLA3bWLsO4NICNF0SPFvYBSDO4bYVAyxqWgW8xVfUPMT5sytjFb1dAmI4oclRwi+7x5CQp0zHbUQwrVJ8W/AFJ3edvVwdApajwexnDyE+eh24jK304pjWL/eSEl4Im5xt6GP6Yjq5e/syEIIFyHFv5FQVBV9eAL68ATcuz3A4V272L1uNZ1PnsAvdz4XNn6MGhqHIbYT+phUVF+TsyMLIZxIin8jpCgKrdq141hFIFPXHOT+VCO9Ak/avqDmhwVc+GEBalCzi99LkIrqHyFnBwnRxEjxb8T6pkZx/FQJn2/PJWBoV1KHD8FafOryF9RsX0TF9kWofmG2iediO6EFJzs7thCiHkjxb8QURWFM/wRyi0p5b9leQgI8aRYaglvKQNxSBmItO2NrFB/dQcUvy6n4eSlZ3wVAQDRqQAQ6/wjUgAjUgMhbno1UCOFapPg3cga9ylP3JvPKR9uZvXA3Ux9KxcfLDQDVyx+3Nn1wa9MHrbwEc9bP6PMPUJb3K5U5+6i0VFZtR/EOtL0RXPGGoAuIQHH3dtZTE0LcAin+TYCf0Z2nhiXz6qc/MWdxBv/vd+3R66pPAaF4GDHE98B0+0Dy88+hWa1oJQVYT2djOZ2D9XQO1tPZVO5fB1d8QY3i6YcaGFntTUENiED1cM2vwxNC2EjxbyJiw315aGAi7y7Zy+drDjGmX8INl1dUFcU3BNU3BH3zDlW3a5oVraTw4ptBju2N4Uw2lQc3QmX55fU9fKq/GQTY3iAUT19pLgvhAqT4NyHd2oZx/FQJK7dmER1i5M72kXZvQ1FUFB8Tqo8JmrWrul3TNLTSoqo3BesZ2yeGysNboOL85Q24e6MLuPKTwsWegpe/vCkIUY+k+DcxI+6IIzu/lE9XHSQiyJv4aH+HbFdRFBRjEKoxCKIvnzGkaRpa2ZmLbwi2oSPr6Rwqj26D/aWXN+Dmaesj/PZNwTtQ3hSEqANS/JsYVVX4w5A2zJi/gzcX7Wbqg7cR5OdRZ4+nKAqKdwCqdwBEta26XdM0tPJzF98Msqs+MZizfkY7sP7yBgweqP4RaOHNqfQ0XWw6R6L4BF01vbUQouak+DdBXh4GJg5PZsb8Hcz+ahcvjO6Eu0FXrxkURUHx9EX19IWI1tXus5afu2L4yPZp4fyRn7GUnL68kM4NNSDcNnwUGInO39ZbUHxMKKq8KQhxM1L8m6jwIG/+MKQt//ryFz5cvo8/DGnrMsMrqocPangChF9uSptMPpw6kWdrMp+5fPaRJfcA5sNbLq+s06P6h6P6R14xfBSB6hta9f0HQogaFv+ZM2fy7bffkp2dzZIlS4iPj79qmYULFzJv3jxUVcVqtTJy5EjGjh1bbZkjR45w77338sADD/Dcc8855hmIWkuJC2JE7zi+/D6TKJORwd1jnB3phhR376rvQr6SVnH+4ieEHCwXh5Aspw5jzvzh8kKqDtUvvPobgn8kql8oik6OgUTTU6NXfVpaGmPHjmXUqFHXXaZ///4MGzYMRVEoKSkhPT2dzp07k5iYCIDFYuHll1+mb9++jkkuHGJA52YcP1XCovVHiDIZucvU8M7PV9w80YXEoQuJw3DF7VplOdYzuZc/JZzOwVJwDPORbcDF70ZWVFS/0MunpPpfPC3VLxRF7+aMpyOaIE3TQNNAs1b/T1GBuvmbrFHxT01NvekyRqOx6ufy8nIqKyurDSPMnTuXO++8k7KyMsrKymoRVdQFRVF4aEAieYVlzF2yh4QWQXjqXGP451YpBg90plh0pthqt2vmiotvCtlVfQVL0QnMx3bY/gABFAXFN+Ti2UdXXqsQhqJ3d8KzcS7tqsJ08XerFe23t1362WpFwwrW6uuWV3hgKSq5uN41Cp5Vu2Kb1qrHubRd7bc5Lt6nXWf5y/dpv7nvivWsVk6667hwvuIa6/12Ha1qnauft/X691mt13/Ol153v6Uo+IyeBp7NHP5v6tDPu2vWrGHWrFlkZWUxefJkEhJsY7b79+9n48aNzJ8/n7feesuRDykcwM2g46lhtikgZnzwI0+PTCHYv/HO5aPo3dAFN0cX3Lza7Zq5AmvxyapPCpfPQNoFmuXS2ig+wba5jwIiKY5sTmVpxQ2Ki3Z1UeK3Bevqonnt+y6vr/3mMa5VmC7oFMyV5qsL001zalcXL65TnGqh/g79FNuRs3Lx/+rlnxVFveI2238X9Drb7q26T7n886V1VBVUHYpiuLxdRbnm9qrW+812Lq+n2k5O+O196hX59O64h7Wg5KzZ4XvHocU/LS2NtLQ0cnJymDBhAr169SI6OpopU6bw97//HZ2u9g23oCDjzRe6DpOLDmW4Ui6TyYcpj3Thv+ZuYfr8HTw3NpV2rVxrzv962V/hQUCbajdplkoqi/KoKDhBZcFxKgpOUJF/nIoTeyj4pTZ/lEpVIbpUUJQrCseVhUS5VFzU395WvXgoOhUUffVlFRX9lQXv0rKqrnrRqvb4yo2zXGvZ3xSxq7NWL2jXei7XWv+q5a7z3K+dTXWZExgcwVQHf4p10umKiIggOTmZdevWMWDAALKysnjssccAKC4uRtM0SkpKmD59eo23WVhYgtVq/9GHyeRDfv45u9era66YK8jLwKw/3cG0935gyjubua93S/rdFu0Sf0TO31/+EOwPwUmogAfgbrUQ4F5BUVHJVUd1VxahK4/06rMo2bPPtOv8XBfs/re0Xvy/5UYLWK93Z405/zV2bbXNparKDQ+aHVb8MzMziYuLA6CoqIitW7fSr18/IiIi2Lp1a9Vys2fPpqysTM72cVERJiMvjunE+8v2sWDtYX49eY4HByTW+3UADYGi6jD4h6BWNt4hMtF41aj4z5gxg1WrVlFQUMC4cePw9/dn2bJljB8/nkmTJpGcnMyCBQvYtGkTer0eTdMYPXo0PXr0qOv8og54uut58t4klm35lcXrj5BTUMpTw5IJ9pMiJ0RjoWja9drMrkWGferHb3P9criAuUv2olMVnrinLa1jAl0il6tw1Vzgutkkl33qathHroMXN9SuZTBTHkzFx8vAPxf8wqptx2kgxwtCiBuQ4i9uKizQi5fGptK+VTBfrDnEe0v3UlF53e6bEKIBkOIvauRSH+DenrH8sOckf/tkBwVnz998RSGES5LiL2pMVRTSb49l4ogU8s+c55V529n36+mbryiEcDlS/IXd2rcMZsqDt9n6AF/8LH0AIRogKf6iVi71Adq1DLrYB9gnfQAhGhAp/qLWPN31TBiWzNCesWzZk8ffP/mJwrPlN19RCOF0UvzFLVEVhSG3xzJpRAqnzpQxbd429ksfQAiXJ8VfOET7lsG8NNZ2PcB/f/Ez322XPoAQrkyKv3CY8CDvqj7A56sP8f4y6QMI4aqk+AuHquoD9Ihlc0Yef/9U+gBCuCIp/sLhVEVhSI9YJg1P4dTpMl75aBsHsqQPIIQrkeIv6kz7VrY+gNHTwD8+lz6AEK5Eir+oU5f6AClx0gcQwpVI8Rd1ztNdz1PDk7nnij5AUbH0AYRwJin+ol6oisI9PWKZODyZk0W26wGkDyCE80jxF/WqQysTUx5MxdvDdj3AaukDCOEUUvxFvbvUB0huEcRnqw/xwbJ9VJqlDyBEfZLiL5zCy8PWBxhyewybMmzzAkkfQIj6I8VfOI2qKAzt2YKJw5LJKyrjFekDCFFvpPgLp+sQb+Klsal4XuwDrNlxQvoAQtSxGhX/mTNn0qdPHxISEjh48OA1l1m4cCHp6encc889pKenM3/+/Kr73nzzTe6++27S09MZNmwYGzZscEx60WhEBHszZWwqSbGBfPrdQT5YLn0AIeqSviYLpaWlMXbsWEaNGnXdZfr378+wYcNQFIWSkhLS09Pp3LkziYmJpKSk8PDDD+Pp6cn+/fsZPXo0GzduxMPDw2FPRDR8Xh56Jo5I4ZuNR/lm0zFyCkqZcG8ygb7yOhHC0Wp05J+amkp4ePgNlzEajSiKAkB5eTmVlZVVv/fs2RNPT08AEhIS0DSNM2fO3EJs0Vhd6gM8NSyZnEJbH+Dg8TPOjiVEo1OjI/+aWrNmDbNmzSIrK4vJkyeTkJBw1TKLFy+mWbNmhIWF2bXtoCBjrXOZTD61XrcuSa7r62/yoU1LE3/9cCv/+HwnZ8oqGXR7bNUBhStxhf11Pa6aTXLZpy5yObT4p6WlkZaWRk5ODhMmTKBXr160aNGi6v4ff/yRf/3rX3zwwQd2b7uwsASr1f4moMnkQ37+ObvXq2uS6+Y8VHhhVCfeXbKHtxftJuNwAWP6x2PQ65wdrYor7a/fctVskss+tc2lqsoND5rr5GyfiIgIkpOTWbduXdVtO3fu5M9//jNvvvlmtTcEIW7kUh/gd3fFs3F3Lq9+ulOuBxDCARxW/DMzM6t+LioqYuvWrcTHxwOwa9cunn76aV5//XXatm3rqIcUTYSqKIwe0JoJ9yaTU1gqfQAhHKBGwz4zZsxg1apVFBQUMG7cOPz9/Vm2bBnjx49n0qRJJCcns2DBAjZt2oRer0fTNEaPHk2PHj0AmDZtGuXl5UydOrVqm6+99to1ewJCXE+nBBNhQam8sXAX//h8J/f3bUXvDpEu2QcQwtUpWgO5mkbG/OtHQ8hVVl7J3CV72ZVZSI+UcMb0c14fwFX3F7huNsllnwY15i9EXfLyMDBpRAqDu8ewcZetD3D63AVnxxKiQZHiLxokVVEY1qsFE+5NIqewlGnSBxDCLlL8RYPWKSHENi+Qm45/fL6T73+SeYGEqAkp/qLBiwz2ZsqDqbSNDeTjVQeZt2I/lWars2MJ4dKk+ItGwcvDwKThKQzu3pwNu3KZ+dlP0gcQ4gak+ItGQ1UVhvWKY8K9SWTn2/oAh06ccXYsIVySFH/R6Nj6AJ3wcNPx2mc7+X5ntvQBhPgNKf6iUYo0GZn6YCptYgL5+NsDfLRS+gBCXEmKv2i0vDwM/HFECnd3a876X6QPIMSVpPiLRk1VFYbfEceTQ219gFekDyAEIMVfNBGpiSG8OLYT7gZbH2DdzmxnRxLCqaT4iyYjymRkykOptI4JYP63B+R6ANGkSfEXTYq3h4E/jWh3sQ+Qw2vSBxBNlBR/0eRc2Qc4cbEPcPjEWWfHEqJeSfEXTdaVfYCZn/3Eup+lDyCaDin+okmr6gM0D2D+SukDiKZDir9o8rw9DPxp5BV9gM+lDyAaPyn+QnC5D/DE0CSOnyrhlY+2cThb+gCi8ZLiL8QVbksM4aUxqbjpVWZ+Kn0A0XhJ8RfiN6JCjEx58LaqPoDMCyQaIyn+QlyD0dPWBxjUtTn/97OtD3CmRPoAovG4afGfOXMmffr0ISEhgYMHD15zmYULF5Kens4999xDeno68+fPr7rPYrEwbdo0+vbty1133cWXX37puPRC1CFVVRhx5+U+wLR50gcQjYf+ZgukpaUxduxYRo0add1l+vfvz7Bhw1AUhZKSEtLT0+ncuTOJiYksWbKErKwsVq1axZkzZxg6dCjdunUjKirKoU9EiLpyW2IIYYFevPHVLmZ++hOj+8VzR/tIZ8cS4pbc9Mg/NTWV8PDwGy5jNBpRFAWA8vJyKisrq35fvnw5I0eORFVVAgMD6du3LytXrnRAdCHqT/TFPkBi8wA+WnmA+Sv3Y7ZIH0A0XDc98q+pNWvWMGvWLLKyspg8eTIJCQkA5ObmEhERUbVceHg4eXl5dm8/KMhY62wmk0+t161Lkss+zs5lAv76ZA8+Xr6Xhd8f5uSZcp5/8Dan57oRV80muexTF7kcVvzT0tJIS0sjJyeHCRMm0KtXL1q0aOGozVNYWILVav9X8ZlMPuTnn3NYDkeRXPZxpVx3d2mGydedD5bv40+z1tG7QyTd2oYR5Ofh7GjVuNI+u5Lksk9tc6mqcsODZocV/0siIiJITk5m3bp1tGjRgvDwcHJyckhJSQGu/iQgREPUuXUo4UHe/HtdJl+tP8JX64+Q2MyfbklhpCaE4Onu8D8tIRzKIad6ZmZmVv1cVFTE1q1biY+PB2DAgAF8+eWXWK1WioqKWL16Nf3793fEwwrhVNEhRl6d0IOZj3djaM9Yis5d4MPl+3l69kbe+WYPuzILsVilLyBc000PT2bMmMGqVasoKChg3Lhx+Pv7s2zZMsaPH8+kSZNITk5mwYIFbNq0Cb1ej6ZpjB49mh49egBwzz338Msvv9CvXz8AJkyYQHR0dN0+KyHqkcnfkyG3x5LePYYjOcVs3pPHj3tPsnXvSXy93ejaJpRubcNoFnr5xAghnE3RNM3+gXQnkDH/+iG57HO9XGaLlV2ZhWzOyOOXwwVYrBqRJm+6tw2ja9swAnzcnZbN2SSXfRrMmL8QAvQ6lY7xJjrGmyg5X8m2fSfZvCePL9dl8p91mbSOCaB7Uhgd4014uMmfoah/8qoToo4ZPQ307hhF745RnCwqY8uePDZn5PHe0n24Gw7SMd5E96QwWjcPQFVlWEjUDyn+QtSj0EAvhvZswT09Yjl04ixb9uTx475TbNmTh7/Rja5tw+jeNoyokNpf1yJETUjxF8IJFEUhPtqf+Gh/Hujbil8O2/oD3207zsqtWTQLMdItKYyubULxM9Z9f0A0PVL8hXAyg15HamIIqYkhFJdV8OPek2zZk8eCtYf59/eHaRsbSPekMDq0MuFu0Dk7rmgkpPgL4UJ8vdzomxpN39RocgtL2ZyRxw978pj7zV483HR0SjDRPSmchGb+qHLaqLgFUvyFcFHhQd4MvyOOe3u14GDWGTbvyWP7/lNs2p1HoK873dqG0a1tGBHB3s6OKhogKf5CuDhVUUhsHkBi8wBG3RXPz4cK2JyRx4ofsli25VdiwnzolhRGlzah+Hq5OTuuaCCk+AvRgLgbdHRpE0qXNqGcLbnA1r226wc+X32If689TFJsIN2Tw2nfMsjZUYWLk+IvRAPlZ3SnX+dm9OvcjBP5JWzJyOOHvSf5ZXEGnu56eraPpGPLIFpG+Ul/QFxFir8QjUCUycjI3i0Zfkcc+7JOsyUjj/U7T7Bq668E+3nQrW0Y3ZPCCA30cnZU4SKk+AvRiKiqQtuYQNrGBOLj68mqzUfZvCePpVuOsWTzMeIifOmWFEbn1qEYPQ3OjiucSIq/EI2Uh7uebklhdEsK4/S5i/2BjFw+WXWQz1cfIiUuiO5J4aTEBWHQO2R2d9GASPEXogkI8HFnQJdmDOjSjKyT59ickcfWvSfZeagAbw89nVuH0i0pjLgIX5l2uomQ4i9EE9Ms1IdmoT6M7B3HvmOn2ZyRx6bduXy/M5uQAE/btNNJYYT4ezo7qqhDUvyFaKJ0qkpSiyCSWgRx/oKZHQfy2bInj683HmXxxqO0ivKjW1IYtyWG4O0h/YHGRoq/EAJPdz09UsLpkRJOUXF51bTT81ce4LPvDtG+pa0/kNQiEL1O+gONgRR/IUQ1gb4e3N0thkFdm/PrFf2B7QfyMXoa6NImlO5JYcSE+Uh/oAGT4i+EuCZFUYgJ8yUmzJf7erdkz9EiNmfk8X8/57BmxwnCAr3onhRG17ahBPtJf6ChkeIvhLgpvU6lXctg2rUMpqy8ku0H8tmckcdX64/w1fojJDbzp1vbMFITQ/B0l7LSENToX2nmzJl8++23ZGdns2TJEuLj469a5s0332T58uWoqorBYODpp5+mZ8+eABw9epSpU6dSXFxMRUUFgwYNYuLEiY59JkKIeuHlYaBXuwh6tYug4Mx5W39gz0k+XLGfT747SIdWwXRPCqdtbAA6VfoDrqpGxT8tLY2xY8cyatSo6y6TkpLCww8/jKenJ/v372f06NFs3LgRDw8P/vGPf9C/f39Gjx5NaWkpgwcP5o477iAlJcVhT0QIUf+C/T1Jvz2Wwd1jOJJbzJaL/YEf953C19uNrm1C6dY2jGahRukPuJgaFf/U1NSbLnPpKB8gISEBTdM4c+YMYWFhKIrCuXPnACgvL0dRFAIDA2sZWQjhahRFIS7Cj7gIP36f1ordmbavpVz70wlWbTtOZLD3xf5AGCaTj7PjCupozH/x4sU0a9aMsLAwAP7yl7/w+OOP89lnn1FcXMyzzz5LVFRUXTy0EMLJ9DqVDvEmOsSbKDlfyfb9p9ickceX6zL5cl0mkSZvok1GYsJ9iQ23XXAmX09Z/xRN07SaLtynTx/efvvta475X/Ljjz/y7LPP8sEHH9CiRQsAZs2aha+vL48++iinTp1izJgxvPbaa7Rr1+7Wn4EQokHIKShh0y85HMw6zaHjZyg8Ww7YJqNrFupDq2j/i/8F0DzcV+YbqmMOPfLfuXMnf/7zn3nrrbeqCj/Axx9/zOrVqwEICQmha9eubNu2za7iX1hYgtVa4/epKiaTD/n55+xer65JLvtILvu5WjYDcGdKOCPT4snPP8eZkgsczS3mWO45juYVs2V3Lt/9mAWAXqcQHeJDTLgPsWG2TwjhQd6oat31DVxtf11S21yqqhAUZLzu/Q4r/rt27eLpp5/m9ddfp23bttXui4qKYsOGDQwdOpSSkhJ27NhBnz59HPXQQogGyN/oTodWJjq0MgGgaRoFZ8ur3hCO5dkayN//lA2Au5uO5qE+xIT5EHtxyMjk7ymN5Fqq0bDPjBkzWLVqFQUFBQQEBODv78+yZcsYP348kyZNIjk5meHDh5OdnU1oaGjVeq+99hoJCQlkZGQwY8YMysrKMJvNDBo0iKeeesquoHLkXz8kl31cNRe4bjZ7clk1jbzCMtsbQt45juUW8+vJEswWKwDeHnpiwnwu9g9s/wX4uNd5rvpUV0f+do35O5MU//ohuezjqrnAdbPdai6zxUp2filH8y5+Qsgt5kR+KdaLpczP6EZsmK9tyCjcl5gwH3xq8MX2jW1/1duwjxBC1Ae9TqV5mA/Nw3ygve22ikoLWadKqg0Z/XK4gEuHi8F+HlVnF8WG+dI8zKfJX4nctJ+9EKJRcDPoaBnpR8tIv6rbzl8w24aK8oo5evETwvb9pwBQgLAgL2IuNpNjw33x829a328sxV8I0Sh5uutp3TyA1s0Dqm4rLquoGio6lneOvceK2LInDwCdqhBp8q72hhAR7N1op7CW4i+EaDJ8vdxIiQsiJS4IsJ1hdPrcBY7mnuNUcTl7MwvYceAU63/JAcCgV2kWcvmCtNhwX0IDvVAbwRlGUvyFEE2WoigE+noQ6OtR1VjVNI1TZ85f7h/kFrNxVy5rdpwAwMNNV/0MozAfgvw8Gtwpp1L8hRDiCoqiEBrgRWiAF13b2KaosVo1cgpLq51yunr7ccwWW0vZ6Gm44oI026cEP2PtTjmtL1L8hRDiJlRVIcpkJMpkpOfFyYgrzVZO5JdwLLeYoxffEJYePcalk+cDfNyvuCDNduqpK30XshR/IYSoBYNerSrsvS/edqHCwq8nLzeUj+YWs/NQQdU6If6eVdcfxIb70jzUB3c350xqJ8VfCCEcxN1NR3y0P/HR/lW3lZZXVg0VHcs9x+Hss/y47+IppwpEBHlXe0OIMhnrZVI7Kf5CCFGHvD0MtI0JpG3M5e8wOVtacbGhbPuEsCuzkE27L59yGhViJDbcl7gIX9Lv8K6TXFL8hRCinvl5u9G+ZTDtWwYDtlNOC4vLq2Y4PZZ7jq1781i3M5tmkf5EB3o6PIMUfyGEcDJFUQj28yTYz5PUxBDANqldSVklcTFBdTLnUOO8dE0IIRo4VVHw9b75hHS13n6dbVkIIYTLkuIvhBBNkBR/IYRogqT4CyFEEyTFXwghmiAp/kII0QQ1mPP8VbX206Xeyrp1SXLZR3LZz1WzSS771CbXzdZpMF/gLoQQwnFk2EcIIZogKf5CCNEESfEXQogmSIq/EEI0QVL8hRCiCZLiL4QQTZAUfyGEaIKk+AshRBMkxV8IIZqgBjO9w40cPXqU559/njNnzuDv78/MmTOJiYmptozFYmHGjBls2LABRVF47LHHGDlypNNzzZ49m88++4yQENtXt3Xs2JGXX365TnPNnDmTb7/9luzsbJYsWUJ8fPxVyzhjf9UklzP21+nTp3n22WfJysrCzc2N5s2b88orrxAYGFhtufPnz/PCCy+wZ88edDodzz33HL1793Z6rueff57NmzcTEBAAwIABA3jiiSfqLBfAk08+yYkTJ1BVFS8vL6ZMmULr1q2rLeOM11hNcjnjNXbJG2+8wezZs6/5+nf460trBMaMGaMtXrxY0zRNW7x4sTZmzJirllm0aJH28MMPaxaLRSssLNR69uypHT9+3Om5Xn/9de3VV1+t0xy/tW3bNi0nJ0fr3bu3duDAgWsu44z9VZNczthfp0+f1n744Yeq31999VXthRdeuGq52bNnay+++KKmaZp29OhRrXv37lpJSYnTcz333HPaxx9/XGc5rqW4uLjq5++++04bOnToVcs44zVWk1zOeI1pmqZlZGRojzzyyHVf/45+fTX4YZ/CwkL27t3L4MGDARg8eDB79+6lqKio2nLLly9n5MiRqKpKYGAgffv2ZeXKlU7P5QypqamEh4ffcJn63l81zeUM/v7+dOnSper39u3bk5OTc9VyK1as4He/+x0AMTExJCUlsX79eqfncgYfH5+qn0tKSlCUqycZc8ZrrCa5nKGiooJXXnmF//qv/7ruMo5+fTX4YZ/c3FxCQ0PR6XQA6HQ6QkJCyM3NrfbxNzc3l4iIiKrfw8PDycvLc3ougGXLlrFx40ZMJhMTJ06kQ4cOdZarpup7f9nDmfvLarXy+eef06dPn6vuy8nJITIysur3+txnN8oF8OGHH7JgwQKio6OZPHkycXFxdZ7pxRdfZNOmTWiaxnvvvXfV/c56jd0sF9T/a+xf//oXQ4YMISoq6rrLOPr11eCLf0P3+9//nscffxyDwcCmTZt48sknWb58edX4rKjO2ftr+vTpeHl5MXr06Hp5vJq6Ua6nn34ak8mEqqosXryYRx99lNWrV1cdmNSVv/71rwAsXryY1157jXfffbdOH6+mbparvl9jO3fuJCMjg2eeeaZOtn89DX7YJzw8nJMnT2KxWABbE+nUqVNXDR+Eh4dX+0icm5tLWFiY03OZTCYMBgMAt99+O+Hh4Rw6dKjOctVUfe+vmnLm/po5cya//vor//u//4uqXv2nExERQXZ2dtXv9bXPbpYrNDS06vahQ4dSVlZWr5/ihg4dytatWzl9+nS12539Grtervp+jW3bto3MzEzS0tLo06cPeXl5PPLII2zcuLHaco5+fTX44h8UFETr1q1ZunQpAEuXLqV169ZXDa0MGDCAL7/8EqvVSlFREatXr6Z///5Oz3Xy5Mmqn/ft20d2djaxsbF1lqum6nt/1ZSz9tesWbPIyMjgzTffxM3N7ZrLDBgwgAULFgBw7Ngxdu/eTc+ePZ2e68p9tmHDBlRVJTQ0tM4ylZaWkpubW/X72rVr8fPzw9/fv9py9f0aq2mu+n6NPfbYY2zcuJG1a9eydu1awsLCeP/99+nRo0e15Rz++qp1q9iFHD58WBsxYoTWr18/bcSIEVpmZqamaZr26KOPart27dI0TdPMZrM2depULS0tTUtLS9O++OILl8j17LPPanfffbeWnp6uDRs2TFu3bl2d55o+fbrWs2dPrXXr1lr37t21QYMGXZXLGfurJrmcsb8OHjyoxcfHa/369dOGDBmiDRkyRHvyySc1TdO0IUOGaHl5eZqmaVppaak2ceJErW/fvlq/fv207777ziVyPfjgg9rgwYO19PR07f7779d27txZp7ny8/O1kSNHaoMHD9aGDBmijRkzRsvIyNA0zbmvsZrmcsZr7EpXnu1Tl68v+SYvIYRoghr8sI8QQgj7SfEXQogmSIq/EEI0QVL8hRCiCZLiL4QQTZAUfyGEaIKk+AshRBMkxV8IIZqg/w+TIHIFK6DOdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"best\"\n",
    "example2 = \"good\"\n",
    "example3 = \"okay\"\n",
    "example4 = \"trash\"\n",
    "example_s1 = \"it definitely worth its price. will purchase again. cheap and of good quality.\"\n",
    "example_s2 = \"it is very a peice of trash. it is too expensive comparing with other options.\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cuda(1)\n",
    "seq2 = torch.tensor([seq2]).cuda(1)\n",
    "seq3 = torch.tensor([seq3]).cuda(1)\n",
    "seq4 = torch.tensor([seq4]).cuda(1)\n",
    "seq5 = torch.tensor([seq5]).cuda(1)\n",
    "seq6 = torch.tensor([seq6]).cuda(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  best \n",
      "prediction:  tensor([[8.8157e-05, 3.7458e-04, 2.0531e-04, 5.1226e-03, 9.9421e-01]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  good \n",
      "prediction:  tensor([[0.0022, 0.0047, 0.0416, 0.8937, 0.0578]], device='cuda:1',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Example:  okay \n",
      "prediction:  tensor([[7.0977e-06, 2.4715e-03, 9.9715e-01, 3.7280e-04, 9.3525e-08]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  trash \n",
      "prediction:  tensor([[9.3506e-01, 6.4238e-02, 5.5132e-04, 2.0200e-05, 1.2616e-04]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it definitely worth its price. will purchase again. cheap and of good quality. \n",
      "prediction:  tensor([[1.0322e-06, 1.9816e-07, 3.1107e-08, 3.8902e-05, 9.9996e-01]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "Example:  it is very a peice of trash. it is too expensive comparing with other options. \n",
      "prediction:  tensor([[9.6180e-01, 3.8000e-02, 2.0010e-04, 1.3083e-06, 3.4155e-06]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", d)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11638.,  4867.,  1935.,   763.,   751.],\n",
      "        [ 5015.,  8204.,  4339.,  1248.,  1066.],\n",
      "        [ 1707.,  4427.,  9089.,  3695.,   989.],\n",
      "        [  493.,   765.,  2922., 10889.,  5100.],\n",
      "        [  392.,   546.,   534.,  2988., 15606.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist: tensor(60885.)\n",
      "diag:  tensor(55426.)\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "diagnal = 0\n",
    "\n",
    "ep = 5\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        distance+= confusion_matrix[ep-1][i][j]*abs(i-j)\n",
    "        if i == j:\n",
    "            diagnal += confusion_matrix[ep-1][i][j]\n",
    "        \n",
    "print(\"dist:\" ,distance)\n",
    "print(\"diag: \",diagnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(sum(confusion_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
